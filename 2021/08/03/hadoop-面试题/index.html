<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="hadoop解决哪些问题，有哪些特性 主要用于解决海量数据的存储和分析计算的问题。  特性有如下四个： （1）高可靠性：hadoop底层维护多个数据副本，即使某个节点的计算出现问题或存储出现故障，数据也不会丢失； （2）高扩展性：天然支持分布式，可以方便地扩展出几千个节点； （3）高效性：在mapreduce的思想中，hadoop是并行工作的，这就提高了任务的处理效率； （4）高容错性：可以自动将">
<meta property="og:type" content="article">
<meta property="og:title" content="hadoop - 面试题">
<meta property="og:url" content="http://example.com/2021/08/03/hadoop-%E9%9D%A2%E8%AF%95%E9%A2%98/index.html">
<meta property="og:site_name" content="往南">
<meta property="og:description" content="hadoop解决哪些问题，有哪些特性 主要用于解决海量数据的存储和分析计算的问题。  特性有如下四个： （1）高可靠性：hadoop底层维护多个数据副本，即使某个节点的计算出现问题或存储出现故障，数据也不会丢失； （2）高扩展性：天然支持分布式，可以方便地扩展出几千个节点； （3）高效性：在mapreduce的思想中，hadoop是并行工作的，这就提高了任务的处理效率； （4）高容错性：可以自动将">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2021-08-03T14:41:25.000Z">
<meta property="article:modified_time" content="2022-02-26T17:19:39.154Z">
<meta property="article:author" content="Bonnie">
<meta property="article:tag" content="hadoop">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/2021/08/03/hadoop-%E9%9D%A2%E8%AF%95%E9%A2%98/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>hadoop - 面试题 | 往南</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">往南</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-resources">

    <a href="/resources/" rel="section"><i class="download fa-fw"></i>资源</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/08/03/hadoop-%E9%9D%A2%E8%AF%95%E9%A2%98/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Bonnie">
      <meta itemprop="description" content="每天都要做个人啊">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="往南">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          hadoop - 面试题
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-08-03 22:41:25" itemprop="dateCreated datePublished" datetime="2021-08-03T22:41:25+08:00">2021-08-03</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-02-27 01:19:39" itemprop="dateModified" datetime="2022-02-27T01:19:39+08:00">2022-02-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E9%9D%A2%E8%AF%95%E9%A2%98/" itemprop="url" rel="index"><span itemprop="name">面试题</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h3 id="hadoop解决哪些问题，有哪些特性"><a href="#hadoop解决哪些问题，有哪些特性" class="headerlink" title="hadoop解决哪些问题，有哪些特性"></a>hadoop解决哪些问题，有哪些特性</h3><ol>
<li><p>主要用于解决海量数据的存储和分析计算的问题。</p>
</li>
<li><p>特性有如下四个：</p>
<p>（1）高可靠性：hadoop底层维护多个数据副本，即使某个节点的计算出现问题或存储出现故障，数据也不会丢失；</p>
<p>（2）高扩展性：天然支持分布式，可以方便地扩展出几千个节点；</p>
<p>（3）高效性：在mapreduce的思想中，hadoop是并行工作的，这就提高了任务的处理效率；</p>
<p>（4）高容错性：可以自动将运行失败的任务重新分配到新的节点运行。</p>
</li>
</ol>
<span id="more"></span>

<h3 id="hadoop的版本区别"><a href="#hadoop的版本区别" class="headerlink" title="hadoop的版本区别"></a>hadoop的版本区别</h3><p>1.x的版本包含辅助工具，hdfs和mapreduce。其中hdfs负责数据存储，mapreduce负责数据计算和资源调度。</p>
<p>2.x的版本与1.x版本大致相同，唯一的区别在于将mapreduce的任务一分为二，mapreduce继续负责数据的运算，将资源调度的任务分配给yarn框架。</p>
<h3 id="常用端口号"><a href="#常用端口号" class="headerlink" title="常用端口号"></a>常用端口号</h3><p>hadoop2：</p>
<ol>
<li>HDFS NameNode内部通信端口：8020、9000；</li>
<li>HDFS NameNode的用户查询端口：50070；</li>
<li>Yarn查询任务运行情况端口：8080；</li>
<li>查看历史服务器：19888.</li>
</ol>
<p>hadoop3：</p>
<ol>
<li>NameNode内部通信端口：8020、9000、9820；</li>
<li>NameNode对用户开放的查询端口：9870；</li>
<li>Yarn查询任务运行情况端口：8080；</li>
<li>查看历史服务器端口：19888.</li>
</ol>
<h3 id="常用的配置文件"><a href="#常用的配置文件" class="headerlink" title="常用的配置文件"></a>常用的配置文件</h3><p>2.x：hdfs-site.xml、mapred-site.xml、yarn-site.xml、core-site.xml、slaves；</p>
<p>3.x：hdfs-site.xml、mapred-site.xml、core-site.xml、yarn-site.xml、workers。</p>
<h3 id="HDFS相关"><a href="#HDFS相关" class="headerlink" title="HDFS相关"></a>HDFS相关</h3><h4 id="组成架构"><a href="#组成架构" class="headerlink" title="组成架构"></a>组成架构</h4><ol>
<li>NameNode：用于存储文件的元数据，比如文件名、文件目录结构、文件的块列表以及块所在的datanode等，并处理客户端的读写请求。</li>
<li>DataNode：存储实际的数据块，并执行数据块的读写操作。</li>
<li>SecondaryNameNode：它不是NameNode的热备，不能在NameNode挂掉时进行替换，而是辅助NameNode，分担其工作量，比如定期合并fsimage和edits，在NameNode挂掉时辅助恢复NameNode。</li>
</ol>
<h4 id="机架感知机制（副本节点的选择）"><a href="#机架感知机制（副本节点的选择）" class="headerlink" title="机架感知机制（副本节点的选择）"></a>机架感知机制（副本节点的选择）</h4><p>默认情况下是三个副本，可以通过dfs.replication参数修改副本数。该参数的范围是1-16，修改后需要重启hdfs。</p>
<p>默认三个副本的情况下，第一个副本存储在客户端所在的datanode上，如果客户端不在集群中，久就任意选择一个；第二个副本保存在第一副本所在的datanode的不同节点上；第三个副本保存在与第一个副本不同的datanode的任意节点中。</p>
<h4 id="NameNode和SecondaryNameNode运行机制"><a href="#NameNode和SecondaryNameNode运行机制" class="headerlink" title="NameNode和SecondaryNameNode运行机制"></a>NameNode和SecondaryNameNode运行机制</h4><p>​        首先已知元数据信息被存储在NameNode节点的磁盘中，因此如果频繁的进行读写请求，会导致NameNode的处理效率变低。但是如果将其存储在内存中，那么一旦出现断电，元数据会因为无法及时保存到磁盘而导致数据丢失。于是引入了fsimage，将元数据存储在内存，并备份到磁盘的fsimage中。</p>
<p>​        但是这里又会出现一个新的问题：如果将元数据保存到内存的时候，同步备份到fsimage，同样会造成NameNode的效率变低；但如果不同步进行，一旦出现断电等情况，内存中的元数据依然会丢失。于是又引入了edits文件。edits只执行追加操作，将数据的变更操作写入edits，这样断电重启的时候就可以直接合并，形成完整的元数据信息。</p>
<p>​        但是这种合并需要定期执行，否则edits的数据量过大也会导致执行效率变低。如果使用NameNode负责定期合并的操作，会加大NameNode的处理压力，所以引入了SecondaryNameNode来执行定期合并的操作。它的定期将fsimage和edits文件合并生成一个新的fsimage.chkpoint文件，然后拷贝到NameNode中，NameNode会将其重命名为fsimage。</p>
<h4 id="HDFS中小文件的处理"><a href="#HDFS中小文件的处理" class="headerlink" title="HDFS中小文件的处理"></a>HDFS中小文件的处理</h4><ol>
<li><p>小文件的影响：因为一个文件不管在磁盘中多大，在HDFS中至少会占用一个数据块存储，如果一个文件的大小为1M，那么存储到数据块中，这个块的其余127M空间都不能再被使用。并且，存储大量小文件，会占用NameNode的大部分内存，甚至会耗尽内存。</p>
</li>
<li><p>解决的方法：</p>
<p>（1）har文件：将多个小文件打包为一个har文件，在HDFS中只会存储这个har文件的元数据信息，但是实际操作中，允许对里面的文件进行透明访问；</p>
<p>（2）sequencefile：将文件名作为key，文件内容作为value存储，可以将多个kv形式的文件合并为一个大文件进行存储；</p>
<p>（3）CombineTextInputFormat：是新的InputFormat的格式，用于将多个小文件合并为一个split，同时也会考虑数据的存储位置。</p>
</li>
</ol>
<h4 id="HDFS的读写过程"><a href="#HDFS的读写过程" class="headerlink" title="HDFS的读写过程"></a>HDFS的读写过程</h4><ol>
<li><p>写过程：</p>
<p>（1）客户端首先通过分布式文件系统向NameNode请求上传文件，NameNode检查目标文件机器路径是否存在，然后返回给系统是否可以上传；</p>
<p>（2）如果可以上传，客户端接着向NameNode询问第一个block要上传到哪个DataNode中，NameNode会返回三个DataNode：dn1、dn2和dn3；</p>
<p>（3）然后客户端向dn1请求上传block，dn1将请求传递给dn2，dn2在传递给dn3，此时没有其他的datanode节点了，dn3开始向dn2返回响应信息，dn2收到后向dn1返回响应，dn1收到后向客户端返回，于是传输管道建成；</p>
<p>（4）客户端开始上传block给dn1，dn1以packet为单位接收数据，接收到一个packet数量的数据后将数据发送给dn2，dn2发送给dn3；</p>
<p>（5）当第一个block传输成功后，客户端再向NameNode请求上传第二个block。</p>
</li>
<li><p>读过程：</p>
<p>（1）客户端通过分布式文件系统向NameNode请求下载文件，NameNode通过查询元数据，返回block所在的DataNode地址；</p>
<p>（2）客户端会依据先就近再随机的原则选择一个DataNode，请求读取数据；</p>
<p>（3）DataNode开始传输数据给客户端，客户端以packet为单位接收数据，先在本地缓存，然后再写入目标文件。</p>
</li>
</ol>
<h4 id="为什么数据块不能设置太小也不能设置太大"><a href="#为什么数据块不能设置太小也不能设置太大" class="headerlink" title="为什么数据块不能设置太小也不能设置太大"></a>为什么数据块不能设置太小也不能设置太大</h4><p>HDFS文件在物理上是分块存储的，块的大小可以通过dfs.blocksize调整。默认情况下，hadoop1的块大小是64M，hadoop2的块大小是128M。</p>
<p>（1）如果设置太小，会增加寻址时间，并且每个块都会在NameNode中存储元数据，也会增大NameNode的开销；</p>
<p>（2）如果设置太大，以至于从磁盘获取数据的时间明显大于定位这个块开始位置的时间，会导致程序处理这块数据会非常慢。</p>
<h4 id="HDFS实现高可用"><a href="#HDFS实现高可用" class="headerlink" title="HDFS实现高可用"></a>HDFS实现高可用</h4><p>​        同时启动2个NameNode，一个处于活动状态，一个处于随时待命状态。这样可以保证运行状态的NameNode出现故障的时候，可以在数据不丢失的情况下，手动或自动将待命的NameNode切换到活动状态继续执行。</p>
<p>​        为了使两个NameNode保持同步，两个NameNode会与一组名为JournalNode的守护程序进行通信。当活动的NameNode修改命名空间时，会定期将执行的操作记录到editlog中，并写入JN的多数节点，比如写入 2n + 1 个守护节点上，只要 n+1 个守护节点成功写入就表示写入成功，而待命的NameNode会一直监听守护节点上editlog的变化，如果出现改动就会读取这个日志并与当前的命名空间合并，保证活动的NameNode发生错误时，待命的NameNode能够与活动的NameNode的命名空间保持一致。</p>
<p>​        为了让状态切换尽快完成，还需要保证待命的NameNode也实时保存了数据块的存储信息，这样在错误切换的时候，待命的NameNode就不需要等待所有数据块全部汇报完后再切换，而是直接切换到活动状态。我们只需要让DataNode同时向这两个NameNode发送块位置信息和心跳。</p>
<h3 id="MapReduce相关"><a href="#MapReduce相关" class="headerlink" title="MapReduce相关"></a>MapReduce相关</h3><h4 id="组成架构-1"><a href="#组成架构-1" class="headerlink" title="组成架构"></a>组成架构</h4><p>MapReduce使用主从架构，包含JobClient、JobTracker、TaskTracker和Task。</p>
<ol>
<li>在用户端使用JobClient将打包好的jar文件存储到HDFS上，然后将路径提交给JobTracker，JobTracker会创建Task，分发给多个TaskTracker执行；</li>
<li>JobTracker是主从结构中的主节点，会调度和监控每个Task的状态，如果某个Task执行失败，就会重新运行它；</li>
<li>TaskTracker是主从结构中的从节点，运行在HDFS的DataNode上，会主动和JobTracker进行通信，接收并执行从JobTracker传过来的任务；</li>
<li>Task分为Map Task和Reduce Task，由TaskTracker来启动，我们知道在HDFS中使用block为单位存储数据，在MapReduce中则使用split为单位处理数据，这个split是一个逻辑概念，只存储一些元数据信息，比如数据的起始位置、数据的长度、数据所在的节点等。它的划分方法由用户决定，一个split对应一个map task。</li>
</ol>
<h4 id="数据切片和Map-Task并行度"><a href="#数据切片和Map-Task并行度" class="headerlink" title="数据切片和Map Task并行度"></a>数据切片和Map Task并行度</h4><p>Split即数据切片，是逻辑存储，假设要切分130M的数据，数据块会将其切分为128M和2M使用两个数据块实现物理存储，想要切分为三片，需要记录 0-65、65-130的索引，这是数据切分的实现。切片的大小可以大于或小于一个数据块的大小，也可以等于一个数据块的大小，但是大于或小于数据块的时候，就比如刚刚的例子，将数据平分切片，就会涉及跨节点取数据的问题，效率肯定会比获取本地数据要低；如果按照数据块大小切片，在本地文件系统获取数据块，效率就会更高一些。切片不会考虑数据集整体，也就是如果有两个文件输入，不会将两个文件看成一个整体切分，而是每个文件单独切片。</p>
<p>具体切片的逻辑是：</p>
<p>首先需要获取 splitsize 一片的大小，涉及三个值：minsize默认1、maxsize默认Long类型的最大值和blocksize数据块的大小，依据max(minsize, min(maxsize, blocksize)) 的逻辑可以得到 一片的大小默认是数据块的大小，然后判断被切数据和splitsize的比值如果大于1.1，就切片，否则不再切片。</p>
<p>从这个逻辑可以看出，如果控制了 minsize 和 maxsize 的值，就可以控制切片的大小，如果想要调大切片修改 minsize，调小切片修改 maxsize。</p>
<h4 id="Job提交流程"><a href="#Job提交流程" class="headerlink" title="Job提交流程"></a>Job提交流程</h4><p>对待处理的文件进行切片划分，然后提交给RM，提交切片、jar包和job.xml，然后RM会让NM开启一个MrAppMaster。MrAppMaster启动之后计算Map Task的数量并开启对应的Map Task，进入Map Task阶段。</p>
<h4 id="Map-Task工作机制"><a href="#Map-Task工作机制" class="headerlink" title="Map Task工作机制"></a>Map Task工作机制</h4><h3 id="Yarn相关"><a href="#Yarn相关" class="headerlink" title="Yarn相关"></a>Yarn相关</h3><h4 id="组成架构-2"><a href="#组成架构-2" class="headerlink" title="组成架构"></a>组成架构</h4><p>Yarn使用主从架构，包含ResourceManager、NodeManager、ApplicationMaster和Container。</p>
<ol>
<li><p>ResourceManager</p>
<p>是全局资源管理器，负责整个系统资源的管理和分配，主要由两个组件构成：调度器和应用程序管理器。</p>
<p><strong>（1）调度器：</strong></p>
<p>​        仅负责资源的分配，分配的资源单位用抽象概念Container表示，它将CPU、网络、内存、磁盘等资源封装在一起，从而限定每个任务使用的资源量。</p>
<p><strong>（2）应用程序管理器：</strong></p>
<p>​        负责管理系统中所有的应用程序，包括程序的提交、与调度器协商资源启动ApplicationMaster、监控ApplicationMaster的状态并在它失败时重启等。</p>
</li>
<li><p>NodeManager：</p>
<p>是RM和AM之间的桥梁，管理单个节点上的资源，并处理来自AM和RM的请求，会定时向RM报告本节点的资源使用情况和各个Container的状态，也会接收来自AM启动或停止Container的请求。</p>
</li>
<li><p>ApplicationMaster：每个应用程序都会有一个ApplicationMaster，用于监控任务的状态和申请任务的资源。</p>
</li>
</ol>
<h4 id="调度器的种类"><a href="#调度器的种类" class="headerlink" title="调度器的种类"></a>调度器的种类</h4><p>调度器的种类有三种：</p>
<ol>
<li>FIFO调度器：所有作业被提交到一个队列中，然后先按照优先级高低、再按照作业提交时间选择被执行的作业。这种算法简单，但是如果前一个作业占用了全部的资源，会导致后面的任务一直无法处理。</li>
<li>计算能力调度器：是hadoop的默认调度器，支持多个队列，每个队列使用FIFO算法调度，计算能力调度器会给每个队列分配资源，为了防止同一用户的作业独占队列的所有资源，为每个用户提交的作业所占资源量进行限定，调度时，先计算每个队列正在运行的任务数与其应分得的计算资源直接的比值，选择比值小的队列，然后根据优先级和提交时间顺序从该队列调度一个作业。</li>
<li>公平调度器：也支持多个队列，尽可能保证所有作业都能获得等量的资源，系统中只有一个作业时，会独占所有资源，有其他作业提交时再将资源平分给其他任务。</li>
</ol>
<p><strong>计算能力调度器和公平调度器的比较：</strong></p>
<p>二者核心的区别在于，提交任务到队列中，是采用公平调度还是FIFO调度。对于公平调度器，因为能够尽量保证任务获得等量的资源，所以能够避免因为长时间运行大任务而阻塞小任务；但是计算能力调度器也可以针对不同的任务创建不同的队列，然后由任务提交者根据任务的特点提交到不同队列中，也可以实现和公平调度器一样的效果。</p>
<p>调度器的修改参数是 <code>yarn-site.xml</code> 中的 <code>yarn.resourcemanager.scheduler.class</code> 。</p>
<h4 id="Yarn具体的提交作业流程（工作流程）"><a href="#Yarn具体的提交作业流程（工作流程）" class="headerlink" title="Yarn具体的提交作业流程（工作流程）"></a>Yarn具体的提交作业流程（工作流程）</h4><ol>
<li>首先JobClient会向ResourceManager申请提交应用程序，包括AM程序、启动AM的命令、用户程序、环境变量等；</li>
<li>然后RM会为这个程序分配第一个Container，并和对应的NM通信，让它在这个Container上启动AM；</li>
<li>AM被启动后会首先向RM进行注册，目的是为了让用户能够随时查看应用程序的运行状态，然后AM会以轮询的方式向RM申请资源；</li>
<li>成功申请到资源之后，AM会和对应的NM通信，让它启动任务；</li>
<li>NM为任务配置好环境后，将启动任务的命令写入一个脚本，然后通过调用这个脚本来运行任务；</li>
<li>各个任务会向AM汇报自己的运行状态和进度，方便AM随时掌握这些信息，并在任务执行失败时能够及时为它重新申请资源；</li>
<li>等到所有任务执行完毕后，AM会向RM申请注销自己。</li>
</ol>
<h4 id="Yarn怎么保证高可用"><a href="#Yarn怎么保证高可用" class="headerlink" title="Yarn怎么保证高可用"></a>Yarn怎么保证高可用</h4><p>在hadoop2.4版本之前，Yarn框架的RM存在单点故障的问题，也就是如果RM挂掉了，恢复的时间会比较长，这就会导致正在运行的程序丢失，影响范围较大，所以从hadoop2.4版本开始，引入了RM高可用机制，典型的高可用集群中，默认会配置两个独立的ResourceManager，在任意时间，有且仅有一个RM处于运行状态，另一台处于待命状态，一旦运行状态的RM出现故障，就可以将待命状态的RM切换为运行状态继续执行任务。切换的方式可以是手动切换，也可以基于Zookeeper实现自动切换。</p>
<h2 id="1-MapReduce优化"><a href="#1-MapReduce优化" class="headerlink" title="1. MapReduce优化"></a>1. MapReduce优化</h2><h3 id="1-跑得慢的原因"><a href="#1-跑得慢的原因" class="headerlink" title="1. 跑得慢的原因"></a>1. 跑得慢的原因</h3><p>Mapreduce的瓶颈在于两点：</p>
<p>（1）计算机性能：CPU、内存、磁盘健康、网络等。</p>
<p>（2）I&#x2F;O操作：数据倾斜、Map和Reduce数设置不合理、Map运行时间太长导致Reduce等待过久、小文件过多、大量的不可分块的超大文件、spill次数过多、Merge次数过多等。</p>
<h3 id="2-具体的优化方法"><a href="#2-具体的优化方法" class="headerlink" title="2. 具体的优化方法"></a>2. 具体的优化方法</h3><p>主要从六个方面考虑：数据输入、Map阶段、Reduce阶段、IO传输、数据倾斜问题和常用的调优参数。</p>
<h4 id="1）数据输入"><a href="#1）数据输入" class="headerlink" title="1）数据输入"></a>1）数据输入</h4><p>（1）合并小文件：在执行MR任务前将小文件进行合并，大量的小文件会产生大量的Map任务，增大Map任务装载次数，而任务的装载比较耗时，从而导致MR运行较慢。</p>
<p>（2）采用CombineTextInputFormat来作为输入，解决输入端大量小文件场景。</p>
<h4 id="2）Map阶段"><a href="#2）Map阶段" class="headerlink" title="2）Map阶段"></a>2）Map阶段</h4><p>（1）减少溢写(Spill)次数：通过调整io.sort.mb及sort.spill.percent参数值，增大触发Spill的内存上限，减少Spill次数，从而减少磁盘IO。</p>
<p>（2）减少合并(Merge)次数：通过调整io.sort.factor参数，增大Merge的文件数目，减少Merge的次数，从而缩短MR处理时间。</p>
<p>（3）在Map之后，不影响业务逻辑前提下，先进行Conbine处理，减少IO。</p>
<h4 id="3）Reduce阶段"><a href="#3）Reduce阶段" class="headerlink" title="3）Reduce阶段"></a>3）Reduce阶段</h4><p>（1）合理设置Map和Reduce数：两个都不能设置太少，也不能设置太多。太少，会导致Task等待，延长处理时间；太多，会导致Map、Reduce任务间竞争资源，造成处理超时等错误。</p>
<p>（2）设置Map、Redce共存：调整slowstart.completedmaps参数，使Map运行到—定程度后，Recuce也开始运行，减少Reduce的等待时间。</p>
<p>（3）规避使用Reduce：因为Reduce在用于连接数据集的时候将会产生大量的网络消耗。</p>
<p>（4）合理设置Reduce端的Buffer：默认情况下，数据达到一个阈值的时候，Buffer中的数据就会写入磁盘，然后Recuce会从磁盘中获得所有的数据。也就是说，Buffer和Recuce是没有直接关联的，中间多次写磁盘-&gt;读磁盘的过程，既然有这个弊端，那么就可以通过参数来配置，使得Buffer中的一部分数据可以直接输送到Reduce，从而减少Io开销：mapreduce.reduce.input.buffer.percent，默认为0.0。当值大于0的时候，会保留指定比例的内存读Buffer中的数据直接拿给Recuce使用。但是这样一来，设置Buffer需要内存，读取数据需要内存，Recuce计算也要内存，所以要根据作业的运行情况进行调整。</p>
<h4 id="4）IO传输"><a href="#4）IO传输" class="headerlink" title="4）IO传输"></a>4）IO传输</h4><p>（1）采用数据压缩的方式，减少网络Io的的时间。安装Snappy和LZo压缩编码器。</p>
<p>（2）使用SequenceFile二进制文件。</p>
<h4 id="5）数据倾斜"><a href="#5）数据倾斜" class="headerlink" title="5）数据倾斜"></a>5）数据倾斜</h4><p><strong>（1）数据倾斜现象</strong><br>大量的相同key被分配到一个分区里，map &#x2F;reduce程序执行时，reduce节点大部分执行完毕，但是有一个或者几个reduce节点运行很慢，导致整个程序的处理时间很长。<br><strong>（2）减少数据倾斜的方法</strong></p>
<p>方法一：将不均匀的key值打散。</p>
<p>这种方式适用于绝大部分key对应10%的数据，而很少部分的key对应90%的数据。对于这种情况，可以给key值加上随机数，将数据量很大的key值打散到不同的reduce中计算。</p>
<p>方法二：使用map join代替 reduce join。</p>
<p>适用于小表join大表的情况。可以将小表放到内存，然后将map task的数据通过hash取余的方式选择小表中对应的key值，进行join操作。在map端的每个map task中完成join操作，后续就不需要进入reduce端处理了，能够避免shuffle过程，从而避免数据倾斜。</p>
<p>方法三：使用group by代替distinct。</p>
<p>在统计数量的时候经常会用到 <code>select count(distinct name)</code> ，这样会将name的key值全都shuffle到一个reduce中处理，很容易产生数据倾斜。采用group by+聚合函数的方式可以将数据根据key值分配到不同的reduce中，避免数据倾斜。</p>
<h4 id="6）常见的调优参数"><a href="#6）常见的调优参数" class="headerlink" title="6）常见的调优参数"></a>6）常见的调优参数</h4><p>mapreduce中比如有 <code>mapreduce.map.cpu.vcores</code> 设置每个MapTask可使用的最多cpu core数目，默认值: 1；</p>
<p>yarn中比如有 <code>yarn.scheduler.minimum-allocation-vcores </code> 设置每个Container申请的最小CPU核数，默认值：1；</p>
<p>shuffle中比如有 <code>mapreduce.map.sort.spill.percent</code> 设置环形缓冲区溢出的阈值，默认80%；</p>
<p>容错相关系数比如有 <code>mapreduce.map.maxattempts</code> 设置每个Map Task最大重试次数，一旦重试参数超过该值，则认为Map Task运行失败，默认值：4。</p>
<h2 id="4-Map-Join-和-Reduce-Join"><a href="#4-Map-Join-和-Reduce-Join" class="headerlink" title="4. Map Join 和 Reduce Join"></a>4. Map Join 和 Reduce Join</h2><p>reduce join是在map阶段完成数据的标记，在reduce阶段完成数据的合并；</p>
<p>map join是直接在map阶段完成数据的合并，没有reduce阶段。</p>
<p>Reduce Join的缺陷：</p>
<p>1、合并的任务在reduce端执行，reduce端处理压力大，而map端负载很低，资源利用率不高。<br>2、容易产生数据倾斜。</p>
<p>Map Join没有reduce过程，所有的工作都在map阶段完成，极大减少了网络传输和io的代价。它适用于一张小表和一张大表进行join操作。</p>
<h2 id="5-Hadoop组成架构"><a href="#5-Hadoop组成架构" class="headerlink" title="5. Hadoop组成架构"></a>5. <strong>Hadoop组成架构</strong></h2><ol>
<li><p>版本区别：</p>
<p>1.x包括辅助工具、hdfs数据存储、mapreduce进行计算和资源调度；</p>
<p>2.x与1.x版本大致相同，唯一的区别在于将mapreduce的任务一分为二，mapreduce继续负责进行计算，资源调度由yarn负责；</p>
<p>3.x版本在组成上与2.x版本没有区别。</p>
</li>
<li><p>hdfs组成：</p>
<p>（1） NameNode(m)：存储文件的元数据，如文件名，文件目录结构，文件属性（生成时间、副本数、文件权限），以及每个文件的块列表和块所在的DataNode等。</p>
<p>（2）DataNode(dn)：在本地文件系统存储文件块数据，以及块数据的校验和。</p>
<p>（3）Secondary NameNode(2nn)：用来监控HDFS状态的辅助后台程序，每隔一段时间从namenode对元数据进行备份。</p>
</li>
<li><p>yarn组成：</p>
<p>YARN 主要由 ResourceManager、NodeManager、ApplicationMaster 和 Container 等组件构成。</p>
<p>1）ResourceManager ( RM )主要作用如下：<br>（1）处理客户端请求；</p>
<p>（2）监控NodeManager；</p>
<p>（3）启动或监控ApplicationMaster；</p>
<p>（4）资源的分配与调度。</p>
<p>2）NodeManager ( NM）主要作用如下：<br>（1）管理单个节点上的资源；</p>
<p>（2）处理来自ResourceManager的命令；</p>
<p>（3）处理来自ApplicationMaster的命令。</p>
<p>3）ApplicationMaster ( AM )作用如下：<br>（1）负责数据的切分；</p>
<p>（2）为应用程序申请资源并分配给内部的任务；</p>
<p>（3）任务的监控与容错。</p>
<p>4）Container<br>Container是YARN中的资源抽象，它封装了某个节点上的多维度资源，如内存、CPu、磁盘网络等。</p>
</li>
<li><p>mr组成</p>
<p>Hadoop MapReduce采用Master&#x2F;Slave（M&#x2F;S）架构，主要包括以下组件：Client、JobTracker、TaskTracker和Task。</p>
<p>（1）Client<br>  用户编写的MapReduce程序通过Client提交到JobTracker端；同时，用户可通过Client提供的一些接口查看作业运行状态。在Hadoop内部用“作业”（Job）表示MapReduce程序。一个MapReduce程序可对应若干个作业，而每个作业会被分解成若干个Map&#x2F;Reduce任务（Task）。</p>
<p>(2)JobTracker的主要功能：<br>  负责作业的分解和状态监控。 最重要的是状态监控：主要包括TaskTracker状态监控、作业状态监控和任务状态监控。主要作用：容错和为任务调度提供决策依据。</p>
<p>（3）TaskTracker：<br>  与JobTarcker保持通信，执行JobTracker分配的任务，监控节点健康情况、资源使用情况以及任务执行进度、任务运行状态等。</p>
<p>（4）Task<br>  Task分为Map Task和Reduce Task两种，均由TaskTracker启动。我们知道，HDFS以固定大小的block为基本单位存储数据，而对于MapReduce而言，其处理单位是split。split是一个逻辑概念，它只包含一些元数据信息，比如数据起始位置、数据长度、数据所在节点等。它的划分方法完全由用户自己决定。但需要注意的是，split的多少决定Map Task的数目，因为每个split会交由一个Map Task处理。</p>
</li>
<li><p>三者关系的简述</p>
<p>客户端将任务提交到RM，RM到某个NM下启动一个container，并在该container内放置传输的AM；接着AM向RM申请资源，RM返回相应的资源列表，然后AM启动这些对应的资源，这些资源在对应的DN上处理相应的任务，这部分称为maptask，maptask处理完后，将所有maptask的结果传输到reduce端执行，最终将reduce端的结果对应的元数据信息传输到namenode中；2NN会每隔一段时间对NM的元数据进行备份。</p>
</li>
</ol>
<h3 id="9-请简述mapreduce中的combine、partition和shuffle的作用。"><a href="#9-请简述mapreduce中的combine、partition和shuffle的作用。" class="headerlink" title="9. 请简述mapreduce中的combine、partition和shuffle的作用。"></a>9. <strong>请简述mapreduce中的combine、partition和shuffle的作用。</strong></h3><ol>
<li><p>combine</p>
<p>​        combine分为map端和reduce端，作用是把同一个key的键值对合并在一起，可以自定义的。<br>​        combine函数把一个map函数产生的&lt;key,value&gt;对（多个key,value）合并成一个新的&lt;key2,value2&gt;.将新的&lt;key2,value2&gt;作为输入到reduce函数中，这个value2亦可称之为values，因为有多个。</p>
<p>​        这个合并的目的是为了减少网络传输。</p>
</li>
<li><p>partition</p>
<p>​        partition是分割map每个节点的结果，按照key分别映射给不同的reduce，也是可以自定义的。这里其实可以理解归类。<br>​        我们对于错综复杂的数据归类。比如在动物园里有牛羊鸡鸭鹅，他们都是混在一起的，但是到了晚上他们就各自牛回牛棚，羊回羊圈，鸡回鸡窝。partition的作用就是把这些数据归类。</p>
</li>
<li><p>shuffle</p>
<p>​        shuffle就是map和reduce之间的过程，包含了两端的combine和partition。</p>
<p>​        Map的结果，会通过partition分发到Reducer上，Reducer做完Reduce操作后，通过OutputFormat，进行输出；</p>
<p>​        shuffle阶段的主要函数是fetchOutputs(),这个函数的功能就是将map阶段的输出，copy到reduce 节点本地。</p>
</li>
</ol>
<h3 id="11-MapTask工作机制"><a href="#11-MapTask工作机制" class="headerlink" title="11. MapTask工作机制"></a>11. <strong>MapTask工作机制</strong></h3><p>分为5个阶段：</p>
<p>Read阶段：<br>通过InputFormat调用RecorderReader的reader()方法读取数据，默认使用TextInputFormat，其中 k 对应偏移量，v对应一行内容。</p>
<p>Map阶段：<br>将读取的数据返回给Map，并进入用户写的Mapper逻辑。</p>
<p>Collect阶段：</p>
<p>Mapper阶段的数据会输出到环形缓冲区，默认大小100M，其中所有的数据都是按照分区存储，存储的数据到达80%的阈值后反向溢写，一些之前会进行分区内的快速排序。</p>
<p>溢写阶段：<br>从环形缓冲区不断溢出到本地磁盘文件；</p>
<p>Merge阶段：<br>可能会溢出多个文件（分区且区内有序），多个溢出文件会被合并（归并排序）成大的溢出文件，在溢出过程及合并的过程中，都要调用Partitioner进行分区和针对key进行排序。</p>
<h3 id="12-ReduceTask工作机制"><a href="#12-ReduceTask工作机制" class="headerlink" title="12. ReduceTask工作机制"></a>12. <strong>ReduceTask工作机制</strong></h3><p>包括4个阶段。</p>
<p>Copy阶段：<br>MapTask结束后，Reduce Task需要拷贝根据自己的分区号对应Map Task机器上的结果分区数据；</p>
<p>Merge阶段：<br>Reduce Task会取到同一个分区的来自不同MapTask的结果文件，Reduce Task会将这些文件再进行合并；</p>
<p>Sort阶段：<br>使用归并排序方法合并文件，合并成大文件后（到这里Shuffle过程结束），将相同key的数据拷贝到一个reduce方法里面去；</p>
<p>Reduce阶段：<br>进入Reduce Task进行逻辑运算（从文件中取出一个一个的键值对Group，调用用户自定义的reduce()方法）；</p>
<p>最后默认通过TextOutputFormat输出数据。</p>
<h3 id="14-ETL的几个过程分别是什么？"><a href="#14-ETL的几个过程分别是什么？" class="headerlink" title="14. ETL的几个过程分别是什么？"></a>14. <strong>ETL的几个过程分别是什么？</strong></h3><p>ETL是Extract Transform Load三个英文单词的缩写，中文意思就是抽取、转换、加载。说到ETL就必须提到数据仓库，ETL负责完成数据从数据源向目标数据仓库转化的过程，是实施数据仓库的重要步骤。<br>构建数据仓库的核心是建模，在数据仓库的构建中，ETL贯穿于项目始终，它是整个数据仓库的生命线。从数据源中抽取数据，然后对这些数据进行转化，最终加载到目标数据库或者数据仓库中去，这就是ETL 过程。<br>通常数据抽取工作分抽取、清洗、转换、装载几个步骤：</p>
<p>抽取主要是针对各个业务系统及不同服务器的分散数据，充分理解数据定义后，规划需要的数据源及数据定义，制定可操作的数据源，制定增量抽取和缓慢渐变的规则。</p>
<p>清洗主要是针对系统的各个环节可能出现的数据二义性、重复、不完整、违反业务规则等数据质量问题，允许通过数据抽取设定的数据质量规则，将有问题的记录先剔除出来，根据实际情况调整相应的清洗操作。</p>
<p>转换主要是针对数据仓库建立的模型，通过一系列的转换来实现将数据从业务模型到分析模型，通过ETL工具可视化拖拽操作可以直接使用标准的内置代码片段功能、自定义脚本、函数、存储过程以及其他的扩展方式，实现了各种复杂的转换，并且支持自动分析日志，清楚的监控数据转换的状态并优化分析模型。</p>
<p>装载主要是将经过转换的数据装载到数据仓库里面，可以通过直连数据库的方式来进行数据装载，可以充分体现高效性。在应用的时候可以随时调整数据抽取工作的运行方式，可以灵活的集成到其他管理系统中。</p>
<h3 id="15-hadoop的二级排序"><a href="#15-hadoop的二级排序" class="headerlink" title="15. hadoop的二级排序"></a>15. hadoop的二级排序</h3><p>即对key和value双排序。默认情况下，Map输出的结果会对Key进行默认的排序，但是有时候需要对Key排序的同时还需要对Value进行排序，这时候就要用到二次排序了。<br>有两种方法进行二次排序，分别为：buffer and in memory sort和 value-to-key conversion。<br>1、buffer and in memory sort<br>在reduce()函数中，将某个key对应的所有value保存到内存中，然后进行排序。 这种方法最大的缺点是：可能会造成out of memory。<br>2、value-to-key conversion<br>MapReduce程序中，Mapper输出的键值对会经历shuffle过程再交给 Reducer。在shuffle阶段，Mapper输出的键值对会经过partition(分区)-&gt;sort(排序)-&gt;group(分组) 三个阶段。<br>将key和部分value拼接成一个组合key，这样reduce获取的结果便是先按key排序，后按value排序的结果，需要注意的是，用户需 要自己实现Paritioner，以便只按照key进行数据划分。Hadoop显式的支持二次排序，在Configuration类中有setSotComparatorClass()方法可以对key值进行处理，setGroupingComparatorClass()方法对相同key的value值进行处理。<br>shuffle 的 sort 过程会根据键值对&lt;key, value&gt;的 key 进行排序，但是二次排序中，value 也是需要排序的字段。因此需要将 value 字段合并到 key 中作为新的 key，形成新的键值对&lt;key#value, value&gt;。在排序时使其先根据 key 排序，如果相同，再根据 value 排序。</p>
<h3 id="18-shuffle过程详解"><a href="#18-shuffle过程详解" class="headerlink" title="18. shuffle过程详解"></a>18. shuffle过程详解</h3><p>Shuffle横跨Map端和Reduce端，在Map端包括Spill过程，Reduce端包括copy、merge、sort过程。<br>（1）Map端<br>当map task开始运算，并产生中间数据时，其产生的中间结果不会简单的写入磁盘，而是利用内存buffer来进行已经产生的部分结果的缓存，并在内存buffer中进行一些预排序来优化整个map的性能。每个map都会对应存在一个内存buffer中，map会将产生的部分结果先写入对应buffer。该buffer默认大小为100MB，可以根据job提交的参数 - io.sort.mb 调整。<br>当map产生的数据量非常大，如将io.sort.mb调大，那么map在整个计算过程中spill的次数就会降低，map task对磁盘的操作会减少，如果map task的瓶颈在磁盘上，这样调整就能大大提升map的性能。<br>Spill的过程包括collect、sort、spill、merge。<br><strong>collect：</strong> 每个map task不断地以键值对的形式把数据输出到在内存中构造的一个环形数据结构中，这种结构，即看kvbuffer，是为了更有效地利用内存空间来存储数据。默认当存储到内存的80%，就会将内存中的数据刷到磁盘上，接着再往内存中存储，这个过程就是spill；<br>sort：先将kvbuffer中的数据按照partition值和key升序排序，（移动的只是索引数据），排序结果是，kvbuffer中数据按照partition排序，同一partition内按照key排序；<br><strong>spill：</strong> spill线程为spill过程创建一个磁盘文件，然后根据排过序的kvbuffer依次将partition写入这个文件，直到把所有文件遍历完，一个partition在文件中对应的数据也叫段。每一次spill过程至少生成一个out文件；<br><strong>merge：</strong> Map任务如果输出数据很大，可能会进行多次spill，相应的磁盘文件也会很多，最后由merge把这些文件进行合并。<br>（2）Reduce端<br><strong>copy：</strong> 由于Job上的每一个map都会根据reduce数将输出结果分成同等数量的partition，让reduce task可以从不同的已完成的map上下载该reduce对应的partition部分数据，由于map通常有多个，所以对于一个reduce来说，下载也可以是并行的从多个map选择，这些数据默认会保存在内存的缓冲区，等达到阈值才溢出到磁盘；<br><strong>merge：**在**copy**的同时，会在后台开启两个线程 - 内存到磁盘的合并、磁盘到磁盘的合并，对内存到本地磁盘的数据文件进行合并；<br><strong>sort：**在**merge**的同时，会进行排序操作，由于map task阶段已经进行了局部排序，reduce task只需要保证</strong>copy</strong>的数据最终整体有效就行。</p>

    </div>

    
    
    
	  
	
	 <div>
		<div>
    
        <div style="text-align:center;color: #ccc;font-size:24px;">-------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------</div>
    
</div>
	 </div>
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/hadoop/" rel="tag"># hadoop</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2021/07/29/SQL-%E6%8A%A5%E9%94%99/" rel="prev" title="SQL - 报错">
      <i class="fa fa-chevron-left"></i> SQL - 报错
    </a></div>
      <div class="post-nav-item">
    <a href="/2021/08/06/hive-%E6%8A%A5%E9%94%99/" rel="next" title="hive - 报错">
      hive - 报错 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#hadoop%E8%A7%A3%E5%86%B3%E5%93%AA%E4%BA%9B%E9%97%AE%E9%A2%98%EF%BC%8C%E6%9C%89%E5%93%AA%E4%BA%9B%E7%89%B9%E6%80%A7"><span class="nav-number">1.</span> <span class="nav-text">hadoop解决哪些问题，有哪些特性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#hadoop%E7%9A%84%E7%89%88%E6%9C%AC%E5%8C%BA%E5%88%AB"><span class="nav-number">2.</span> <span class="nav-text">hadoop的版本区别</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B8%B8%E7%94%A8%E7%AB%AF%E5%8F%A3%E5%8F%B7"><span class="nav-number">3.</span> <span class="nav-text">常用端口号</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B8%B8%E7%94%A8%E7%9A%84%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="nav-number">4.</span> <span class="nav-text">常用的配置文件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HDFS%E7%9B%B8%E5%85%B3"><span class="nav-number">5.</span> <span class="nav-text">HDFS相关</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%BB%84%E6%88%90%E6%9E%B6%E6%9E%84"><span class="nav-number">5.1.</span> <span class="nav-text">组成架构</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9C%BA%E6%9E%B6%E6%84%9F%E7%9F%A5%E6%9C%BA%E5%88%B6%EF%BC%88%E5%89%AF%E6%9C%AC%E8%8A%82%E7%82%B9%E7%9A%84%E9%80%89%E6%8B%A9%EF%BC%89"><span class="nav-number">5.2.</span> <span class="nav-text">机架感知机制（副本节点的选择）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#NameNode%E5%92%8CSecondaryNameNode%E8%BF%90%E8%A1%8C%E6%9C%BA%E5%88%B6"><span class="nav-number">5.3.</span> <span class="nav-text">NameNode和SecondaryNameNode运行机制</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#HDFS%E4%B8%AD%E5%B0%8F%E6%96%87%E4%BB%B6%E7%9A%84%E5%A4%84%E7%90%86"><span class="nav-number">5.4.</span> <span class="nav-text">HDFS中小文件的处理</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#HDFS%E7%9A%84%E8%AF%BB%E5%86%99%E8%BF%87%E7%A8%8B"><span class="nav-number">5.5.</span> <span class="nav-text">HDFS的读写过程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E6%95%B0%E6%8D%AE%E5%9D%97%E4%B8%8D%E8%83%BD%E8%AE%BE%E7%BD%AE%E5%A4%AA%E5%B0%8F%E4%B9%9F%E4%B8%8D%E8%83%BD%E8%AE%BE%E7%BD%AE%E5%A4%AA%E5%A4%A7"><span class="nav-number">5.6.</span> <span class="nav-text">为什么数据块不能设置太小也不能设置太大</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#HDFS%E5%AE%9E%E7%8E%B0%E9%AB%98%E5%8F%AF%E7%94%A8"><span class="nav-number">5.7.</span> <span class="nav-text">HDFS实现高可用</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MapReduce%E7%9B%B8%E5%85%B3"><span class="nav-number">6.</span> <span class="nav-text">MapReduce相关</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%BB%84%E6%88%90%E6%9E%B6%E6%9E%84-1"><span class="nav-number">6.1.</span> <span class="nav-text">组成架构</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%88%87%E7%89%87%E5%92%8CMap-Task%E5%B9%B6%E8%A1%8C%E5%BA%A6"><span class="nav-number">6.2.</span> <span class="nav-text">数据切片和Map Task并行度</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Job%E6%8F%90%E4%BA%A4%E6%B5%81%E7%A8%8B"><span class="nav-number">6.3.</span> <span class="nav-text">Job提交流程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Map-Task%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6"><span class="nav-number">6.4.</span> <span class="nav-text">Map Task工作机制</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Yarn%E7%9B%B8%E5%85%B3"><span class="nav-number">7.</span> <span class="nav-text">Yarn相关</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%BB%84%E6%88%90%E6%9E%B6%E6%9E%84-2"><span class="nav-number">7.1.</span> <span class="nav-text">组成架构</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%B0%83%E5%BA%A6%E5%99%A8%E7%9A%84%E7%A7%8D%E7%B1%BB"><span class="nav-number">7.2.</span> <span class="nav-text">调度器的种类</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Yarn%E5%85%B7%E4%BD%93%E7%9A%84%E6%8F%90%E4%BA%A4%E4%BD%9C%E4%B8%9A%E6%B5%81%E7%A8%8B%EF%BC%88%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B%EF%BC%89"><span class="nav-number">7.3.</span> <span class="nav-text">Yarn具体的提交作业流程（工作流程）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Yarn%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81%E9%AB%98%E5%8F%AF%E7%94%A8"><span class="nav-number">7.4.</span> <span class="nav-text">Yarn怎么保证高可用</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-MapReduce%E4%BC%98%E5%8C%96"><span class="nav-number"></span> <span class="nav-text">1. MapReduce优化</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-%E8%B7%91%E5%BE%97%E6%85%A2%E7%9A%84%E5%8E%9F%E5%9B%A0"><span class="nav-number">1.</span> <span class="nav-text">1. 跑得慢的原因</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-%E5%85%B7%E4%BD%93%E7%9A%84%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95"><span class="nav-number">2.</span> <span class="nav-text">2. 具体的优化方法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1%EF%BC%89%E6%95%B0%E6%8D%AE%E8%BE%93%E5%85%A5"><span class="nav-number">2.1.</span> <span class="nav-text">1）数据输入</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2%EF%BC%89Map%E9%98%B6%E6%AE%B5"><span class="nav-number">2.2.</span> <span class="nav-text">2）Map阶段</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3%EF%BC%89Reduce%E9%98%B6%E6%AE%B5"><span class="nav-number">2.3.</span> <span class="nav-text">3）Reduce阶段</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4%EF%BC%89IO%E4%BC%A0%E8%BE%93"><span class="nav-number">2.4.</span> <span class="nav-text">4）IO传输</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5%EF%BC%89%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C"><span class="nav-number">2.5.</span> <span class="nav-text">5）数据倾斜</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6%EF%BC%89%E5%B8%B8%E8%A7%81%E7%9A%84%E8%B0%83%E4%BC%98%E5%8F%82%E6%95%B0"><span class="nav-number">2.6.</span> <span class="nav-text">6）常见的调优参数</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-Map-Join-%E5%92%8C-Reduce-Join"><span class="nav-number"></span> <span class="nav-text">4. Map Join 和 Reduce Join</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-Hadoop%E7%BB%84%E6%88%90%E6%9E%B6%E6%9E%84"><span class="nav-number"></span> <span class="nav-text">5. Hadoop组成架构</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#9-%E8%AF%B7%E7%AE%80%E8%BF%B0mapreduce%E4%B8%AD%E7%9A%84combine%E3%80%81partition%E5%92%8Cshuffle%E7%9A%84%E4%BD%9C%E7%94%A8%E3%80%82"><span class="nav-number">1.</span> <span class="nav-text">9. 请简述mapreduce中的combine、partition和shuffle的作用。</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#11-MapTask%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6"><span class="nav-number">2.</span> <span class="nav-text">11. MapTask工作机制</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#12-ReduceTask%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6"><span class="nav-number">3.</span> <span class="nav-text">12. ReduceTask工作机制</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#14-ETL%E7%9A%84%E5%87%A0%E4%B8%AA%E8%BF%87%E7%A8%8B%E5%88%86%E5%88%AB%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="nav-number">4.</span> <span class="nav-text">14. ETL的几个过程分别是什么？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#15-hadoop%E7%9A%84%E4%BA%8C%E7%BA%A7%E6%8E%92%E5%BA%8F"><span class="nav-number">5.</span> <span class="nav-text">15. hadoop的二级排序</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#18-shuffle%E8%BF%87%E7%A8%8B%E8%AF%A6%E8%A7%A3"><span class="nav-number">6.</span> <span class="nav-text">18. shuffle过程详解</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Bonnie"
      src="/images/avatar.gif">
  <p class="site-author-name" itemprop="name">Bonnie</p>
  <div class="site-description" itemprop="description">每天都要做个人啊</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">102</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">62</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2021-05 – 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Bonnie</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

  

</body>
</html>
