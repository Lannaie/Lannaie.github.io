<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="hadoop解决哪些问题，有哪些特性 主要用于解决海量数据的存储和分析计算的问题。  特性有如下四个： （1）高可靠性：hadoop底层维护多个数据副本，即使某个节点的计算出现问题或存储出现故障，数据也不会丢失； （2）高扩展性：天然支持分布式，可以方便地扩展出几千个节点； （3）高效性：在mapreduce的思想中，hadoop是并行工作的，这就提高了任务的处理效率； （4）高容错性：可以自动将">
<meta property="og:type" content="article">
<meta property="og:title" content="hadoop - 面试题">
<meta property="og:url" content="http://example.com/2021/08/03/hadoop-%E9%9D%A2%E8%AF%95%E9%A2%98/index.html">
<meta property="og:site_name" content="往南">
<meta property="og:description" content="hadoop解决哪些问题，有哪些特性 主要用于解决海量数据的存储和分析计算的问题。  特性有如下四个： （1）高可靠性：hadoop底层维护多个数据副本，即使某个节点的计算出现问题或存储出现故障，数据也不会丢失； （2）高扩展性：天然支持分布式，可以方便地扩展出几千个节点； （3）高效性：在mapreduce的思想中，hadoop是并行工作的，这就提高了任务的处理效率； （4）高容错性：可以自动将">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2021-08-03T14:41:25.000Z">
<meta property="article:modified_time" content="2022-03-14T07:56:59.850Z">
<meta property="article:author" content="Bonnie">
<meta property="article:tag" content="hadoop">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/2021/08/03/hadoop-%E9%9D%A2%E8%AF%95%E9%A2%98/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>hadoop - 面试题 | 往南</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">往南</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-resources">

    <a href="/resources/" rel="section"><i class="download fa-fw"></i>资源</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/08/03/hadoop-%E9%9D%A2%E8%AF%95%E9%A2%98/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Bonnie">
      <meta itemprop="description" content="每天都要做个人啊">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="往南">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          hadoop - 面试题
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-08-03 22:41:25" itemprop="dateCreated datePublished" datetime="2021-08-03T22:41:25+08:00">2021-08-03</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-03-14 15:56:59" itemprop="dateModified" datetime="2022-03-14T15:56:59+08:00">2022-03-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E9%9D%A2%E8%AF%95%E9%A2%98/" itemprop="url" rel="index"><span itemprop="name">面试题</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h3 id="hadoop解决哪些问题，有哪些特性"><a href="#hadoop解决哪些问题，有哪些特性" class="headerlink" title="hadoop解决哪些问题，有哪些特性"></a>hadoop解决哪些问题，有哪些特性</h3><ol>
<li><p>主要用于解决海量数据的存储和分析计算的问题。</p>
</li>
<li><p>特性有如下四个：</p>
<p>（1）高可靠性：hadoop底层维护多个数据副本，即使某个节点的计算出现问题或存储出现故障，数据也不会丢失；</p>
<p>（2）高扩展性：天然支持分布式，可以方便地扩展出几千个节点；</p>
<p>（3）高效性：在mapreduce的思想中，hadoop是并行工作的，这就提高了任务的处理效率；</p>
<p>（4）高容错性：可以自动将运行失败的任务重新分配到新的节点运行。</p>
</li>
</ol>
<span id="more"></span>

<h3 id="hadoop的版本区别"><a href="#hadoop的版本区别" class="headerlink" title="hadoop的版本区别"></a>hadoop的版本区别</h3><p>1.x的版本包含辅助工具，hdfs和mapreduce。其中hdfs负责数据存储，mapreduce负责数据计算和资源调度。</p>
<p>2.x的版本与1.x版本大致相同，唯一的区别在于将mapreduce的任务一分为二，mapreduce继续负责数据的运算，将资源调度的任务分配给yarn框架。</p>
<h3 id="常用端口号"><a href="#常用端口号" class="headerlink" title="常用端口号"></a>常用端口号</h3><p>hadoop2：</p>
<ol>
<li>HDFS NameNode内部通信端口：8020、9000；</li>
<li>HDFS NameNode的用户查询端口：50070；</li>
<li>Yarn查询任务运行情况端口：8080；</li>
<li>查看历史服务器：19888.</li>
</ol>
<p>hadoop3：</p>
<ol>
<li>NameNode内部通信端口：8020、9000、9820；</li>
<li>NameNode对用户开放的查询端口：9870；</li>
<li>Yarn查询任务运行情况端口：8080；</li>
<li>查看历史服务器端口：19888.</li>
</ol>
<h3 id="常用的配置文件"><a href="#常用的配置文件" class="headerlink" title="常用的配置文件"></a>常用的配置文件</h3><p>2.x：hdfs-site.xml、mapred-site.xml、yarn-site.xml、core-site.xml、slaves；</p>
<p>3.x：hdfs-site.xml、mapred-site.xml、core-site.xml、yarn-site.xml、workers。</p>
<h3 id="HDFS相关"><a href="#HDFS相关" class="headerlink" title="HDFS相关"></a>HDFS相关</h3><h4 id="组成架构"><a href="#组成架构" class="headerlink" title="组成架构"></a>组成架构</h4><ol>
<li>NameNode：用于存储文件的元数据，比如文件名、文件目录结构、文件的块列表以及块所在的datanode等，并处理客户端的读写请求。</li>
<li>DataNode：存储实际的数据块，并执行数据块的读写操作。</li>
<li>SecondaryNameNode：它不是NameNode的热备，不能在NameNode挂掉时进行替换，而是辅助NameNode，分担其工作量，比如定期合并fsimage和edits，在NameNode挂掉时辅助恢复NameNode。</li>
</ol>
<h4 id="机架感知机制（副本节点的选择）"><a href="#机架感知机制（副本节点的选择）" class="headerlink" title="机架感知机制（副本节点的选择）"></a>机架感知机制（副本节点的选择）</h4><p>默认情况下是三个副本，可以通过dfs.replication参数修改副本数。该参数的范围是1-16，修改后需要重启hdfs。</p>
<p>默认三个副本的情况下，第一个副本存储在客户端所在的节点上 <code>localstorage</code>，如果客户端不在集群中，就任意选择一个；第二个副本保存在和第一副本不同机架的节点上 <code>chooseremoterack</code>；第三个副本保存在与第二个副本相同的机架的不同节点中，会先判断前两个副本是否在一个机架，为了保证数据的可靠性，副本需要存储在至少两个机架上；如果前两个副本不在同一机架，就将该副本存到第二副本相同机架的不同节点上，因为在保证可靠性的同时，也需要兼顾效率，同一机架的效率比跨机架的效率要高一些。</p>
<h4 id="NameNode和SecondaryNameNode运行机制（NameNode的容错机制）"><a href="#NameNode和SecondaryNameNode运行机制（NameNode的容错机制）" class="headerlink" title="NameNode和SecondaryNameNode运行机制（NameNode的容错机制）"></a>NameNode和SecondaryNameNode运行机制（NameNode的容错机制）</h4><p>​        首先已知元数据信息被存储在NameNode节点的磁盘中，因此如果频繁的进行读写请求，会导致NameNode的处理效率变低。但是如果将其存储在内存中，那么一旦出现断电，元数据会因为无法及时保存到磁盘而导致数据丢失。于是引入了fsimage，将元数据存储在内存，并备份到磁盘的fsimage中。</p>
<p>​        但是这里又会出现一个新的问题：如果将元数据保存到内存的时候，同步备份到fsimage，同样会造成NameNode的效率变低；但如果不同步进行，一旦出现断电等情况，内存中的元数据依然会丢失。于是又引入了edits文件。edits只执行追加操作，将数据的变更操作写入edits，这样断电重启的时候就可以直接合并，形成完整的元数据信息。</p>
<p>​        但是这种合并需要定期执行，否则edits的数据量过大也会导致执行效率变低。如果使用NameNode负责定期合并的操作，会加大NameNode的处理压力，所以引入了SecondaryNameNode来执行定期合并的操作。它的定期将fsimage和edits文件合并生成一个新的fsimage.chkpoint文件，然后拷贝到NameNode中，NameNode会将其重命名为fsimage。</p>
<h4 id="HDFS中小文件的处理"><a href="#HDFS中小文件的处理" class="headerlink" title="HDFS中小文件的处理"></a>HDFS中小文件的处理</h4><ol>
<li><p>小文件的影响：因为一个文件不管在磁盘中多大，在HDFS中至少会占用一个数据块存储，如果一个文件的大小为1M，那么存储到数据块中，这个块的其余127M空间都不能再被使用。并且，存储大量小文件，会占用NameNode的大部分内存，甚至会耗尽内存。</p>
</li>
<li><p>解决的方法：</p>
<p>（1）har文件：将多个小文件打包为一个har文件，在HDFS中只会存储这个har文件的元数据信息，但是实际操作中，允许对里面的文件进行透明访问，大致的访问过程是先访问文件的索引数据，然后再定位实际的数据，这种方式会比直接访问hdfs文件的速度要慢一些；</p>
<p>（2）sequencefile：将文件名作为key，文件内容作为value存储，可以将多个kv形式的文件合并为一个大文件进行存储，这种方式读取数据比较方便，并且不限制数目，但是不能执行追加操作，适用于一次写入大量小文件的场景；</p>
<p>（3）CombineTextInputFormat：是新的InputFormat的格式，可以将多个小文件从逻辑上划分到一个切片中，但是这种方式不能区分输入的来源。</p>
</li>
</ol>
<h4 id="HDFS的读写过程"><a href="#HDFS的读写过程" class="headerlink" title="HDFS的读写过程"></a>HDFS的读写过程</h4><ol>
<li>写过程：</li>
</ol>
<p>（1）客户端首先创建一个分布式文件系统，向NameNode请求上传文件，NameNode检查这个客户端是否上传的权限以及目标文件路径是否存在，如果有权限且不存在这个路径，就返回可以上传的响应；</p>
<p>（2）分布式文件系统接着向NameNode询问第一个block要上传到哪个DataNode中，NameNode会返回三个DataNode：dn1、dn2和dn3；</p>
<p>（3）然后客户端会创建一个FSDataOutputStream对象，先向dn1请求建立传输通道，dn1将请求传给dn2，dn2传给dn3，等到没有datanode，开始往回响应，此时通道建立完毕；</p>
<p>（4）传输之前，数据会先放到一个缓冲队列，在缓冲队列中，首先以chunk为单位接收数据，一个chunk应该有一个512字节的数据和4字节的校验位，接着这些chunk会形成一个个64k的packet；</p>
<p>（5）输出流以packet为单位将数据传输到dn1，dn1接收完后再传给dn2，dn再传给dn3；</p>
<p>（6）输出流在发送packet的同时，会创建一个ack队列，这个队列主要用于接收是否应答成功，确保数据是在应答成功后才会删除，如果没有应答成功，ack队列会将数据再放回缓冲队列中等待再次传输；</p>
<p>（7）输出流发送的数据先由dn1接收，接收后会向dn2发送，然后dn2向dn3发送，等到dn3接收完毕会向dn2发回应答成功的响应，dn2向dn1发回响应，dn1返回给流对象，流对象接收到响应后才会删除ack队列的数据。</p>
<ol start="2">
<li>读过程：</li>
</ol>
<p>（1）客户端创建一个分布式文件系统对象，由这个对象向NameNode请求下载文件，NameNode先判断这个对象是否有权限查看文件，再判断是否存在这个文件，然后将文件的元数据返回给对象；</p>
<p>（2）客户端会创建一个fsdatainputstream对象，这个对象会依据先就近再随机的原则选择一个DataNode，请求读取数据，但是如果一直使用这个datanode，它的负载就会很高，所以在考虑就近的基础上，还会考虑负载情况来选择datanode读取；</p>
<p>（3）block之间会以串行的形式读取给客户端。</p>
<h4 id="为什么数据块不能设置太小也不能设置太大"><a href="#为什么数据块不能设置太小也不能设置太大" class="headerlink" title="为什么数据块不能设置太小也不能设置太大"></a>为什么数据块不能设置太小也不能设置太大</h4><p>HDFS文件在物理上是分块存储的，块的大小可以通过dfs.blocksize调整。默认情况下，hadoop1的块大小是64M，hadoop2的块大小是128M。</p>
<p>（1）如果设置太小，会增加寻址时间，并且每个块都会在NameNode中存储元数据，也会增大NameNode的开销；</p>
<p>（2）如果设置太大，以至于从磁盘获取数据的时间明显大于定位这个块开始位置的时间，会导致程序处理这块数据会非常慢。</p>
<h4 id="HDFS实现高可用"><a href="#HDFS实现高可用" class="headerlink" title="HDFS实现高可用"></a>HDFS实现高可用</h4><p>​        同时启动2个NameNode，一个处于活动状态，一个处于随时待命状态。这样可以保证运行状态的NameNode出现故障的时候，可以在数据不丢失的情况下，手动或自动将待命的NameNode切换到活动状态继续执行。</p>
<p>​        为了使两个NameNode保持同步，两个NameNode会与一组名为JournalNode的守护程序进行通信。当活动的NameNode修改命名空间时，会定期将执行的操作记录到editlog中，并写入JN的多数节点，比如写入 2n + 1 个守护节点上，只要 n+1 个守护节点成功写入就表示写入成功，而待命的NameNode会一直监听守护节点上editlog的变化，如果出现改动就会读取这个日志并与当前的命名空间合并，保证活动的NameNode发生错误时，待命的NameNode能够与活动的NameNode的命名空间保持一致。</p>
<p>​        为了让状态切换尽快完成，还需要保证待命的NameNode也实时保存了数据块的存储信息，这样在错误切换的时候，待命的NameNode就不需要等待所有数据块全部汇报完后再切换，而是直接切换到活动状态。我们只需要让DataNode同时向这两个NameNode发送块位置信息和心跳。</p>
<h3 id="MapReduce相关"><a href="#MapReduce相关" class="headerlink" title="MapReduce相关"></a>MapReduce相关</h3><h4 id="组成架构-1"><a href="#组成架构-1" class="headerlink" title="组成架构"></a>组成架构</h4><p>MapReduce使用主从架构，包含JobClient、JobTracker、TaskTracker和Task。</p>
<ol>
<li>在用户端使用JobClient将打包好的jar文件存储到HDFS上，然后将路径提交给JobTracker，JobTracker会创建Task，分发给多个TaskTracker执行；</li>
<li>JobTracker是主从结构中的主节点，会调度和监控每个Task的状态，如果某个Task执行失败，就会重新运行它；</li>
<li>TaskTracker是主从结构中的从节点，运行在HDFS的DataNode上，会主动和JobTracker进行通信，接收并执行从JobTracker传过来的任务；</li>
<li>Task分为Map Task和Reduce Task，由TaskTracker来启动，我们知道在HDFS中使用block为单位存储数据，在MapReduce中则使用split为单位处理数据，这个split是一个逻辑概念，只存储一些元数据信息，比如数据的起始位置、数据的长度、数据所在的节点等。它的划分方法由用户决定，一个split对应一个map task。</li>
</ol>
<h4 id="MapReduce核心编程思想（WordCount编程思想）"><a href="#MapReduce核心编程思想（WordCount编程思想）" class="headerlink" title="MapReduce核心编程思想（WordCount编程思想）"></a>MapReduce核心编程思想（WordCount编程思想）</h4><p>​        MapReduce一般会分为Map阶段和Reduce阶段。</p>
<p>​        在Map阶段，逐行读取数据，按空格分割单词，组成 &lt;单词,1&gt; 的键值对形式，假设这里存在两个分区，分别对应首字母为 a-p、q-z的单词，那么就会将对应首字母的键值对发送到相应的分区，再溢写到磁盘。Map阶段并发执行Map Task，是完全的并行操作，互不干扰。</p>
<p>​        在Reduce阶段，会开启两个Reduce Task，分别处理 a-p、q-z的分区。Reduce Task也是并发执行的，相互之间不干扰，但是它们的数据依赖于Map Task的输出。</p>
<h4 id="数据切片和Map-Task并行度"><a href="#数据切片和Map-Task并行度" class="headerlink" title="数据切片和Map Task并行度"></a>数据切片和Map Task并行度</h4><p>Split即数据切片，是逻辑存储，假设要切分130M的数据，数据块会将其切分为128M和2M使用两个数据块实现物理存储，想要切分为三片，需要记录 0-65、65-130的索引，这是数据切分的实现。切片的大小可以大于或小于一个数据块的大小，也可以等于一个数据块的大小，但是大于或小于数据块的时候，就比如刚刚的例子，将数据平分切片，就会涉及跨节点取数据的问题，效率肯定会比获取本地数据要低；如果按照数据块大小切片，在本地文件系统获取数据块，效率就会更高一些。切片不会考虑数据集整体，也就是如果有两个文件输入，不会将两个文件看成一个整体切分，而是每个文件单独切片。</p>
<p>具体切片的逻辑是：</p>
<p>首先需要获取 splitsize 一片的大小，涉及三个值：minsize默认1、maxsize默认Long类型的最大值和blocksize数据块的大小，依据max(minsize, min(maxsize, blocksize)) 的逻辑可以得到 一片的大小默认是数据块的大小，然后判断被切数据和splitsize的比值如果大于1.1，就切片，否则不再切片。</p>
<p>从这个逻辑可以看出，如果控制了 minsize 和 maxsize 的值，就可以控制切片的大小，如果想要调大切片修改 minsize，调小切片修改 maxsize。</p>
<h4 id="Job提交流程"><a href="#Job提交流程" class="headerlink" title="Job提交流程"></a>Job提交流程</h4><p>通过 <code>waitForCompletion</code> 方法进入提交流程，首先会判断输出路径是否存在，然后建立连接，<code>providerList</code> 有两种连接，YarnClient和LocalClient，选择对应的连接方式，然后给这个任务创建一个JobID，并以这个ID为名称创建存提交文件的文件夹，接着对输入数据执行切片，最后提交的内容包括配置文件、切片信息，如果是集群运行还包括jar包，最后将 DEFINE 状态修改为 RUNNING，提交Job成功。</p>
<h4 id="Map-Task工作机制"><a href="#Map-Task工作机制" class="headerlink" title="Map Task工作机制"></a>Map Task工作机制</h4><p>分为5个阶段：</p>
<p>Read阶段：<br>通过InputFormat调用RecorderReader的reader()方法读取数据，默认使用TextInputFormat，其中 k 对应偏移量，v对应一行内容。</p>
<p>Map阶段：<br>将读取的数据返回给Map，开始执行用户写的Mapper逻辑。</p>
<p>Collect阶段：</p>
<p>Mapper阶段的数据首先会进入Partitioner标记分区，接着输出到环形缓冲区，一半存实际数据，一半存数据的索引，分区号就在索引数据中，存储的数据到达80%的阈值或者文件输入完后，执行 <code>sortAndSpill()</code> 方法先对索引数据按分区和key值进行快排再反向溢写到磁盘。</p>
<p>溢写阶段：<br>遍历分区，溢写到本地文件中，这里并不是一个分区一个文件，而是存在一个文件，然后使用索引划分数据属于哪个分区，如果数据量特别大，一个文件装不下，才会溢写出多个文件。</p>
<p>Merge阶段：<br>溢写操作结束后，进入 <code>mergeParts</code> 方法，将多个溢写文件归并为一个，并生成一个index文件存储归并后的文件的索引，最终Reduce Task按照index文件中对应的分区读取归并文件中的数据。</p>
<p><strong>MapTask并行度决定机制：</strong></p>
<p>​        是由切片的个数决定的，一个切片对应一个maptask，而切片的个数是由输入文件的类型和切片规则决定的。</p>
<ol>
<li>切片规则：max(minsize, min(maxsize, blocksize))。</li>
<li>InputFormat的类型包含了TextInputFormat、CombineInputFormat等。</li>
</ol>
<h4 id="ReduceTask工作机制"><a href="#ReduceTask工作机制" class="headerlink" title="ReduceTask工作机制"></a>ReduceTask工作机制</h4><p>包括3个阶段。</p>
<p>Copy阶段：</p>
<p>会先从maptask拉取指定分区的数据；</p>
<p>Sort阶段：</p>
<p>每个reducetask对拉取的数据进行归并排序；</p>
<p>Reduce阶段：<br>相同的key会进入一个reduce中，依据用户的逻辑处理数据并输出文件。最后默认通过TextOutputFormat输出数据。</p>
<p><strong>并行度决定机制：</strong></p>
<p>可以直接手动设置：job.setNumReduceTasks(num)，默认是1。这个数值一般会通过实验求正态分布中的最大值，具体会比较不同task数目的执行时间，可以通过8088端口开启Yarn界面查看。</p>
<p><strong>Partition分区数和Reduce Task个数的关系：</strong></p>
<ol>
<li>如果Reduce Task的数目 &gt; Partition分区数，会产生空的输出文件，因为生成每个输出文件都会消耗CPU和1G的内存，这样就产生了资源浪费；</li>
<li>Reduce Task的数目 &gt; 1 &amp;&amp; &lt; Partition分区数，则有一部分数据无处安放，会报错；</li>
<li>如果Reduce Task的数目为1，最终结果都会输出到这个文件中。</li>
</ol>
<h4 id="shuffle过程详解"><a href="#shuffle过程详解" class="headerlink" title="shuffle过程详解"></a>shuffle过程详解</h4><p>​        Map方法之后，Reduce方法之前的混洗的过程就叫做Shuffle。</p>
<p>​        从Map方法出来之后，会先进入 getPartition() 方法，标记数据是哪个分区的，然后进入环形缓冲区。这个缓冲区默认100M，左侧存索引，右侧存实际的数据，存储的数据量到达80%的阈值后开始反向溢写，这样就可以让缓冲区一直高效运转，不至于在缓冲区满了以后阻塞等待。在溢写之前，还需要对数据中的key的索引，按照字典序进行快排。</p>
<p>​        溢出后，会产生两个文件，一个是实际溢出的数据文件，一个是这个数据文件的索引文件，之后可以执行Combiner过程，可以看成是本地的reduce过程，将相同key的数据合并，这样能够减少reduce task拉取的次数。</p>
<p>​        之后会对溢出文件执行归并排序，归并排序后，也可以执行Combiner操作，之后还可以执行压缩的操作，以减少网络传输的内容。最后写入本地磁盘，等待Reduce拉取。</p>
<p>​        Reduce端拉取数据，会先尝试放到内存中，内存不够的情况下会溢写到磁盘。拉取完后会对内存和磁盘中的数据执行归并排序，最后将相同key的数据分配到一个reduce中执行。</p>
<h4 id="Combiner-过程"><a href="#Combiner-过程" class="headerlink" title="Combiner 过程"></a>Combiner 过程</h4><p>​        Combiner不是MR程序默认的组件，可以看成是一个插件，父类是Reducer，所以会继承Reduce端的业务逻辑，但是实际上在每个Map Task所在的节点运行。它的目的是对每个Map Task的输出进行局部汇总，以减小网络传输量，比如一个Map Task中有100个 &lt;a,1&gt;，汇总以后变成 &lt;a,100&gt;，那么原来需要传100次，现在只需要传1次。但是Combiner应用的前提是不能影响最终的业务逻辑。假设Mapper端有两个Task，<code>3 5 7</code>和 <code>2 4</code> ，最终的业务逻辑是累加求平均值，这里如果使用Combiner，会分别计算 <code>(3+5+7)/3</code> 和 <code>(2+4)/2</code> ，这和最终的 <code>(2+5+7+2+4)/5</code> 的结果就不一致了。</p>
<h4 id="序列化概述"><a href="#序列化概述" class="headerlink" title="序列化概述"></a>序列化概述</h4><p>​        假设机器 hadoop102 的内存中存储数据 abc，想要将其拷贝到机器 hadoop103 上，需要先将 hadoop102 内存中的数据转换为字节码的形式存储到磁盘，然后通过网络传输到 hadoop103 中，再转换到 hadoop103 的内存上。其中，hadoop102 将内存的数据转换为字节码格式的过程叫做序列化，hadoop103 将字节码加载到内存的过程叫做反序列化。</p>
<p>​        Java中其实本身自带了序列化框架 Serializable，它大致的流程是在要传输数据的末尾再加上各种校验信息、头信息、继承体系等，然后一起打包传输到另一个机器后再序列化，这种机制比较复杂。对Hadoop来说，因为是在系统内部进行传输，所以只需要一个简单的校验。相比于Java的序列化机制，Hadoop序列化因为传输的信息更少，所以存储的空间更小，传输速度更快。</p>
<p>​        如果想要自定义序列化可以继承 Writable 接口，此处就不过多赘述。</p>
<h4 id="Map-Join-和-Reduce-Join"><a href="#Map-Join-和-Reduce-Join" class="headerlink" title="Map Join 和 Reduce Join"></a>Map Join 和 Reduce Join</h4><p>reduce join是在map阶段完成数据的标记，在reduce阶段完成数据的合并；</p>
<p>map join是直接在map阶段完成数据的合并，没有reduce阶段。</p>
<p>Reduce Join的缺陷：</p>
<p>1、合并的任务在reduce端执行，reduce端处理压力大，而map端默认情况下一次会处理一个数据块，负载比较低，那么资源利用率不高。<br>2、在Key值分布不均匀的情况下，很容易产生数据倾斜。</p>
<p>所以如果是一张小表和一张大表执行Join操作，可以考虑将小表加载到内存，在Map端执行Join操作，也就是使用Map Join，Map Join由于没有Reduce阶段，可以极大的减少网络传输和IO的代价。</p>
<h4 id="hadoop的二级排序"><a href="#hadoop的二级排序" class="headerlink" title="hadoop的二级排序"></a>hadoop的二级排序</h4><p>即对key和value双排序。默认情况下，Map输出的结果会对Key进行默认的排序，但是有时候需要对Key排序的同时还需要对Value进行排序，这时候就要用到二次排序了。<br>有两种方法进行二次排序，分别为：buffer and in memory sort和 value-to-key conversion。<br>1、buffer and in memory sort<br>在reduce()函数中，将某个key对应的所有value保存到内存中，然后进行排序。 这种方法最大的缺点是：可能会造成out of memory。<br>2、value-to-key conversion<br>MapReduce程序中，Mapper输出的键值对会经历shuffle过程再交给 Reducer。在shuffle阶段，Mapper输出的键值对会经过partition(分区)-&gt;sort(排序)-&gt;group(分组) 三个阶段。<br>将key和部分value拼接成一个组合key，这样reduce获取的结果便是先按key排序，后按value排序的结果，需要注意的是，用户需 要自己实现Paritioner，以便只按照key进行数据划分。Hadoop显式的支持二次排序，在Configuration类中有setSotComparatorClass()方法可以对key值进行处理，setGroupingComparatorClass()方法对相同key的value值进行处理。<br>shuffle 的 sort 过程会根据键值对&lt;key, value&gt;的 key 进行排序，但是二次排序中，value 也是需要排序的字段。因此需要将 value 字段合并到 key 中作为新的 key，形成新的键值对&lt;key#value, value&gt;。在排序时使其先根据 key 排序，如果相同，再根据 value 排序。</p>
<h4 id="MapReduce优化"><a href="#MapReduce优化" class="headerlink" title="MapReduce优化"></a>MapReduce优化</h4><h5 id="跑得慢的原因"><a href="#跑得慢的原因" class="headerlink" title="跑得慢的原因"></a>跑得慢的原因</h5><p>Mapreduce的瓶颈在于两点：</p>
<p>（1）计算机性能：CPU、内存、磁盘健康、网络等。</p>
<p>（2）I&#x2F;O操作：数据倾斜、Map和Reduce数设置不合理、Map运行时间太长导致Reduce等待过久、小文件过多、大量的不可分块的超大文件、spill次数过多、Merge次数过多等。</p>
<h5 id="具体的优化方法"><a href="#具体的优化方法" class="headerlink" title="具体的优化方法"></a>具体的优化方法</h5><p>主要从六个方面考虑：数据输入、Map阶段、Reduce阶段、IO传输、数据倾斜问题和常用的调优参数。</p>
<p><strong>1）数据输入</strong></p>
<p>（1）合并小文件：在执行MR任务前将小文件进行合并，大量的小文件会产生大量的Map任务，增大Map任务装载次数，而任务的装载比较耗时，从而导致MR运行较慢。</p>
<p>（2）采用CombineTextInputFormat来作为输入，解决输入端大量小文件场景。</p>
<p><strong>2）Map阶段</strong></p>
<p>（1）减少溢写(Spill)次数：通过调整io.sort.mb及sort.spill.percent参数值，增大触发Spill的内存上限，减少Spill次数，从而减少磁盘IO。</p>
<p>（2）减少合并(Merge)次数：通过调整io.sort.factor参数，增大Merge的文件数目，减少Merge的次数，从而缩短MR处理时间。</p>
<p>（3）在Map之后，不影响业务逻辑前提下，先进行Conbine处理，减少IO。</p>
<p><strong>3）Reduce阶段</strong></p>
<p>（1）合理设置Map和Reduce数：两个都不能设置太少，也不能设置太多。太少，会导致Task等待，延长处理时间；太多，会导致Map、Reduce任务间竞争资源，造成处理超时等错误。</p>
<p>（2）设置Map、Redce共存：调整slowstart.completedmaps参数，使Map运行到—定程度后，Recuce也开始运行，减少Reduce的等待时间。</p>
<p>（3）规避使用Reduce：因为Reduce在用于连接数据集的时候将会产生大量的网络消耗。</p>
<p>（4）合理设置Reduce端的Buffer：默认情况下，数据达到一个阈值的时候，Buffer中的数据就会写入磁盘，然后Recuce会从磁盘中获得所有的数据。也就是说，Buffer和Recuce是没有直接关联的，中间多次写磁盘-&gt;读磁盘的过程，既然有这个弊端，那么就可以通过参数来配置，使得Buffer中的一部分数据可以直接输送到Reduce，从而减少Io开销：mapreduce.reduce.input.buffer.percent，默认为0.0。当值大于0的时候，会保留指定比例的内存读Buffer中的数据直接拿给Recuce使用。但是这样一来，设置Buffer需要内存，读取数据需要内存，Recuce计算也要内存，所以要根据作业的运行情况进行调整。</p>
<p><strong>4）IO传输</strong></p>
<p>（1）采用数据压缩的方式，减少网络Io的的时间。安装Snappy和LZo压缩编码器。</p>
<p>（2）使用SequenceFile二进制文件。</p>
<p><strong>5）数据倾斜</strong></p>
<p>（1）数据倾斜现象<br>大量的相同key被分配到一个分区里，map &#x2F;reduce程序执行时，reduce节点大部分执行完毕，但是有一个或者几个reduce节点运行很慢，导致整个程序的处理时间很长。<br>（2）减少数据倾斜的方法</p>
<p>方法一：将不均匀的key值打散。</p>
<p>这种方式适用于绝大部分key对应10%的数据，而很少部分的key对应90%的数据。对于这种情况，可以给key值加上随机数，将数据量很大的key值打散到不同的reduce中计算。</p>
<p>方法二：使用map join代替 reduce join。</p>
<p>适用于小表join大表的情况。可以将小表放到内存，然后将map task的数据通过hash取余的方式选择小表中对应的key值，进行join操作。在map端的每个map task中完成join操作，后续就不需要进入reduce端处理了，能够避免shuffle过程，从而避免数据倾斜。</p>
<p>方法三：使用group by代替distinct。</p>
<p>在统计数量的时候经常会用到 <code>select count(distinct name)</code> ，这样会将name的key值全都shuffle到一个reduce中处理，很容易产生数据倾斜。采用group by+聚合函数的方式可以将数据根据key值分配到不同的reduce中，避免数据倾斜。</p>
<p><strong>6）常见的调优参数</strong></p>
<p>mapreduce中比如有 <code>mapreduce.map.cpu.vcores</code> 设置每个MapTask可使用的最多cpu core数目，默认值: 1；</p>
<p>yarn中比如有 <code>yarn.scheduler.minimum-allocation-vcores </code> 设置每个Container申请的最小CPU核数，默认值：1；</p>
<p>shuffle中比如有 <code>mapreduce.map.sort.spill.percent</code> 设置环形缓冲区溢出的阈值，默认80%；</p>
<p>容错相关系数比如有 <code>mapreduce.map.maxattempts</code> 设置每个Map Task最大重试次数，一旦重试参数超过该值，则认为Map Task运行失败，默认值：4。</p>
<h3 id="Yarn相关"><a href="#Yarn相关" class="headerlink" title="Yarn相关"></a>Yarn相关</h3><h4 id="组成架构-2"><a href="#组成架构-2" class="headerlink" title="组成架构"></a>组成架构</h4><p>Yarn使用主从架构，包含ResourceManager、NodeManager、ApplicationMaster和Container。</p>
<p>​        ResourceManager负责整个集群资源的管理，负责处理客户端的请求，监控所有NodeManager的运行情况，当哪个NodeManager的资源不够就可以即使分配资源；也负责启动和监控所有ApplicationMaster，当ApplicationMaster里面有任务挂了可以及时将这个任务分配到其他节点运行。</p>
<p>​        NodeManager负责管理单个节点的资源，并定时向RM汇报本节点的资源使用情况，以及处理来自RM的命令和来自AM的命令。</p>
<p>​        ApplicationMaster会为应用程序向RM申请资源并分配给内部的任务，然后监控任务的执行，当任务挂掉可以及时向RM反应。</p>
<p>​        Container是Yarn中的集群抽象，封装了某个节点上的多维度资源，比如内存、磁盘、CPU、网络等。</p>
<h4 id="Yarn工作机制"><a href="#Yarn工作机制" class="headerlink" title="Yarn工作机制"></a>Yarn工作机制</h4><ol>
<li>首先执行Jar文件，入口main方法，走到 <code>job.waitForCompletion()</code> 方法会建立一个YarnRunner，开始向RM申请一个Application；</li>
<li>RM会返回Application资源提交的路径，程序会向这个路径提交三样东西：xml配置文件、jar包、切片文件；</li>
<li>资源提交完毕后，程序向RM申请运行这个任务的ApplicationMaster，RM会将用户的请求初始化为一个Task，保存到调度队列上，这个调度队列默认使用容量调度器；</li>
<li>等到NodeManager从调度队列上获取该Task，会创建一个Container，并在这个Container内启动AM，这个AM会下载对应路径下提交的资源，然后根据切片信息向RM申请对应数量的MapTask容器，这个请求也会存到调度队列上等待调度；</li>
<li>有NodeManager领取到这个任务后，会创建相应数量的Container，然后将对应的jar包拷贝过来；</li>
<li>接着AM发送程序启动的脚本到这些Container中，让它们启动并运行MapTask；</li>
<li>MapTask运行结束后，将输出数据按照分区持久化到磁盘；</li>
<li>然后AM开始向RM申请ReduceTask数目的容器，之后向这些Container发送启动ReduceTask命令，Reduce开始向Map端拉取数据并执行业务逻辑；</li>
<li>等到所有程序运行完毕，AM会向RM申请注销自己。</li>
</ol>
<h4 id="作业提交全过程"><a href="#作业提交全过程" class="headerlink" title="作业提交全过程"></a>作业提交全过程</h4><p>画一个大图，将这三者的整个流程全画一遍。<strong>这是必须要会的内容！！！</strong></p>
<h4 id="调度器的种类"><a href="#调度器的种类" class="headerlink" title="调度器的种类"></a>调度器的种类</h4><p>调度器的种类有三种：</p>
<ol>
<li><p>FIFO调度器：</p>
<p>​        所有作业被提交到一个队列中，然后先按照优先级高低、再按照作业提交时间选择被执行的作业。这种算法简单，但是如果前一个作业占用了全部的资源，会导致后面的任务一直无法处理。</p>
</li>
<li><p>容量调度器：</p>
<p>（1）是apache hadoop3的默认调度器，支持多个队列，每个队列使用FIFO算法调度；</p>
<p>（2）管理员可以为每个队列设置最低资源保证和资源上限，这个上限不是固定的，如果一个队列的资源有剩余，可以暂时共享给其他需要资源的队列，但是一旦该队列有新的任务提交，其他队列借调的资源需要立刻归还给该队列；</p>
<p>（3）支持多用户共享集群和多程序同时运行，此处为了防止同一用户独占队列的资源，会对同一用户所占资源进行限定。</p>
<p><strong>资源分配算法：</strong></p>
<p>（1）先确定分配的队列：优先选择资源占用率最低的队列；</p>
<p>（2）接着定位要分配资源的作业：默认按照作业的优先级和提交顺序来执行；</p>
<p>（3）最后确定分配资源的容器：先按照容器的优先级分配，如果优先级相同，按照数据本地性原则分配：先任务和数据在同意节点、然后任务和数据在同一机架、最后任务和数据不在一个节点也不在一个机架。</p>
</li>
<li><p>公平调度器：也支持多队列，尽可能保证所有作业都能获得等量的资源，系统中只有一个作业时，会独占所有资源，有其他作业提交时再将资源平分给其他任务。</p>
</li>
</ol>
<p><strong>计算能力调度器和公平调度器的比较：</strong></p>
<p>二者核心的区别在于，提交任务到队列中，是采用公平调度还是FIFO调度。对于公平调度器，因为能够尽量保证任务获得等量的资源，所以能够避免因为长时间运行大任务而阻塞小任务；但是容量调度器也可以针对不同的任务创建不同的队列，然后由任务提交者根据任务的特点提交到不同队列中，也可以实现和公平调度器一样的效果。</p>
<p>调度器的修改参数是 <code>yarn-site.xml</code> 中的 <code>yarn.resourcemanager.scheduler.class</code> 。</p>
<h4 id="Yarn怎么保证高可用"><a href="#Yarn怎么保证高可用" class="headerlink" title="Yarn怎么保证高可用"></a>Yarn怎么保证高可用</h4><p>在hadoop2.4版本之前，Yarn框架的RM存在单点故障的问题，也就是如果RM挂掉了，恢复的时间会比较长，这就会导致正在运行的程序丢失，影响范围较大，所以从hadoop2.4版本开始，引入了RM高可用机制，典型的高可用集群中，默认会配置两个独立的ResourceManager，在任意时间，有且仅有一个RM处于运行状态，另一台处于待命状态，一旦运行状态的RM出现故障，就可以将待命状态的RM切换为运行状态继续执行任务。切换的方式可以是手动切换，也可以基于Zookeeper实现自动切换。</p>
<h3 id="三者关系的简述"><a href="#三者关系的简述" class="headerlink" title="三者关系的简述"></a>三者关系的简述</h3><p>客户端将任务提交到RM，RM到某个NM下启动一个container，并在该container内放置传输的AM；接着AM向RM申请资源，RM返回相应的资源列表，然后AM启动这些对应的资源，这些资源在对应的DN上处理相应的任务，这部分称为maptask，maptask处理完后，将所有maptask的结果传输到reduce端执行，最终将reduce端的结果对应的元数据信息传输到namenode中；2NN会每隔一段时间对NM的元数据进行备份。</p>
<h3 id="ETL的几个过程分别是什么？"><a href="#ETL的几个过程分别是什么？" class="headerlink" title="ETL的几个过程分别是什么？"></a>ETL的几个过程分别是什么？</h3><p>ETL是Extract Transform Load三个英文单词的缩写，中文意思就是抽取、转换、加载。说到ETL就必须提到数据仓库，ETL负责完成数据从数据源向目标数据仓库转化的过程，是实施数据仓库的重要步骤。<br>构建数据仓库的核心是建模，在数据仓库的构建中，ETL贯穿于项目始终，它是整个数据仓库的生命线。从数据源中抽取数据，然后对这些数据进行转化，最终加载到目标数据库或者数据仓库中去，这就是ETL 过程。<br>通常数据抽取工作分抽取、清洗、转换、装载几个步骤：</p>
<p>抽取主要是针对各个业务系统及不同服务器的分散数据，充分理解数据定义后，规划需要的数据源及数据定义，制定可操作的数据源，制定增量抽取和缓慢渐变的规则。</p>
<p>清洗主要是针对系统的各个环节可能出现的数据二义性、重复、不完整、违反业务规则等数据质量问题，允许通过数据抽取设定的数据质量规则，将有问题的记录先剔除出来，根据实际情况调整相应的清洗操作。</p>
<p>转换主要是针对数据仓库建立的模型，通过一系列的转换来实现将数据从业务模型到分析模型，通过ETL工具可视化拖拽操作可以直接使用标准的内置代码片段功能、自定义脚本、函数、存储过程以及其他的扩展方式，实现了各种复杂的转换，并且支持自动分析日志，清楚的监控数据转换的状态并优化分析模型。</p>
<p>装载主要是将经过转换的数据装载到数据仓库里面，可以通过直连数据库的方式来进行数据装载，可以充分体现高效性。在应用的时候可以随时调整数据抽取工作的运行方式，可以灵活的集成到其他管理系统中。</p>

    </div>

    
    
    
	  
	
	 <div>
		<div>
    
        <div style="text-align:center;color: #ccc;font-size:24px;">-------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------</div>
    
</div>
	 </div>
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/hadoop/" rel="tag"># hadoop</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2021/07/29/SQL-%E6%8A%A5%E9%94%99/" rel="prev" title="SQL - 报错">
      <i class="fa fa-chevron-left"></i> SQL - 报错
    </a></div>
      <div class="post-nav-item">
    <a href="/2021/08/06/hive-%E6%8A%A5%E9%94%99/" rel="next" title="hive - 报错">
      hive - 报错 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#hadoop%E8%A7%A3%E5%86%B3%E5%93%AA%E4%BA%9B%E9%97%AE%E9%A2%98%EF%BC%8C%E6%9C%89%E5%93%AA%E4%BA%9B%E7%89%B9%E6%80%A7"><span class="nav-number">1.</span> <span class="nav-text">hadoop解决哪些问题，有哪些特性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#hadoop%E7%9A%84%E7%89%88%E6%9C%AC%E5%8C%BA%E5%88%AB"><span class="nav-number">2.</span> <span class="nav-text">hadoop的版本区别</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B8%B8%E7%94%A8%E7%AB%AF%E5%8F%A3%E5%8F%B7"><span class="nav-number">3.</span> <span class="nav-text">常用端口号</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B8%B8%E7%94%A8%E7%9A%84%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="nav-number">4.</span> <span class="nav-text">常用的配置文件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HDFS%E7%9B%B8%E5%85%B3"><span class="nav-number">5.</span> <span class="nav-text">HDFS相关</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%BB%84%E6%88%90%E6%9E%B6%E6%9E%84"><span class="nav-number">5.1.</span> <span class="nav-text">组成架构</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9C%BA%E6%9E%B6%E6%84%9F%E7%9F%A5%E6%9C%BA%E5%88%B6%EF%BC%88%E5%89%AF%E6%9C%AC%E8%8A%82%E7%82%B9%E7%9A%84%E9%80%89%E6%8B%A9%EF%BC%89"><span class="nav-number">5.2.</span> <span class="nav-text">机架感知机制（副本节点的选择）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#NameNode%E5%92%8CSecondaryNameNode%E8%BF%90%E8%A1%8C%E6%9C%BA%E5%88%B6%EF%BC%88NameNode%E7%9A%84%E5%AE%B9%E9%94%99%E6%9C%BA%E5%88%B6%EF%BC%89"><span class="nav-number">5.3.</span> <span class="nav-text">NameNode和SecondaryNameNode运行机制（NameNode的容错机制）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#HDFS%E4%B8%AD%E5%B0%8F%E6%96%87%E4%BB%B6%E7%9A%84%E5%A4%84%E7%90%86"><span class="nav-number">5.4.</span> <span class="nav-text">HDFS中小文件的处理</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#HDFS%E7%9A%84%E8%AF%BB%E5%86%99%E8%BF%87%E7%A8%8B"><span class="nav-number">5.5.</span> <span class="nav-text">HDFS的读写过程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E6%95%B0%E6%8D%AE%E5%9D%97%E4%B8%8D%E8%83%BD%E8%AE%BE%E7%BD%AE%E5%A4%AA%E5%B0%8F%E4%B9%9F%E4%B8%8D%E8%83%BD%E8%AE%BE%E7%BD%AE%E5%A4%AA%E5%A4%A7"><span class="nav-number">5.6.</span> <span class="nav-text">为什么数据块不能设置太小也不能设置太大</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#HDFS%E5%AE%9E%E7%8E%B0%E9%AB%98%E5%8F%AF%E7%94%A8"><span class="nav-number">5.7.</span> <span class="nav-text">HDFS实现高可用</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MapReduce%E7%9B%B8%E5%85%B3"><span class="nav-number">6.</span> <span class="nav-text">MapReduce相关</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%BB%84%E6%88%90%E6%9E%B6%E6%9E%84-1"><span class="nav-number">6.1.</span> <span class="nav-text">组成架构</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#MapReduce%E6%A0%B8%E5%BF%83%E7%BC%96%E7%A8%8B%E6%80%9D%E6%83%B3%EF%BC%88WordCount%E7%BC%96%E7%A8%8B%E6%80%9D%E6%83%B3%EF%BC%89"><span class="nav-number">6.2.</span> <span class="nav-text">MapReduce核心编程思想（WordCount编程思想）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%88%87%E7%89%87%E5%92%8CMap-Task%E5%B9%B6%E8%A1%8C%E5%BA%A6"><span class="nav-number">6.3.</span> <span class="nav-text">数据切片和Map Task并行度</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Job%E6%8F%90%E4%BA%A4%E6%B5%81%E7%A8%8B"><span class="nav-number">6.4.</span> <span class="nav-text">Job提交流程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Map-Task%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6"><span class="nav-number">6.5.</span> <span class="nav-text">Map Task工作机制</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#ReduceTask%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6"><span class="nav-number">6.6.</span> <span class="nav-text">ReduceTask工作机制</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#shuffle%E8%BF%87%E7%A8%8B%E8%AF%A6%E8%A7%A3"><span class="nav-number">6.7.</span> <span class="nav-text">shuffle过程详解</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Combiner-%E8%BF%87%E7%A8%8B"><span class="nav-number">6.8.</span> <span class="nav-text">Combiner 过程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%BA%8F%E5%88%97%E5%8C%96%E6%A6%82%E8%BF%B0"><span class="nav-number">6.9.</span> <span class="nav-text">序列化概述</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Map-Join-%E5%92%8C-Reduce-Join"><span class="nav-number">6.10.</span> <span class="nav-text">Map Join 和 Reduce Join</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#hadoop%E7%9A%84%E4%BA%8C%E7%BA%A7%E6%8E%92%E5%BA%8F"><span class="nav-number">6.11.</span> <span class="nav-text">hadoop的二级排序</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#MapReduce%E4%BC%98%E5%8C%96"><span class="nav-number">6.12.</span> <span class="nav-text">MapReduce优化</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%B7%91%E5%BE%97%E6%85%A2%E7%9A%84%E5%8E%9F%E5%9B%A0"><span class="nav-number">6.12.1.</span> <span class="nav-text">跑得慢的原因</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%85%B7%E4%BD%93%E7%9A%84%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95"><span class="nav-number">6.12.2.</span> <span class="nav-text">具体的优化方法</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Yarn%E7%9B%B8%E5%85%B3"><span class="nav-number">7.</span> <span class="nav-text">Yarn相关</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%BB%84%E6%88%90%E6%9E%B6%E6%9E%84-2"><span class="nav-number">7.1.</span> <span class="nav-text">组成架构</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Yarn%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6"><span class="nav-number">7.2.</span> <span class="nav-text">Yarn工作机制</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BD%9C%E4%B8%9A%E6%8F%90%E4%BA%A4%E5%85%A8%E8%BF%87%E7%A8%8B"><span class="nav-number">7.3.</span> <span class="nav-text">作业提交全过程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%B0%83%E5%BA%A6%E5%99%A8%E7%9A%84%E7%A7%8D%E7%B1%BB"><span class="nav-number">7.4.</span> <span class="nav-text">调度器的种类</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Yarn%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81%E9%AB%98%E5%8F%AF%E7%94%A8"><span class="nav-number">7.5.</span> <span class="nav-text">Yarn怎么保证高可用</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%89%E8%80%85%E5%85%B3%E7%B3%BB%E7%9A%84%E7%AE%80%E8%BF%B0"><span class="nav-number">8.</span> <span class="nav-text">三者关系的简述</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ETL%E7%9A%84%E5%87%A0%E4%B8%AA%E8%BF%87%E7%A8%8B%E5%88%86%E5%88%AB%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="nav-number">9.</span> <span class="nav-text">ETL的几个过程分别是什么？</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Bonnie"
      src="/images/avatar.gif">
  <p class="site-author-name" itemprop="name">Bonnie</p>
  <div class="site-description" itemprop="description">每天都要做个人啊</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">108</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">66</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2021-05 – 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Bonnie</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

  

</body>
</html>
