<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="Kafka 的概念定义​        做缓冲。正常情况下，网站的行为日志传输到hdfs会使用flume。当flume传输的速率大于hdfs上传的速率，就容易产生数据丢失，于是引入了kafka来做中间的缓存。它是分布式基于发布订阅模式的消息队列，主要用于处理流数据。">
<meta property="og:type" content="article">
<meta property="og:title" content="kafka面试题">
<meta property="og:url" content="http://example.com/2022/03/03/kafka%E9%9D%A2%E8%AF%95%E9%A2%98/index.html">
<meta property="og:site_name" content="往南">
<meta property="og:description" content="Kafka 的概念定义​        做缓冲。正常情况下，网站的行为日志传输到hdfs会使用flume。当flume传输的速率大于hdfs上传的速率，就容易产生数据丢失，于是引入了kafka来做中间的缓存。它是分布式基于发布订阅模式的消息队列，主要用于处理流数据。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/2022/03/03/kafka%E9%9D%A2%E8%AF%95%E9%A2%98/kafka面试题.assets/image-20220322230050201.png">
<meta property="article:published_time" content="2022-03-03T14:37:42.000Z">
<meta property="article:modified_time" content="2022-03-27T17:13:22.188Z">
<meta property="article:author" content="Bonnie">
<meta property="article:tag" content="kafka">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2022/03/03/kafka%E9%9D%A2%E8%AF%95%E9%A2%98/kafka面试题.assets/image-20220322230050201.png">

<link rel="canonical" href="http://example.com/2022/03/03/kafka%E9%9D%A2%E8%AF%95%E9%A2%98/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>kafka面试题 | 往南</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">往南</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-resources">

    <a href="/resources/" rel="section"><i class="download fa-fw"></i>资源</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/03/03/kafka%E9%9D%A2%E8%AF%95%E9%A2%98/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Bonnie">
      <meta itemprop="description" content="每天都要做个人啊">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="往南">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          kafka面试题
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-03-03 22:37:42" itemprop="dateCreated datePublished" datetime="2022-03-03T22:37:42+08:00">2022-03-03</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-03-28 01:13:22" itemprop="dateModified" datetime="2022-03-28T01:13:22+08:00">2022-03-28</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E9%9D%A2%E8%AF%95%E9%A2%98/" itemprop="url" rel="index"><span itemprop="name">面试题</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h3 id="Kafka-的概念"><a href="#Kafka-的概念" class="headerlink" title="Kafka 的概念"></a>Kafka 的概念</h3><h4 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h4><p>​        做缓冲。正常情况下，网站的行为日志传输到hdfs会使用flume。当flume传输的速率大于hdfs上传的速率，就容易产生数据丢失，于是引入了kafka来做中间的缓存。它是分布式基于发布订阅模式的消息队列，主要用于处理流数据。</p>
<span id="more"></span>
<h4 id="应用场景（使用消息队列的原因，应该也可以看成是使用kafka的原因）"><a href="#应用场景（使用消息队列的原因，应该也可以看成是使用kafka的原因）" class="headerlink" title="应用场景（使用消息队列的原因，应该也可以看成是使用kafka的原因）"></a>应用场景（使用消息队列的原因，应该也可以看成是使用kafka的原因）</h4><ol>
<li>缓冲和削峰：就是用于解决发布和消费的处理速度不一致的情况。</li>
<li>解耦：假设发布者有三个，消费者也有三个，如果不使用消息队列，那么每个发布者都需要写三个接口发往不同的目的地；如果使用消息队列，就可以让发布者将消息统一发给队列，然后消费者再根据需要到队列获取特定的消息，两边的处理过程可以独立扩展或修改。</li>
<li>异步通信：假设用户注册信息写入数据库，正常的步骤是会发送短信告诉用户注册成功。如果是同步通信，就需要等待注册信息写入，并调用接口发送短信，之后页面才会响应注册成功；如果是异步通信，当用户注册信息成功后，会将发送短信的请求写入消息队列，然后页面直接响应成功，之后等到消息队列处理到这个请求再发送短信，这个过程相比于同步通信不需要等待太多时间。也就是先将核心业务处理完成，也就是注册信息和响应页面处理完成，发送短信这种不是很重要的事情可以发送到队列慢慢完成。</li>
</ol>
<h3 id="消息队列的两种模式（传统的消息传递方式）"><a href="#消息队列的两种模式（传统的消息传递方式）" class="headerlink" title="消息队列的两种模式（传统的消息传递方式）"></a>消息队列的两种模式（传统的消息传递方式）</h3><h4 id="点对点模式"><a href="#点对点模式" class="headerlink" title="点对点模式"></a>点对点模式</h4><p>​        发布者发送消息给消息队列，然后一个消费者会主动拉取消息队列中的数据，然后返回应答，之后消息队列就会删除这条被消费过的数据。</p>
<h4 id="发布订阅模式"><a href="#发布订阅模式" class="headerlink" title="发布订阅模式"></a>发布订阅模式</h4><p>​        可以在消息队列中存储不同类型的topic，然后消费者消费数据后，消息队列不会删除数据，每个消费者相互独立，都可以消费到数据。</p>
<h4 id="Kafka相较于传统消息传递的优势"><a href="#Kafka相较于传统消息传递的优势" class="headerlink" title="Kafka相较于传统消息传递的优势"></a>Kafka相较于传统消息传递的优势</h4><ol>
<li>快速：单一的kafka代理可以处理成千上万的客户端，每秒处理数兆字节的数据；</li>
<li>可扩展：kafka可以实现透明扩展，扩展的操作可以在集群联机时进行，而不会影响整个系统的可用性；</li>
<li>容错性：使用多副本机制对每个分区提供若干个副本，避免数据丢失。</li>
</ol>
<h3 id="Kafka基础架构"><a href="#Kafka基础架构" class="headerlink" title="Kafka基础架构"></a>Kafka基础架构</h3><ol>
<li>Producer：是负责发布数据的生产者；</li>
<li>Consumer：是消费数据的消费者；</li>
<li>Topic：主题，用于存储各种类型的数据；</li>
<li>Consumer Group：是消费者组，一个组内包含多个消费者，消费者组之间是互相独立的，组内的消费者负责消费不同分区的数据，一个分区只能由消费者组中的一个消费者消费；</li>
<li>Partition：为了方便扩展和提高吞吐量，可以将一个数据量非常大的topic切分为多个partition存储到多个broker中；</li>
<li>Broker：一个服务器就是一个broker，kafka集群可以包含多个broker，一个broker可以包含多个topic；</li>
<li>replica：为了保证集群中某个节点出现故障时数据不丢失，让kafka能够正常持续的运行，kafka提供了副本机制，为每个分区提供若干个副本，一个leader和多个follower，其中，生产者发布和消费者消费的对象都是leader。</li>
<li>zookeeper：kafka2.4版本之前引入了zookeeper框架来存储broker的节点信息和每个分区的副本信息，在2.4版本之后，出现了kraft代替zookeeper执行相同的内容。</li>
</ol>
<h3 id="Kafka发布数据的流程"><a href="#Kafka发布数据的流程" class="headerlink" title="Kafka发布数据的流程"></a>Kafka发布数据的流程</h3><ol>
<li>由main线程创建一个producer，执行send方法发送数据；</li>
<li>数据首先可以被发送到拦截器，在拦截器内可以对数据进行一些加工处理；</li>
<li>接着序列化器将数据序列化后，传到分区器进行分区，之后数据被传到相应的分区队列中缓存，这些分区队列使用一块内存存储，内存总大小默认是32M；</li>
<li>当某一分区的数据量达到batch.size参数设置的16k后，会有一个sender线程将这一批次的数据拉取到kafka broker；但是如果某一批次的数据量一直没满16k，那么在等待linger.ms参数设置的时间后也会发送数据，这个参数单位是ms，默认是0，也就是没有延迟；</li>
<li>sender线程读取到数据后，会将这些数据封装成类似kv的结构，以brokerid为key，想要发送到该broker上的数据请求会连成一个请求队列，作为value，然后将请求逐一发往对应的broker，如果broker接收到请求后没有立刻回应，sender依然可以继续发送请求，但是如果发了5个都没有得到回应就不会再发了，也就是说这个broker节点上最多能缓存5个请求；</li>
<li>broker接收到数据以后，会有一个应答机制：如果是0，那么sender不需要等待broker的应答，可以继续发送；如果是1，sender线程需要等待leader接收到后返回应答才能继续发送；如果是-1或all，那么需要leader和所有follower接收到数据后才能返回应答；</li>
<li>这个返回的应答如果是成功的，删除对应的请求和分区中对应的数据；如果失败了会重试，重试的次数默认是Integer的最大值。</li>
</ol>
<h3 id="Kafka同步发送和异步发送"><a href="#Kafka同步发送和异步发送" class="headerlink" title="Kafka同步发送和异步发送"></a>Kafka同步发送和异步发送</h3><p>​        同步发送指的是分区内这个批次的数据发送完了，下一批次才能继续发送；异步发送是无论这一批数据是否发送，下一批数据都会继续发送过来。</p>
<p>​        kafka使用的send方法默认就是异步发送，如果想要使用带回调函数的异步发送机制，也就是能够返回这个数据的分区、broker等信息，就使用带callback回调参数的 send(, new callback(){…}) 方法；如果想要同步发送，就在 send() 方法使用 <code>.get()</code> 实现。</p>
<h3 id="Kafka-分区"><a href="#Kafka-分区" class="headerlink" title="Kafka 分区"></a>Kafka 分区</h3><h4 id="使用分区的好处："><a href="#使用分区的好处：" class="headerlink" title="使用分区的好处："></a>使用分区的好处：</h4><ol>
<li>能够合理使用存储资源，将海量数据分别存储在多个服务器上，起到负载均衡的效果；</li>
<li>提高并行度，生产者可以以分区为单位传输数据，消费者也可以以分区为单位消费数据。</li>
</ol>
<h4 id="分区策略："><a href="#分区策略：" class="headerlink" title="分区策略："></a>分区策略：</h4><ol>
<li><p>默认的分区策略：</p>
<p>​        如果传入的数据指定了分区，就向指定分区发布数据；如果没有指定分区，但是指定了key值，就将key值对分区数取模，发布到对应的分区上；如果没有指定分区也没有指定key值，就使用粘性分区器，也就是随机选择一个分区，并在之后一直使用这个分区，直到这个分区内装满一个批次发送出去，再开始随机选择与上一个分区不同的其他分区。</p>
<p>​        <strong>这里有一个面试题</strong>，如果mysql中有一张订单表，希望将这个表的所有数据都发到一个分区，应该怎么做？应该将表名设置为key，那么相同key的数据就会发送到一个分区。</p>
</li>
<li><p>自定义分区器：</p>
<p>​        具体的步骤是：实现Partitioner接口，声明partition、close和configure方法，主要重写的是partition，partition中传入指定的topic、key和value，然后根据传入的参数指定发往某一个分区，分区从0开始。</p>
</li>
</ol>
<h3 id="Kafka丢不丢数据和应答机制有关"><a href="#Kafka丢不丢数据和应答机制有关" class="headerlink" title="Kafka丢不丢数据和应答机制有关"></a>Kafka丢不丢数据和应答机制有关</h3><p>​        当应答为0，也就是producer发送数据后，不需要等待leader的应答，会一直发送数据，此时如果leader还没有将数据从内存持久化到磁盘就宕机，数据就会丢失，虽然效率高，但一般生产环境极少使用；</p>
<p>​        当应答为1，也就是producer发送数据后，会等待leader返回应该后再继续发送数据，此时如果follower还没有进行同步，leader就挂了，新leader无法获取没同步数据，producer也不会重发已经接收的数据，就会导致数据丢失，效率中等，可靠性中等，适合传输普通日志，允许个别丢数据；</p>
<p>​        当应答为-1，也就是producer发送数据后，会等待leader和所有的follower接收到后返回应答，才会继续发送数据，效率查，但是可靠性高，适合传输钱相关的数据。</p>
<p><strong>应答为-1会产生一个问题，如果有一个follower在同步之前出现故障，迟迟不能与leader进行同步，leader会一直等待这个follower。</strong></p>
<p>解决：Leader维护一个动态的ISR队列，也就是和Leader保持同步的follower+leader的集合，如果这个集合中的某个follower长时间未向leader发送请求或同步数据，这个follower就会被踢出这个isr队列，这样就不用等待长时间联系不上的节点了。这个时间由参数replica.lag.time.max.ms控制，默认是30s。</p>
<p>​        但是应答为-1的机制也不能完全保证数据的可靠性，如果副本数为1，或者这个isr队列的最小应答数为1，那么当follower全挂的时候，和ack=1的效果就是一样的了，仍然会有丢数的风险。</p>
<p>​        如果想要保证数据的完全可靠，在ack=-1的情况下，还需要设置分区副本数要大于等于2，isr队列里最小应答数量大于等于2。</p>
<h3 id="Kafka-数据重复"><a href="#Kafka-数据重复" class="headerlink" title="Kafka 数据重复"></a>Kafka 数据重复</h3><p>​        应答为-1除了可靠性的问题，还有数据重复的问题：如果leader在发送ack之前故障了，生产者由于接收不到应答会重发数据，就会导致数据重复。</p>
<p>​        为了解决这个问题，kafka0.11版本后，引入了<strong>幂等性和事务</strong>的特性。</p>
<p>​        幂等性指的是无论生产者向broker发送多少重复的数据，broker只会持久化一条，来保证不重复。这里判断重复的标准是具有相同主键的数据就是重复的，这个主键由三部分组成：pid是生产者的id号，kafka重启一次会给producer分配一个新的id；分区号；sequence number，是一个单调自增的数值。这个方法只能保证在kafka没有挂掉之前的这一次运行过程中，一个分区内不会有重复数据产生。</p>
<p>​        为了解决pid这个问题，引入了事务。事务是建立在幂等性上执行的。在broker上，有两个内容：事务协调器用于处理事务，存储事务的特殊主题，用于持久化存储事务的信息，这个主题的底层也是一个磁盘。其中，事务协调器在每个broker中都有， 如何决定使用哪个broker的事务协调器？首先这个特殊主题默认有50个分区，每个分区负责一部分事务，事务的划分是根据传过来的事务id的哈希值对50取模，然后计算出该事务放到哪个分区，然后由这个分区leader所在的broker上的事务协调器处理这个事务。这个事务id需要由用户手动指定，必须是全局唯一值。这个事务id可以让客户端即使重启也能继续处理未完成的事务。</p>
<p>​        具体的步骤如下：</p>
<ol>
<li>生产者首先向对应的事务协调器请求幂等性要用的pid；</li>
<li>接收到返回的pid后，生产者开始向对应的leader发送数据，发送完后，生产者会向事务协调器请求提交；</li>
<li>事务协调器会将提交请求持久化到特殊主题，持久化后会给生产者返回应答；</li>
<li>接着，事务协调器会向leader发送提交请求，leader将数据接收完后会向协调器返回ack，协调器就会将提交成功的信息持久化到特殊主题。</li>
</ol>
<p><img src="kafka面试题.assets/image-20220322230050201.png" alt="image-20220322230050201"></p>
<h3 id="生产者如何提高吞吐量"><a href="#生产者如何提高吞吐量" class="headerlink" title="生产者如何提高吞吐量"></a>生产者如何提高吞吐量</h3><ol>
<li>设置参数 batch.size 和 linger.ms ，调整每批次拉取的数据量和多久拉取一次的时间来提高吞吐量，一般会将 linger.ms 设置为5~100ms，因为太小可能每次拉取的时候都不到一批次的大小，如果太大，那么拉去一次的延时就高了；</li>
<li>设置 compression.type 参数为压缩 snappy，压缩之后一个批次拉取的数据量会更大；</li>
<li>当分区数较多，比如1万的时候，可以增大缓冲区大小，来增大存储的批次数量，默认 buffer.memory = 32M 。</li>
</ol>
<h3 id="生产者发布的数据乱序的问题（面试重点）"><a href="#生产者发布的数据乱序的问题（面试重点）" class="headerlink" title="生产者发布的数据乱序的问题（面试重点）"></a>生产者发布的数据乱序的问题（面试重点）</h3><h4 id="数据乱序的产生"><a href="#数据乱序的产生" class="headerlink" title="数据乱序的产生"></a>数据乱序的产生</h4><p>​        因为brober默认可以连存5个请求而不需要应答，假设1和2成功发送3发送失败了，此时4就顺位继续发送，然后重发3的时候，就会出现乱序，应该是1234的，结果变成1243。</p>
<h4 id="数据乱序的解决"><a href="#数据乱序的解决" class="headerlink" title="数据乱序的解决"></a>数据乱序的解决</h4><ol>
<li>在kafka1版本之前，设置分区内的请求数量为1，只能等到当前请求成功发送才能接收下一个请求；</li>
<li>1版本之后引入了幂等性，开启幂等性enable.idempotence = true，并设置缓存数小于等于5，此时broker会缓存生产者发来的最近5个请求的元数据，能够保证最近5个数据都是有序的。具体实现有序的步骤是：broker中请求落盘的顺序是按照seqnumber的自增顺序进行的，例子中当number不为3的时候，哪怕到了4、5也会继续等待，直到请求3到达，会对broker中未落盘的请求按照sqnumber排序，再一次落盘。</li>
</ol>
<p><strong>设置缓存数不能大于5的原因是：</strong></p>
<p>​        因为broker上的ProducerStateManager实例会缓存每个pid在每个分区上发送的最近5个批次的数据，这个5是写死的，所以如果 max.in.flight.requests.per.connection 这个参数如果设置超过5，producerStateManager就会把最旧的批次数据删除。</p>
<h3 id="Broker-ZK存储内容"><a href="#Broker-ZK存储内容" class="headerlink" title="Broker ZK存储内容"></a>Broker ZK存储内容</h3><ol>
<li>在线的brokerid；</li>
<li>每个分区对应的副本所在的brokerid；</li>
<li>在某个分区的leader挂掉后，帮助选举新leader。leader的信息存储在/kafka/controller目录下，每个broker上都有一个controller模块，旧leader挂掉后，现有节点中的controller都会去注册zookeeper上的controller节点，第一个注册上的Controller负责进行选举。</li>
</ol>
<h3 id="Broker工作流程"><a href="#Broker工作流程" class="headerlink" title="Broker工作流程"></a>Broker工作流程</h3><ol>
<li>启动一台服务器会向ZK注册brokerid；</li>
<li>接着每台服务器上的controller都会去抢占ZK中的controller节点，第一个抢到的负责选举；</li>
<li>选举之前会监听zk上brokers节点的变化，然后以在isr队列中存活为前提，按照ar的顺序轮询，排在前面的优先，ar是kafka分区中所有副本的统称，ar的顺序就是服务器启动并注册到brokers的顺序，选举完后，这个controller将节点信息上传到zk；</li>
<li>其他controller会从zk中同步这个节点信息；</li>
<li>然后，生产者开始发送消息给leader，follower主动向leader同步数据；之后按照应答机制，leader向生产者返回ack；</li>
<li>如果leader挂掉了，zk会返回给监听他的controller，这个controller会从zk拉取节点信息，重新选举leader；</li>
<li>选举出新leader，这个controller再向zk更新节点信息。</li>
</ol>
<p><strong>脑裂的解决：</strong></p>
<p>​        出现脑裂的原因是可能由于网络的原因，会出现两个controller负责选举的情况。</p>
<p>​        解决：每当新的controller产生的时候就会在zk中生成一个全新的、数值更大的controller epoch的标识，并同步给其他的broker进行保存，这样当第二个controller发送指令时，其他的broker就会自动忽略。</p>
<h3 id="Kafka副本"><a href="#Kafka副本" class="headerlink" title="Kafka副本"></a>Kafka副本</h3><p>​        副本的作用是提高数据的可靠性，默认副本数是1，在生产环境中一般设置为2，不宜太多，因为副本也会消耗磁盘空间和进行网络运输，太多影响效率。</p>
<p>​        Kafka中所有副本统称为AR，包含了ISR和OSR，ISR中保存和Leader保持同步的leader和follower集合，当ISR中有follower与leader长时间没有通信，会被踢出到OSR集合，这个OSR就是存储超时的follower。这个实际默认是30s，由replica.lag.time.max.ms控制。</p>
<h3 id="Leader和Follower故障处理"><a href="#Leader和Follower故障处理" class="headerlink" title="Leader和Follower故障处理"></a>Leader和Follower故障处理</h3><p>​        这里涉及两个词：LEO指的是每个副本的offset+1，HW指的是所有副本中最小的LEO。</p>
<h4 id="Follower故障"><a href="#Follower故障" class="headerlink" title="Follower故障"></a>Follower故障</h4><p>​        当follower出现故障，会被临时踢出ISR，在恢复期间其他的服务器继续接收数据，并更新LEO和HW。等到这个follower恢复后，会先获取本地磁盘记录中故障前的HW，并将log中高于这个HW的部分删掉重新同步，因为这部分数据对于这个follower是没有验证过的。等到follower的HW等于leader的HW后，再重新加入ISR。</p>
<h4 id="Leader故障"><a href="#Leader故障" class="headerlink" title="Leader故障"></a>Leader故障</h4><p>​        Leader出现故障后，会从ISR中重新选举新Leader。为了保证数据的一致性，会将follower中HW高于leader的部分删掉，对于低于Leader的部分，重新同步。这只能保证数据的一致性，但是不能保证数据不丢失或不重复。</p>
<h3 id="Kafka-Partition自动平衡"><a href="#Kafka-Partition自动平衡" class="headerlink" title="Kafka Partition自动平衡"></a>Kafka Partition自动平衡</h3><p>​        在正常情况下，Kafka会自动把leader partition均匀的分布在集群上，来保证每台服务器的吞吐量是均匀的，但是如果某些broker出现故障，会导致这些broker上的leader会分布到其他broker上，就会导致这些broker的读写请求过多，并且这些leader在故障的broker重启后也不会自动回到之前的broker运行，就会导致集群负载不均衡。</p>
<p>​        有三个参数来优化：</p>
<ol>
<li>auto.leader.rebalance.enable，默认是true，也就是开启leader自平衡；</li>
<li>leader.imbalance.per.broker.percentage，默认是10%，当一个broker的不平衡率到达10%会触发自平衡；</li>
<li>leader.imbalance.check.interval.seconds，默认300s，每过300s检查一次不平衡率。</li>
</ol>
<p>​        不平衡率的计算是，假设一个分区中，leader的brokerid是0，ar队列是 [1,0,2,3]，那么不平衡数会依次比较ar队列和leader的id，如果不相等不平衡数会加一，然后再除以副本总数，也就是这里面的 1/4&gt;10% ，那么就会触发自平衡。</p>
<p>​        在生产环境中，这个自平衡不建议开，或者也可以把不平衡率调高，因为自平衡的过程回暂停这个分区的运行，直到平衡完，效率不高。</p>
<h3 id="Broker-文件存储机制"><a href="#Broker-文件存储机制" class="headerlink" title="Broker 文件存储机制"></a>Broker 文件存储机制</h3><p>​        Kafka中，topic只是一个逻辑概念，实际存储的是partition。每个partition对应一个log文件，这个log用于存储发布的数据，生产者会将生产的数据不断追加到log文件的结尾，为了避免log文件过大导致定位效率低下，将一个log文件切分为多个segment存储，一个segment是1G，里面主要包含的文件有.log存储实际的文件、.index存储.log中数据的索引、.timeindex存储索引进入的时间戳，因为数据默认是保存7天，这个时间戳文件用于在规定时间到后删除数据。</p>
<p>​        一个partition的数据会存在一个文件夹下，以 topic名称-分区号 命名，其中每个segment下的文件以当前segment的第一条消息的offset命名。</p>
<p>​        其中，index是稀疏索引，大约每往log中插入4k的数据会写入一条索引，这个4k可以通过 log.index.interval.bytes 修改。index文件中存放的offset是相对的offset，这样能够确保offset的值所占空间不会太大，因此能将offset控制在固定大小。</p>
<p>​        比如想要在log中定位 offset = 600 的数据，会先比较index文件的文件名，找到小于600的最大的值，定位到这个index文件，然后在index文件中找到绝对offset中小于600的最大的offset，因为文件中存的是相对offset，那么绝对offset旧等于文件名对应的值加上这个相对offset，然后取出这个offset对应的position，也就是log文件中这个offset的起始位置，就能得到log中offset为600的数据了。</p>
<h3 id="文件清理策略"><a href="#文件清理策略" class="headerlink" title="文件清理策略"></a>文件清理策略</h3><p>​        Kafka中默认的日志保存时间是7天，可以通过调整如下参数来修改保存时间：</p>
<ol>
<li>log.retention.hours，设置保存的小时数，默认7天；</li>
<li>log.retention.minutes，设置保存的分钟数，设置这个，小时数的参数就不起作用；</li>
<li>log.retention.ms，设置保存的毫秒数，设置这个，分钟数举不起作用。</li>
<li>log.retention.check.intervals.ms，设置检查的周期，默认是5分钟，这个值应该要比保存时间要小。</li>
</ol>
<p>​        一旦数据超过了保存的时间，就会触发清理。清理的策略有delete和compact。默认的策略是删除。</p>
<p>​        删除就是当一个segment中最新写入的数据超过这个保存的时间，就会把这个segment删掉。压缩是对相同key的不同value值，只保留最新版本的数据。压缩后的offset实际是不连续的，只适用于一些特殊场景，比如key是用户id，value是用户资料，可以只保留用户最近的资料。如果想要设置清理策略为compact，可以修改参数 log.cleanup.policy = compact 。</p>
<h3 id="Kafka怎么实现高效读写（高频面试）"><a href="#Kafka怎么实现高效读写（高频面试）" class="headerlink" title="Kafka怎么实现高效读写（高频面试）"></a>Kafka怎么实现高效读写（高频面试）</h3><ol>
<li>Kafka本身是分布式集群，采用分区技术，并行度高；</li>
<li>读数据采用稀疏索引，可以快速定位要消费的数据；</li>
<li>producer发布数据的时候，是顺序追加到log文件的，可以减少寻址时间；</li>
<li>采用零拷贝+页缓存的技术。</li>
</ol>
<p><strong>页缓存：</strong></p>
<p>​        首先我们知道文件都是存储在本地磁盘的，每次读写文件肯定都会经过磁盘IO，为了减少磁盘IO的次数，提升读写的效率，于是引入了页缓存。Linux内核会将文件以页的大小划分为多个数据块，默认是4kb一页。</p>
<p>​        当用户执行读操作，如果读取的这个数据存在页缓存，就直接从页缓存拷贝对应的数据返回；否则内核会申请一个空闲的页缓存，然后从文件中读取数据块到页缓存，再将数据从页缓存拷贝给用户。</p>
<p>​        当用户执行写操作，如果要写入的数据所在的页缓存已经存在，那么会直接写入页缓存，否则内核会申请一个空闲的页缓存，然后从文件中读取数据块到页缓存再将用户插入的数据写到页缓存，对于被修改的页缓存，内核会定时刷新到文件中。</p>
<p>​        Kafka重度依赖于底层的页缓存功能，读写操作都会在页缓存上执行，这样相比于直接操作磁盘的效率就高得多。</p>
<p><strong>零拷贝：</strong></p>
<p>​        kafka将数据的加工处理操作都交给生产者和消费者，本身不用于存储数据，所以数据的读取在查找磁盘和缓存后不需要再上传到kafka，而是直接通过网卡发送给消费者，提高了传输的效率。</p>
<h3 id="消费者的总体工作流程"><a href="#消费者的总体工作流程" class="headerlink" title="消费者的总体工作流程"></a>消费者的总体工作流程</h3><p>​        由于消费者之间互相独立，那么传输的速度肯定不可能一致，所以消费者的消费是主动从leader拉取数据的过程。一个消费者可以消费多个分区，但是一个分区只能被消费者组中的一个消费者消费。为了避免消费者挂掉重启后重复消费数据，会记录分区中最新读取到的offset。在0.9版本之前，这个信息是存储在zookeeper上的，但是由于所有消费者都需要通过网络和zookeeper交互获取offset，效率太低，在0.9版本之后改为使用本地的系统主题来存储offset，因为kafka中的主题数据最终都是存储在磁盘，所以可靠性得到保证。在系统主题中，使用kv的形式存储，key是 groupid+topic+分区号，value是当前offset的值。每隔一段时间，kafka会对系统主题中的数据进行压缩，也就是每个key只保留最新的数据。</p>
<h3 id="消费者组的初始化流程（重点）"><a href="#消费者组的初始化流程（重点）" class="headerlink" title="消费者组的初始化流程（重点）"></a>消费者组的初始化流程（重点）</h3><p>​        通过使用coordinator来辅助实现消费者组的初始化和分区的分配。每个broker都存在一个coordinator。首先使用消费者组的groupid的hash值对存储offset的系统主题的分区数，默认是50取模，然后选择这个分区所在的broker上coordinator进行之后的操作。</p>
<ol>
<li>每个consumer都会往这个coodinator上发送加入这个消费者组的请求；</li>
<li>coodinator会随机从这些请求的消费者中选出一个leader，并将接收到的所有信息都发给这个leader；</li>
<li>leader负责指定消费的方案，也就是哪个consumer消费哪个分区；</li>
<li>制定完后发回给coordinator，然后coordinator群发给所有的consumer；</li>
<li>每个consumer都会和coordinator保持默认3秒的心跳通信，也就是会定期汇报自己还活着，一旦超过 session.timeout.ms 参数默认的时间45s，该消费者就会被移除出组，并触发再平衡，或者这个消费者处理消息的时间超过 max.poll.interval.ms 默认是5分钟，也会触发再平衡。</li>
</ol>
<h3 id="消费者组具体消费流程"><a href="#消费者组具体消费流程" class="headerlink" title="消费者组具体消费流程"></a>消费者组具体消费流程</h3><p>​        首先会创建一个消费者网络连接客户端，这个客户端主要用于和kafka集群进行交互。consumer会像这个客户端通过sendFetches方法发送消费请求，然后客户端通过send方法将这个请求发送给对应的leader，然后通过回调函数onSuccess()拉取数据到completedFetches队列中，然后消费者就可以调用fetchedRecords方法到这个队列中拉取数据，拉取到的数据回先经过反序列和拦截器对数据进行转换和加工，之后就可以处理数据了。</p>
<p>​        其中涉及到几个参数：对于每批次能够拉取的数据量，最小拉取量为 fetch.min.bytes = 1字节，最大拉取量为 fetch.max.bytes=50M，如果参数 fetch.max.wait.ms = 500ms 这个时间内一个批次的数据量没有到达最小拉取量，这个批次也会被拉取。对于消费者从队列中拉取的记录数由参数 max.poll.records 设置，默认是500条。</p>
<h3 id="分区的分配和再平衡"><a href="#分区的分配和再平衡" class="headerlink" title="分区的分配和再平衡"></a>分区的分配和再平衡</h3><h4 id="分区的分配"><a href="#分区的分配" class="headerlink" title="分区的分配"></a>分区的分配</h4><p>​        也就是如何规定哪个consumer消费哪个分区。kafka提供了四种分配策略：range、rangeRobin、Sticky、CooporativeSticky。默认使用的是rage+CooporativeSticky策略，配置的参数是 partition.assignment.strategy 。可以同时使用多个策略。</p>
<h5 id="Range分配"><a href="#Range分配" class="headerlink" title="Range分配"></a>Range分配</h5><p>​        Range是针对每个topic来说的。会将这个topic中的分区按照序号排序，然后将consumer按照字母顺序排序。将分区数除以消费者数，得到每个消费者消费的分区数，如果除不尽就交由前面的消费者分别处理一个分区。</p>
<p>​        比如有8个分区，3个消费者，8 / 3 = 2 …… 2，那么第一个消费者消费0-2的分区，第二个消费者消费3-5的分区，第三个消费者消费6-7的分区。</p>
<p>​        这种模式如果在消费多topic的情况下，前面的消费者处理的内容就会很多，那么就容易造成数据倾斜。</p>
<p>​        这种模式下，如果消费者组的某个消费者出现故障，那么这个消费者负责的分区正在处理的操作会全部分配到另一个消费者上，等到处理完这一波，下一次接收数据的时候，再根据range策略重新分配分区。</p>
<h5 id="RangeRobin分配以及再平衡"><a href="#RangeRobin分配以及再平衡" class="headerlink" title="RangeRobin分配以及再平衡"></a>RangeRobin分配以及再平衡</h5><p>​        RangeRobin是针对所有topic来说的。会将所有topic的分区和所有consumer都列出来，按照hashcode排序，最后通过轮询算法来分配分区。</p>
<p>​        如果某个消费者出现故障，这个消费者负责的分区依然会按照轮询的策略均分给其他的消费者。</p>
<h5 id="Sticky分配以及再平衡"><a href="#Sticky分配以及再平衡" class="headerlink" title="Sticky分配以及再平衡"></a>Sticky分配以及再平衡</h5><p>​        是0.11版本引入的，首先会尽量均衡的分配分区，如果同消费组的某个消费者出现问题，会尽量保证原有分配的分区不变化。</p>
<p>​        该策略的首次分配和Range很像，但是粘性策略不进行排序。如果某个消费者出现故障，会将这个消费者负责的分区尽量均衡分配到其他分区上。这个再平衡的过程会让所有消费者放弃原有分区进行重分配。</p>
<h5 id="CooporativeSticky分配以及再平衡"><a href="#CooporativeSticky分配以及再平衡" class="headerlink" title="CooporativeSticky分配以及再平衡"></a>CooporativeSticky分配以及再平衡</h5><p>​        这个策略和Sticky策略很像，但是在消费者故障之后，不会让所有其他消费者放弃已有分区进行全局重平衡，而是改成多次小规模分区重平衡。</p>
<h3 id="Offset的保存和提交"><a href="#Offset的保存和提交" class="headerlink" title="Offset的保存和提交"></a>Offset的保存和提交</h3><h4 id="Offset的保存"><a href="#Offset的保存" class="headerlink" title="Offset的保存"></a>Offset的保存</h4><p>​        在0.9版本之前使用zookeeper存储，但是所有的消费者都和zookeeper进行交互，效率就会很低，所以在0.9版本之后引入了系统主题来存储offset。存储的是kv形式的数据，key保存 groupid+topic+分区号，value保存当前offset的位置。kafka每隔一段时间就会对系统主题的内容进行压缩，也就是只保留每个key中最新的数据。</p>
<h4 id="Offset的提交"><a href="#Offset的提交" class="headerlink" title="Offset的提交"></a>Offset的提交</h4><h5 id="自动提交"><a href="#自动提交" class="headerlink" title="自动提交"></a>自动提交</h5><p>​        enable.auto.commit 默认是true，也就是默认开启自动提交的功能，auto.commit.interval.ms 默认5s自动提交一次。</p>
<p>​        具体的提交流程是：consumer不断的从分区拉取数据，然后每隔5s向系统主题提交一次当前拉取的offset。</p>
<h5 id="手动提交"><a href="#手动提交" class="headerlink" title="手动提交"></a>手动提交</h5><p>​        自动提交虽然便利，但是因为是基于时间提交的，所以提交时机不好把控。于是kafka提供了手动提交的api实现。</p>
<p>​        手动提交的方式有两种：同步和异步。二者都是将本次提交的最高偏移量提交。不同的是，同步提交是等到offset提交到系统主题完成后再拉取下一波数据，这种模式会阻塞当前线程直到提交成功，并在失败时重试；异步提交是发送完offset提交请求后就继续拉取下一波数据了，不会进行失败重试，可能提交失败。</p>
<p>​        设置手动提交，需要配置ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG参数为true，并调用kafkaConsumer.commitSync()执行同步或commitAsync()执行异步。</p>
<h4 id="指定offset消费"><a href="#指定offset消费" class="headerlink" title="指定offset消费"></a>指定offset消费</h4><p>​        通过参数 auto.offset.reset 指定消费的位置。包括三种：</p>
<ol>
<li>earliest：从分区最开始的位置消费；</li>
<li>latest：从分区最新的位置开始消费，这是默认值；</li>
<li>none：如果没有找到消费者组之前消费的位置，会向消费者抛出异常。</li>
</ol>
<p>​        如果既不想从开始的位置消费，也不想从最新的位置消费，而是想从中间的某个指定位置开始消费，可以在代码中手动指定：consumer.seek(partition, offset) 。因为消费者组的初始化过程会消耗一定时间，而在代码中因为是顺序执行，可能在还没有分配完分区就已经执行到这个代码，就会导致获取不到数据。为了避免这个错误，可以指定消费之前使用 while 循环，在还没有制定好分配方案时不往下进行，并在循环中频繁获取分区信息，一旦分配完毕就立刻退出。</p>
<h3 id="消费者事务"><a href="#消费者事务" class="headerlink" title="消费者事务"></a>消费者事务</h3><h4 id="重复消费和漏消费"><a href="#重复消费和漏消费" class="headerlink" title="重复消费和漏消费"></a>重复消费和漏消费</h4><p>​        重复消费一般是由自动提交引起的。具体的过程是：consumer默认会5s提交一次offset，并且在发送完这个提交请求后继续拉取数据。假设提交这个offset = 2 的请求完成后，这个consumer消费到offset = 4的时候挂掉了，此时因为还没到5s，所以还没有发送请求，再次重启就会从offset=2的位置继续消费，那么offset&gt;2&amp;&amp;offset&lt;=4的位置的数据就被重复消费了。</p>
<p>​        漏消费的场景是：假设offset设置为手动提交，当consumer拉取数据，并向系统主题提交offset的时候，当offset提交完成，但是数据还没有完全落盘的时候，这个消费者挂掉了，这个时候就会导致还未落盘的这部分数据丢失。</p>
<h4 id="消费者事务解决重复消费和漏消费"><a href="#消费者事务解决重复消费和漏消费" class="headerlink" title="消费者事务解决重复消费和漏消费"></a>消费者事务解决重复消费和漏消费</h4><p>​        想要完成consumer端的一次性精准消费，就需要将消费的过程和提交offset的过程作为一个事务进行处理，同时消费者需要支持事务，比如mysql，如果是hbase这种不支持事务回滚的消费者，所以是会存在问题的。</p>
<p>​        想要完全做到整条路线的精确一次消费，除了消费端要使用事务，生产者也需要采用幂等性+事务的特性，同时也需要做到ack=-1、副本数大于等于2、isr最小应答数大于等于2。</p>
<h3 id="数据积压（消费者如何提高吞吐量）（重要）"><a href="#数据积压（消费者如何提高吞吐量）（重要）" class="headerlink" title="数据积压（消费者如何提高吞吐量）（重要）"></a>数据积压（消费者如何提高吞吐量）（重要）</h3><ol>
<li>如果是kafka的topic数据量大，导致消费速度慢，可以考虑增加分区，但是多个分区使用一个消费者消费也不会很快，于是需要同时提升二者的数量，保证消费者数 == 分区数。</li>
<li>如果是批次拉取的数据量过少，导致处理的数据小于生产的数据，也会造成数据积压，对于这种情况可以提高每批次拉取的数据量。</li>
</ol>

    </div>

    
    
    
	  
	
	 <div>
		<div>
    
        <div style="text-align:center;color: #ccc;font-size:24px;">-------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------</div>
    
</div>
	 </div>
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/kafka/" rel="tag"># kafka</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/03/03/flume%E9%9D%A2%E8%AF%95%E9%A2%98/" rel="prev" title="flume面试题">
      <i class="fa fa-chevron-left"></i> flume面试题
    </a></div>
      <div class="post-nav-item">
    <a href="/2022/03/08/Sqoop%E9%9D%A2%E8%AF%95%E9%A2%98/" rel="next" title="Sqoop面试题">
      Sqoop面试题 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka-%E7%9A%84%E6%A6%82%E5%BF%B5"><span class="nav-number">1.</span> <span class="nav-text">Kafka 的概念</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AE%9A%E4%B9%89"><span class="nav-number">1.1.</span> <span class="nav-text">定义</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF%EF%BC%88%E4%BD%BF%E7%94%A8%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%9A%84%E5%8E%9F%E5%9B%A0%EF%BC%8C%E5%BA%94%E8%AF%A5%E4%B9%9F%E5%8F%AF%E4%BB%A5%E7%9C%8B%E6%88%90%E6%98%AF%E4%BD%BF%E7%94%A8kafka%E7%9A%84%E5%8E%9F%E5%9B%A0%EF%BC%89"><span class="nav-number">1.2.</span> <span class="nav-text">应用场景（使用消息队列的原因，应该也可以看成是使用kafka的原因）</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%A8%A1%E5%BC%8F%EF%BC%88%E4%BC%A0%E7%BB%9F%E7%9A%84%E6%B6%88%E6%81%AF%E4%BC%A0%E9%80%92%E6%96%B9%E5%BC%8F%EF%BC%89"><span class="nav-number">2.</span> <span class="nav-text">消息队列的两种模式（传统的消息传递方式）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%82%B9%E5%AF%B9%E7%82%B9%E6%A8%A1%E5%BC%8F"><span class="nav-number">2.1.</span> <span class="nav-text">点对点模式</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8F%91%E5%B8%83%E8%AE%A2%E9%98%85%E6%A8%A1%E5%BC%8F"><span class="nav-number">2.2.</span> <span class="nav-text">发布订阅模式</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Kafka%E7%9B%B8%E8%BE%83%E4%BA%8E%E4%BC%A0%E7%BB%9F%E6%B6%88%E6%81%AF%E4%BC%A0%E9%80%92%E7%9A%84%E4%BC%98%E5%8A%BF"><span class="nav-number">2.3.</span> <span class="nav-text">Kafka相较于传统消息传递的优势</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84"><span class="nav-number">3.</span> <span class="nav-text">Kafka基础架构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka%E5%8F%91%E5%B8%83%E6%95%B0%E6%8D%AE%E7%9A%84%E6%B5%81%E7%A8%8B"><span class="nav-number">4.</span> <span class="nav-text">Kafka发布数据的流程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka%E5%90%8C%E6%AD%A5%E5%8F%91%E9%80%81%E5%92%8C%E5%BC%82%E6%AD%A5%E5%8F%91%E9%80%81"><span class="nav-number">5.</span> <span class="nav-text">Kafka同步发送和异步发送</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka-%E5%88%86%E5%8C%BA"><span class="nav-number">6.</span> <span class="nav-text">Kafka 分区</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8%E5%88%86%E5%8C%BA%E7%9A%84%E5%A5%BD%E5%A4%84%EF%BC%9A"><span class="nav-number">6.1.</span> <span class="nav-text">使用分区的好处：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%88%86%E5%8C%BA%E7%AD%96%E7%95%A5%EF%BC%9A"><span class="nav-number">6.2.</span> <span class="nav-text">分区策略：</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka%E4%B8%A2%E4%B8%8D%E4%B8%A2%E6%95%B0%E6%8D%AE%E5%92%8C%E5%BA%94%E7%AD%94%E6%9C%BA%E5%88%B6%E6%9C%89%E5%85%B3"><span class="nav-number">7.</span> <span class="nav-text">Kafka丢不丢数据和应答机制有关</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka-%E6%95%B0%E6%8D%AE%E9%87%8D%E5%A4%8D"><span class="nav-number">8.</span> <span class="nav-text">Kafka 数据重复</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%94%9F%E4%BA%A7%E8%80%85%E5%A6%82%E4%BD%95%E6%8F%90%E9%AB%98%E5%90%9E%E5%90%90%E9%87%8F"><span class="nav-number">9.</span> <span class="nav-text">生产者如何提高吞吐量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%94%9F%E4%BA%A7%E8%80%85%E5%8F%91%E5%B8%83%E7%9A%84%E6%95%B0%E6%8D%AE%E4%B9%B1%E5%BA%8F%E7%9A%84%E9%97%AE%E9%A2%98%EF%BC%88%E9%9D%A2%E8%AF%95%E9%87%8D%E7%82%B9%EF%BC%89"><span class="nav-number">10.</span> <span class="nav-text">生产者发布的数据乱序的问题（面试重点）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E4%B9%B1%E5%BA%8F%E7%9A%84%E4%BA%A7%E7%94%9F"><span class="nav-number">10.1.</span> <span class="nav-text">数据乱序的产生</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E4%B9%B1%E5%BA%8F%E7%9A%84%E8%A7%A3%E5%86%B3"><span class="nav-number">10.2.</span> <span class="nav-text">数据乱序的解决</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Broker-ZK%E5%AD%98%E5%82%A8%E5%86%85%E5%AE%B9"><span class="nav-number">11.</span> <span class="nav-text">Broker ZK存储内容</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Broker%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B"><span class="nav-number">12.</span> <span class="nav-text">Broker工作流程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka%E5%89%AF%E6%9C%AC"><span class="nav-number">13.</span> <span class="nav-text">Kafka副本</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Leader%E5%92%8CFollower%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86"><span class="nav-number">14.</span> <span class="nav-text">Leader和Follower故障处理</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Follower%E6%95%85%E9%9A%9C"><span class="nav-number">14.1.</span> <span class="nav-text">Follower故障</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Leader%E6%95%85%E9%9A%9C"><span class="nav-number">14.2.</span> <span class="nav-text">Leader故障</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka-Partition%E8%87%AA%E5%8A%A8%E5%B9%B3%E8%A1%A1"><span class="nav-number">15.</span> <span class="nav-text">Kafka Partition自动平衡</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Broker-%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E6%9C%BA%E5%88%B6"><span class="nav-number">16.</span> <span class="nav-text">Broker 文件存储机制</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%96%87%E4%BB%B6%E6%B8%85%E7%90%86%E7%AD%96%E7%95%A5"><span class="nav-number">17.</span> <span class="nav-text">文件清理策略</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka%E6%80%8E%E4%B9%88%E5%AE%9E%E7%8E%B0%E9%AB%98%E6%95%88%E8%AF%BB%E5%86%99%EF%BC%88%E9%AB%98%E9%A2%91%E9%9D%A2%E8%AF%95%EF%BC%89"><span class="nav-number">18.</span> <span class="nav-text">Kafka怎么实现高效读写（高频面试）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E7%9A%84%E6%80%BB%E4%BD%93%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B"><span class="nav-number">19.</span> <span class="nav-text">消费者的总体工作流程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E6%B5%81%E7%A8%8B%EF%BC%88%E9%87%8D%E7%82%B9%EF%BC%89"><span class="nav-number">20.</span> <span class="nav-text">消费者组的初始化流程（重点）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84%E5%85%B7%E4%BD%93%E6%B6%88%E8%B4%B9%E6%B5%81%E7%A8%8B"><span class="nav-number">21.</span> <span class="nav-text">消费者组具体消费流程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%86%E5%8C%BA%E7%9A%84%E5%88%86%E9%85%8D%E5%92%8C%E5%86%8D%E5%B9%B3%E8%A1%A1"><span class="nav-number">22.</span> <span class="nav-text">分区的分配和再平衡</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%88%86%E5%8C%BA%E7%9A%84%E5%88%86%E9%85%8D"><span class="nav-number">22.1.</span> <span class="nav-text">分区的分配</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Range%E5%88%86%E9%85%8D"><span class="nav-number">22.1.1.</span> <span class="nav-text">Range分配</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#RangeRobin%E5%88%86%E9%85%8D%E4%BB%A5%E5%8F%8A%E5%86%8D%E5%B9%B3%E8%A1%A1"><span class="nav-number">22.1.2.</span> <span class="nav-text">RangeRobin分配以及再平衡</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Sticky%E5%88%86%E9%85%8D%E4%BB%A5%E5%8F%8A%E5%86%8D%E5%B9%B3%E8%A1%A1"><span class="nav-number">22.1.3.</span> <span class="nav-text">Sticky分配以及再平衡</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#CooporativeSticky%E5%88%86%E9%85%8D%E4%BB%A5%E5%8F%8A%E5%86%8D%E5%B9%B3%E8%A1%A1"><span class="nav-number">22.1.4.</span> <span class="nav-text">CooporativeSticky分配以及再平衡</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Offset%E7%9A%84%E4%BF%9D%E5%AD%98%E5%92%8C%E6%8F%90%E4%BA%A4"><span class="nav-number">23.</span> <span class="nav-text">Offset的保存和提交</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Offset%E7%9A%84%E4%BF%9D%E5%AD%98"><span class="nav-number">23.1.</span> <span class="nav-text">Offset的保存</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Offset%E7%9A%84%E6%8F%90%E4%BA%A4"><span class="nav-number">23.2.</span> <span class="nav-text">Offset的提交</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%87%AA%E5%8A%A8%E6%8F%90%E4%BA%A4"><span class="nav-number">23.2.1.</span> <span class="nav-text">自动提交</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%89%8B%E5%8A%A8%E6%8F%90%E4%BA%A4"><span class="nav-number">23.2.2.</span> <span class="nav-text">手动提交</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%8C%87%E5%AE%9Aoffset%E6%B6%88%E8%B4%B9"><span class="nav-number">23.3.</span> <span class="nav-text">指定offset消费</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E4%BA%8B%E5%8A%A1"><span class="nav-number">24.</span> <span class="nav-text">消费者事务</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%87%8D%E5%A4%8D%E6%B6%88%E8%B4%B9%E5%92%8C%E6%BC%8F%E6%B6%88%E8%B4%B9"><span class="nav-number">24.1.</span> <span class="nav-text">重复消费和漏消费</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E4%BA%8B%E5%8A%A1%E8%A7%A3%E5%86%B3%E9%87%8D%E5%A4%8D%E6%B6%88%E8%B4%B9%E5%92%8C%E6%BC%8F%E6%B6%88%E8%B4%B9"><span class="nav-number">24.2.</span> <span class="nav-text">消费者事务解决重复消费和漏消费</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E7%A7%AF%E5%8E%8B%EF%BC%88%E6%B6%88%E8%B4%B9%E8%80%85%E5%A6%82%E4%BD%95%E6%8F%90%E9%AB%98%E5%90%9E%E5%90%90%E9%87%8F%EF%BC%89%EF%BC%88%E9%87%8D%E8%A6%81%EF%BC%89"><span class="nav-number">25.</span> <span class="nav-text">数据积压（消费者如何提高吞吐量）（重要）</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Bonnie"
      src="/images/avatar.gif">
  <p class="site-author-name" itemprop="name">Bonnie</p>
  <div class="site-description" itemprop="description">每天都要做个人啊</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">124</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">72</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2021-05 – 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Bonnie</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

  

</body>
</html>
