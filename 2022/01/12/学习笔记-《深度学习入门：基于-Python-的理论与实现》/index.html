<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="注明使用环境：Python3.x 使用外部库：Numpy用于数值计算，提供许多高级数学算法和遍历的矩阵操作方法、Matplotlib用于画图。">
<meta property="og:type" content="article">
<meta property="og:title" content="学习笔记 - 《深度学习入门：基于 Python 的理论与实现》">
<meta property="og:url" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/index.html">
<meta property="og:site_name" content="往南">
<meta property="og:description" content="注明使用环境：Python3.x 使用外部库：Numpy用于数值计算，提供许多高级数学算法和遍历的矩阵操作方法、Matplotlib用于画图。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426000100705.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426000427688.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426000610902.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426000938209.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426001052560.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426001254150.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426001358695.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426001452377.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426001734024.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426001848227.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426001914465.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426001935443.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426001949275.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426002010619.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426002025235.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426002206932.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426002430066.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426002551262.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426002713990.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426002743961.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426002843588.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426003432777.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426003632591.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426003641823.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426003830730.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426003906712.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426004352199.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426004533178.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426004547967.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426004204695.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426004625771.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426004726650.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426004736859.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426005246347.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426005310463.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426005322420.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426143246606.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426143345552.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426143509707.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426143624707.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426143654909.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426143910870.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426143951321.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426144018599.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426144034719.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426144112787.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426144123604.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426144457279.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426144525475.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426144557653.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426144633711.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426145019262.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426144934584.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426145512028.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426145548000.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426145601621.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426150022713.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426150030572.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426150057848.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426185709724.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426185943428.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426190752746.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426190826642.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426190939789.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426190959268.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426191411012.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426192318957.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426192609627.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426193212398.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426193406450.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426193557061.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426193824647.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426194301454.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426194340088.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426214159646.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426214241551.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426214449531.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426214930956.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426214952256.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426215011476.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426215050183.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426215335478.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426215536201.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426215548770.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426215700761.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426215923793.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426220115941.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426220304570.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426220339963.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426220356276.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426222201919.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426222529844.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426223001804.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426223048743.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426223236994.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426223312562.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426223608649.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426223756732.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426224044214.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426224116511.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426230904232.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426230952411.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426231031054.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426232151961.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426232202960.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426232405992.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426232721900.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426232405992.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426232907752.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426232924935.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426233047105.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426233223625.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426233238444.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426233401348.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426233438942.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426233646760.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426233814793.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426233956190.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426234116958.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426234134743.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426234155853.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426234425589.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426234534013.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426234555220.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426234908519.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426234937456.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426235700380.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426235825192.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426235924724.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426235935415.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427000311931.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427000323295.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427000516017.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427000847184.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427000922610.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427000958525.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427001255137.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427001143764.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427001205651.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427001315762.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427001605936.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427001633007.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427001731531.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427001854838.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427002356362.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427002510717.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427002550906.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427002825649.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427002847884.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427003030448.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427003105044.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427003356814.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427003659412.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427003738332.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427003745695.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427004002717.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427004055377.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427004202665.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427004258867.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427004444343.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427004748867.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427004837325.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427005130183.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427005241022.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427005256357.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427005308840.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427005318490.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427005556833.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427005929093.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427010050958.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427010258290.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427010420838.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427010543431.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427010656964.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427010743137.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427010818249.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427010935469.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427010953855.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427115918643.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427120013576.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427120157004.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427120339167.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427120706280.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427120845813.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427121059722.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427121124056.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427121210155.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427121643026.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427121934492.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427122017735.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427122045024.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427122643411.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427123242448.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427123355144.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427123421740.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427141329524.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427141519012.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427141542668.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427142233531.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427142327790.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427143107610.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427143201536.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427144342320.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427144355432.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427144417412.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427144429993.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427144453058.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427144504023.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427144514755.png">
<meta property="og:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427145959397.png">
<meta property="article:published_time" content="2022-01-11T16:12:28.000Z">
<meta property="article:modified_time" content="2022-05-02T17:01:03.563Z">
<meta property="article:author" content="Bonnie">
<meta property="article:tag" content="python">
<meta property="article:tag" content="深度学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426000100705.png">

<link rel="canonical" href="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>学习笔记 - 《深度学习入门：基于 Python 的理论与实现》 | 往南</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">往南</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-resources">

    <a href="/resources/" rel="section"><i class="download fa-fw"></i>资源</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/01/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8E-Python-%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Bonnie">
      <meta itemprop="description" content="每天都要做个人啊">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="往南">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          学习笔记 - 《深度学习入门：基于 Python 的理论与实现》
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-01-12 00:12:28" itemprop="dateCreated datePublished" datetime="2022-01-12T00:12:28+08:00">2022-01-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-05-03 01:01:03" itemprop="dateModified" datetime="2022-05-03T01:01:03+08:00">2022-05-03</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">学习笔记</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="注明"><a href="#注明" class="headerlink" title="注明"></a>注明</h2><p>使用环境：<strong>Python3.x</strong></p>
<p>使用外部库：<strong>Numpy</strong>用于数值计算，提供许多高级数学算法和遍历的矩阵操作方法、<strong>Matplotlib</strong>用于画图。</p>
<span id="more"></span>
<h2 id="Python入门"><a href="#Python入门" class="headerlink" title="Python入门"></a>Python入门</h2><h3 id="python解释器（基本的使用）"><a href="#python解释器（基本的使用）" class="headerlink" title="python解释器（基本的使用）"></a>python解释器（基本的使用）</h3><h4 id="版本查询"><a href="#版本查询" class="headerlink" title="版本查询"></a>版本查询</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;python --version</span><br></pre></td></tr></table></figure>
<p>进入 python 命令行：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;python</span><br></pre></td></tr></table></figure>
<h4 id="算术运算"><a href="#算术运算" class="headerlink" title="算术运算"></a>算术运算</h4><ol>
<li><p>加（+）减（-）乘（*）与Java一致；</p>
</li>
<li><p><strong>除</strong>有两种情况：<code>/</code> 结果是小数，<code>//</code> 结果是整数；</p>
</li>
<li>** 乘方。</li>
</ol>
<h4 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h4><p>使用 <code>type()</code> 获取。</p>
<h4 id="变量"><a href="#变量" class="headerlink" title="变量"></a>变量</h4><p>直接赋值。如 <code>x = 10</code> 即可。</p>
<p>变量的类型是根据赋值情况自动决定的，赋值的是计算结果，也会自动转换为更大的一边。</p>
<h4 id="注释"><a href="#注释" class="headerlink" title="注释"></a>注释</h4><p>使用 <code>#</code> 后的内容会被注释。</p>
<h4 id="列表"><a href="#列表" class="headerlink" title="列表"></a>列表</h4><p>如 <code>arr = [1,2,3,4]</code></p>
<p>提供切片的方式访问某个值或某个子列表。如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;arr[<span class="number">0</span>] <span class="comment"># == 1</span></span><br><span class="line">&gt;&gt;&gt;arr[<span class="number">1</span>:] <span class="comment"># == [2,3,4]</span></span><br><span class="line">&gt;&gt;&gt;arr[<span class="number">1</span>:<span class="number">3</span>] <span class="comment"># == [2,3]</span></span><br><span class="line">&gt;&gt;&gt;arr[:<span class="number">3</span>] <span class="comment"># == [1,2,3]</span></span><br><span class="line">&gt;&gt;&gt;arr[:-<span class="number">1</span>] <span class="comment"># 从第一个元素到最后一个元素，不包括最后一个元素，即 [1,2,3]</span></span><br><span class="line">&gt;&gt;&gt;arr[:-<span class="number">2</span>] <span class="comment"># 从第一个元素到倒数第二个元素，不包括最后两个元素，即[1,2]</span></span><br></pre></td></tr></table></figure>
<h4 id="字典"><a href="#字典" class="headerlink" title="字典"></a>字典</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>me = &#123;<span class="string">&#x27;height&#x27;</span>:<span class="number">180</span>&#125; <span class="comment"># 生成字典 </span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>me[<span class="string">&#x27;height&#x27;</span>]        <span class="comment"># 访问元素 180 </span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>me[<span class="string">&#x27;weight&#x27;</span>] = <span class="number">70</span>   <span class="comment"># 添加新元素 </span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(me) &#123;<span class="string">&#x27;height&#x27;</span>: <span class="number">180</span>, <span class="string">&#x27;weight&#x27;</span>: <span class="number">70</span>&#125;</span><br></pre></td></tr></table></figure>
<h4 id="bool"><a href="#bool" class="headerlink" title="bool"></a>bool</h4><p>取 <code>True</code> 或 <code>False</code>，针对的运算符有：<code>and</code> 、<code>or</code> 、<code>not</code> 。</p>
<h4 id="if-语句"><a href="#if-语句" class="headerlink" title="if 语句"></a>if 语句</h4><p>参考以下代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> hungry:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;赶紧去吃饭&quot;</span>)</span><br><span class="line"><span class="keyword">elif</span> sleepy:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;赶紧去睡觉&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;那就再运动一会&quot;</span>)</span><br></pre></td></tr></table></figure>
<h4 id="for-语句"><a href="#for-语句" class="headerlink" title="for 语句"></a>for 语句</h4><p>参考一下代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]:</span><br><span class="line">	<span class="built_in">print</span>(i)</span><br><span class="line"><span class="comment"># 1 2 3 4</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">    <span class="built_in">print</span>(i)</span><br><span class="line"><span class="comment"># 0 1 2 3</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">4</span>):</span><br><span class="line">    <span class="built_in">print</span>(i)</span><br><span class="line"><span class="comment"># 1 2 3</span></span><br></pre></td></tr></table></figure>
<h4 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="function"><span class="keyword">def</span> <span class="title">hello</span>():</span> </span><br><span class="line"><span class="meta">... </span>   <span class="built_in">print</span>(<span class="string">&quot;Hello World!&quot;</span>) ... </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>hello() </span><br><span class="line">Hello World!</span><br><span class="line"><span class="comment"># 此外，函数可以取参数。</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="function"><span class="keyword">def</span> <span class="title">hello</span>(<span class="params"><span class="built_in">object</span></span>):</span> </span><br><span class="line"><span class="meta">... </span>   <span class="built_in">print</span>(<span class="string">&quot;Hello &quot;</span> + <span class="built_in">object</span> + <span class="string">&quot;!&quot;</span>) ... </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>hello(<span class="string">&quot;cat&quot;</span>) </span><br><span class="line">Hello cat!</span><br></pre></td></tr></table></figure>
<h3 id="python脚本文件"><a href="#python脚本文件" class="headerlink" title="python脚本文件"></a>python脚本文件</h3><h4 id="保存为文件的步骤"><a href="#保存为文件的步骤" class="headerlink" title="保存为文件的步骤"></a>保存为文件的步骤</h4><ol>
<li><p>新建一个名为 <code>hungry.py</code> 的文件，内容：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;I am hungry!&quot;</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>执行命令：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python hungry.py</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h4 id="类"><a href="#类" class="headerlink" title="类"></a>类</h4><p>模板：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> 类名:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, 参数, …</span>):</span> <span class="comment"># 构造函数</span></span><br><span class="line">        ...</span><br><span class="line">    <span class="function"><span class="keyword">def</span> 方法名1(<span class="params">self, 参数, …</span>):</span> <span class="comment"># 方法1</span></span><br><span class="line">        ...</span><br><span class="line">    <span class="function"><span class="keyword">def</span> 方法名2(<span class="params">self, 参数, …</span>):</span> <span class="comment"># 方法2</span></span><br><span class="line">        ...</span><br></pre></td></tr></table></figure>
<p>其中， <code>__init__</code> 进行初始化的方法，也称为构造 函数（constructor），只在生成类的实例时被调用一次。</p>
<p>实例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Man</span>:</span></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, name</span>):</span></span><br><span class="line">        self.name = name</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Initialized!&quot;</span>)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">hello</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Hello &quot;</span> + self.name + <span class="string">&quot;!&quot;</span>)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">goodbye</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Good-bye &quot;</span> + self.name + <span class="string">&quot;!&quot;</span>)</span><br><span class="line">m = Man(<span class="string">&quot;David&quot;</span>)</span><br><span class="line">m.hello()</span><br><span class="line">m.goodbye()</span><br></pre></td></tr></table></figure>
<p>结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ python man.py</span><br><span class="line">Initialized!</span><br><span class="line">Hello David!</span><br><span class="line">Good-bye David!</span><br></pre></td></tr></table></figure>
<h3 id="Numpy"><a href="#Numpy" class="headerlink" title="Numpy"></a>Numpy</h3><h4 id="导入"><a href="#导入" class="headerlink" title="导入"></a>导入</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure>
<h4 id="Numpy数组"><a href="#Numpy数组" class="headerlink" title="Numpy数组"></a>Numpy数组</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = np.array([<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(x)</span><br><span class="line">[ <span class="number">1.</span> <span class="number">2.</span> <span class="number">3.</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">type</span>(x)</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> &#x27;<span class="title">numpy</span>.<span class="title">ndarray</span>&#x27;&gt;</span></span><br></pre></td></tr></table></figure>
<h4 id="一维数组算术运算"><a href="#一维数组算术运算" class="headerlink" title="一维数组算术运算"></a>一维数组算术运算</h4><p>两个数组进行算术运算要求元素个数必须相同，否则会报错。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 准备两个数组</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = np.array([<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y = np.array([<span class="number">2.0</span>, <span class="number">4.0</span>, <span class="number">6.0</span>])</span><br><span class="line"><span class="comment"># 相加</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x + y </span><br><span class="line">array([ <span class="number">3.</span>,  <span class="number">6.</span>, <span class="number">9.</span>]) </span><br><span class="line"><span class="comment"># 相减</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x - y</span><br><span class="line">array([ -<span class="number">1.</span>,  -<span class="number">2.</span>, -<span class="number">3.</span>])</span><br><span class="line"><span class="comment"># 相乘</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x * y </span><br><span class="line">array([  <span class="number">2.</span>,   <span class="number">8.</span>,  <span class="number">18.</span>])</span><br><span class="line"><span class="comment"># 相除</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x / y</span><br><span class="line">array([ <span class="number">0.5</span>,  <span class="number">0.5</span>,  <span class="number">0.5</span>])</span><br><span class="line"><span class="comment"># 和单一数值计算，也叫广播</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x / <span class="number">2.0</span></span><br><span class="line">array([ <span class="number">0.5</span>,  <span class="number">1.</span> ,  <span class="number">1.5</span>])</span><br></pre></td></tr></table></figure>
<h4 id="多维数组算术运算"><a href="#多维数组算术运算" class="headerlink" title="多维数组算术运算"></a>多维数组算术运算</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>A = np.array([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(A)</span><br><span class="line">[[<span class="number">1</span> <span class="number">2</span>] [<span class="number">3</span> <span class="number">4</span>]]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>A.shape</span><br><span class="line">(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>A.dtype</span><br><span class="line">dtype(<span class="string">&#x27;int64&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>B = np.array([[<span class="number">3</span>, <span class="number">0</span>],[<span class="number">0</span>, <span class="number">6</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>A + B</span><br><span class="line">array([[ <span class="number">4</span>,  <span class="number">2</span>],</span><br><span class="line">	  [ <span class="number">3</span>, <span class="number">10</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>A * B</span><br><span class="line">array([[ <span class="number">3</span>,  <span class="number">0</span>],</span><br><span class="line">       [ <span class="number">0</span>, <span class="number">24</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>A * <span class="number">10</span></span><br><span class="line">array([[ <span class="number">10</span>, <span class="number">20</span>], </span><br><span class="line">       [ <span class="number">30</span>, <span class="number">40</span>]])</span><br></pre></td></tr></table></figure>
<p><code>shape</code> 查看行列数，<code>dtype</code> 查看数据类型。</p>
<h4 id="不同行列数的数组计算"><a href="#不同行列数的数组计算" class="headerlink" title="不同行列数的数组计算"></a>不同行列数的数组计算</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>A = np.array([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>B = np.array([<span class="number">10</span>, <span class="number">20</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>A * B</span><br><span class="line">array([[ <span class="number">10</span>, <span class="number">40</span>],</span><br><span class="line">       [ <span class="number">30</span>, <span class="number">80</span>]])</span><br></pre></td></tr></table></figure>
<p>上述例子，会将 <code>[10, 20]</code> 扩展成 <code>[[10,20],[10,20]]</code>，这种扩展功能叫广播。</p>
<h4 id="获取数组维度"><a href="#获取数组维度" class="headerlink" title="获取数组维度"></a>获取数组维度</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>A = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(A)</span><br><span class="line">[<span class="number">1</span> <span class="number">2</span> <span class="number">3</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.ndim(A)</span><br><span class="line"><span class="number">1</span></span><br></pre></td></tr></table></figure>
<p><code>np.ndim(A)</code> 获取数组A的维度为1。</p>
<h4 id="获取行列数"><a href="#获取行列数" class="headerlink" title="获取行列数"></a>获取行列数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>A = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(A)</span><br><span class="line">[<span class="number">1</span> <span class="number">2</span> <span class="number">3</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.ndim(A)</span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>A.shape</span><br><span class="line">(<span class="number">3</span>,)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>A.shape[<span class="number">0</span>]</span><br><span class="line"><span class="number">3</span></span><br></pre></td></tr></table></figure>
<p><code>A.shape</code> 的结果是个元组（tuple），也就是行列的个数，如果是 <code>1</code> 会省略。</p>
<h4 id="访问元素"><a href="#访问元素" class="headerlink" title="访问元素"></a>访问元素</h4><p>以下面数组为例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>X = np.array([[<span class="number">51</span>, <span class="number">55</span>], [<span class="number">14</span>, <span class="number">19</span>], [<span class="number">0</span>, <span class="number">4</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(X)</span><br><span class="line">[[<span class="number">51</span> <span class="number">55</span>]</span><br><span class="line"> [<span class="number">14</span> <span class="number">19</span>]</span><br><span class="line"> [ <span class="number">0</span>  <span class="number">4</span>]]</span><br><span class="line"><span class="comment"># 正常使用，获取(0, 1) 的元素</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X[<span class="number">0</span>][<span class="number">1</span>]</span><br><span class="line"><span class="number">55</span></span><br></pre></td></tr></table></figure>
<p>获取第0行：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>X[<span class="number">0</span>]    <span class="comment"># 第0行 </span></span><br><span class="line">array([<span class="number">51</span>, <span class="number">55</span>])</span><br><span class="line"><span class="comment"># 循环所有行</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> row <span class="keyword">in</span> X:</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span>(row)</span><br><span class="line">...</span><br><span class="line">[<span class="number">51</span> <span class="number">55</span>]</span><br><span class="line">[<span class="number">14</span> <span class="number">19</span>]</span><br><span class="line">[<span class="number">0</span> <span class="number">4</span>]</span><br></pre></td></tr></table></figure>
<p>将多维数组转换为一维数组：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>X = X.flatten() <span class="comment"># 将X转换为一维数组</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(X)</span><br><span class="line">[<span class="number">51</span> <span class="number">55</span> <span class="number">14</span> <span class="number">19</span>  <span class="number">0</span>  <span class="number">4</span>]</span><br></pre></td></tr></table></figure>
<p>过滤获取元素：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>X &gt; <span class="number">15</span> </span><br><span class="line">array([ <span class="literal">True</span>,  <span class="literal">True</span>, <span class="literal">False</span>,  <span class="literal">True</span>, <span class="literal">False</span>, <span class="literal">False</span>], dtype=<span class="built_in">bool</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X[X&gt;<span class="number">15</span>]</span><br><span class="line">array([<span class="number">51</span>, <span class="number">55</span>, <span class="number">19</span>])</span><br><span class="line"><span class="comment"># 获取某几个下标的元素</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X[np.array([<span class="number">0</span>, <span class="number">2</span>, <span class="number">4</span>])] <span class="comment"># 获取索引为0、2、4的元素</span></span><br><span class="line">array([<span class="number">51</span>, <span class="number">14</span>,  <span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<h3 id="Matplotlib"><a href="#Matplotlib" class="headerlink" title="Matplotlib"></a>Matplotlib</h3><h4 id="绘制简单图形"><a href="#绘制简单图形" class="headerlink" title="绘制简单图形"></a>绘制简单图形</h4><p>绘制 sin 函数图</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># 生成数据</span></span><br><span class="line">x = np.arange(<span class="number">0</span>, <span class="number">6</span>, <span class="number">0.1</span>) <span class="comment"># 以0.1为单位，生成0到6的数据</span></span><br><span class="line">y = np.sin(x)</span><br><span class="line"><span class="comment"># 绘制图形</span></span><br><span class="line">plt.plot(x, y)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h4 id="pyplot"><a href="#pyplot" class="headerlink" title="pyplot"></a>pyplot</h4><p>追加cos函数的图形，并尝试使用 pyplot的添加标题和x轴标签名等其他功能。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># 生成数据</span></span><br><span class="line">x = np.arange(<span class="number">0</span>, <span class="number">6</span>, <span class="number">0.1</span>) <span class="comment"># 以0.1为单位，生成0到6的数据</span></span><br><span class="line">y1 = np.sin(x)</span><br><span class="line">y2 = np.cos(x)</span><br><span class="line"><span class="comment"># 绘图</span></span><br><span class="line">plt.plot(x, y1, label=<span class="string">&quot;sin&quot;</span>)</span><br><span class="line">plt.plot(x, y2, linestyle = <span class="string">&quot;--&quot;</span>, label=<span class="string">&quot;cos&quot;</span>) <span class="comment"># 用虚线绘制</span></span><br><span class="line">plt.xlabel(<span class="string">&quot;x&quot;</span>) <span class="comment"># x轴标签</span></span><br><span class="line">plt.ylabel(<span class="string">&quot;y&quot;</span>) <span class="comment"># y轴标签</span></span><br><span class="line">plt.title(<span class="string">&#x27;sin &amp; cos&#x27;</span>) <span class="comment"># 标题</span></span><br><span class="line">plt.legend() <span class="comment"># 显示图中标签</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h4 id="显示图像"><a href="#显示图像" class="headerlink" title="显示图像"></a>显示图像</h4><p>pyplot中的 <code>imshow()</code> 显示图像，image 的 <code>imread</code> 读取图像路径。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib.image <span class="keyword">import</span> imread</span><br><span class="line">img = imread(<span class="string">&#x27;lena.png&#x27;</span>) <span class="comment"># 读入图像（设定合适的路径！）</span></span><br><span class="line">plt.imshow(img)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h2 id="感知机"><a href="#感知机" class="headerlink" title="感知机"></a>感知机</h2><p>​        感知机是作为神经网络（深度学习）的起源的算法。</p>
<h3 id="感知机运行原理"><a href="#感知机运行原理" class="headerlink" title="感知机运行原理"></a>感知机运行原理</h3><p>​        感知机接收多个输入信号，输出一个信号，信号只有“流/不流”（ 1/0）两种取值。</p>
<p>​        以一个简单的图例说明：其中 x1、x2是输入信号， y是输出信号，w1、w2是权重，○称为“神经元”或者“节点”。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426000100705.png" alt="image-20220426000100705"></p>
<p>​        输入信号被送往神经元时，会被分别乘以固定的权重（w1x1、w2x2）。神经元会计算传送过来的信号的总和，只有当这个总和超过 了某个界限值时，才会输出1。这也称为“<strong>神经元被激活</strong>” 。这里将这个界限值称为阈值，用符号θ表示。</p>
<p>​        把上述内容用数学式来表示，就是式（2.1）。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426000427688.png" alt="image-20220426000427688"></p>
<h3 id="简单逻辑电路"><a href="#简单逻辑电路" class="headerlink" title="简单逻辑电路"></a>简单逻辑电路</h3><h4 id="与门（and）"><a href="#与门（and）" class="headerlink" title="与门（and）"></a>与门（and）</h4><p>​        与门仅在两个输入均为1时输出1，其他时候则输出0。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426000610902.png" alt="image-20220426000610902"></p>
<p>​        感知机表示：比如，<strong>(w1,w2, θ) = (0.5, 0.5, 0.7)、(w1,w2,θ) 为(0.5,0.5, 0.8)或者(1.0, 1.0, 1.0)</strong>时，设定这样的参数后，<strong>仅当x1和x2同时为1时</strong>，信号的加权总和才会超过给定的阈值θ。</p>
<h4 id="与非门（nand）"><a href="#与非门（nand）" class="headerlink" title="与非门（nand）"></a>与非门（nand）</h4><p>​        仅当x1和x2同时为1时输出0，其他时候则输出1。和与门完全相反。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426000938209.png" alt="image-20220426000938209"></p>
<p>​        感知机表示：比如，(w1,w 2, θ) = (−0.5,−0.5,−0.7)。</p>
<h4 id="或门（or）"><a href="#或门（or）" class="headerlink" title="或门（or）"></a>或门（or）</h4><p>​        只要有一个输入信号是1，输出就为1。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426001052560.png" alt="image-20220426001052560"></p>
<h4 id="综上"><a href="#综上" class="headerlink" title="综上"></a>综上</h4><p>​        <strong>与门、与非门、或门的感知机构造是一样的。</strong> 实际上，3个门电路只有参数的值（权重和阈值）不同。也就是说，相同构造 的感知机，只需<strong>通过适当地调整参数的值</strong>，就可以像“变色龙演员”表演不 同的角色一样，变身为与门、与非门、或门。</p>
<h3 id="感知机的实现"><a href="#感知机的实现" class="headerlink" title="感知机的实现"></a>感知机的实现</h3><h4 id="简单的实现-与门"><a href="#简单的实现-与门" class="headerlink" title="简单的实现 - 与门"></a>简单的实现 - 与门</h4><p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426001254150.png" alt="image-20220426001254150"></p>
<h4 id="导入权重和偏置"><a href="#导入权重和偏置" class="headerlink" title="导入权重和偏置"></a>导入权重和偏置</h4><p>​        首先把式（2.1）的 <strong>θ换成−b</strong>，于 是就可以用式（2.2）来表示感知机的行为。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426001358695.png" alt="image-20220426001358695"></p>
<p>​        此处，b称为偏置，w1和w2称为权重。<strong>权重是控制输入信号的重要性的参数，而偏置是调整神经元被激活的容易程度（输出信号为1的程度）的参数。</strong> 比如，若b为 −0.1，则只要输入信号的加权总和超过0.1，神经元就会被激活。但是如果b 为−20.0，则输入信号的加权总和必须超过20.0，神经元才会被激活。像这样， 偏置的值决定了神经元被激活的容易程度。</p>
<h4 id="使用权重和偏置的实现-与门"><a href="#使用权重和偏置的实现-与门" class="headerlink" title="使用权重和偏置的实现 - 与门"></a>使用权重和偏置的实现 - 与门</h4><p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426001452377.png" alt="image-20220426001452377"></p>
<h3 id="感知机的局限性"><a href="#感知机的局限性" class="headerlink" title="感知机的局限性"></a>感知机的局限性</h3><h4 id="异或门（xor）"><a href="#异或门（xor）" class="headerlink" title="异或门（xor）"></a>异或门（xor）</h4><p>​        仅当x1或x2中的一方为1时，才会输出1。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426001734024.png" alt="image-20220426001734024"></p>
<p>​        实际上，感知机是无法实现这个异或门的。具体的解释以下图的内容：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426001848227.png" alt="image-20220426001848227"></p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426001914465.png" alt="image-20220426001914465"></p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426001935443.png" alt="image-20220426001935443"></p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426001949275.png" alt="image-20220426001949275"></p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426002010619.png" alt="image-20220426002010619"></p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426002025235.png" alt="image-20220426002025235"></p>
<p>​        综上，感知机的局限性就在于它只能表示由一条直线分割的空间，也就是线性空间。下图使用曲线分割而成的空间称为非线性空间。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426002206932.png" alt="image-20220426002206932"></p>
<h3 id="多层感知机解决异或门问题"><a href="#多层感知机解决异或门问题" class="headerlink" title="多层感知机解决异或门问题"></a>多层感知机解决异或门问题</h3><p>​        异或门的制作方法有很多，其中之一就是组合我们前面做好的与门、与非门、或门进行配置。</p>
<h4 id="图例实现"><a href="#图例实现" class="headerlink" title="图例实现"></a>图例实现</h4><p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426002430066.png" alt="image-20220426002430066"></p>
<p>​        x1和x2表示输入信号， y表示输出信号。x1和x2是与非门和或门的输入，而与非门和或门的输出则是与门的输入。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426002551262.png" alt="image-20220426002551262"></p>
<p>​        验证：把 s1作为与非门的输出，把s2作为或门的输出，填入真值表中。结果如图2-12 所示，观察x1、x2、y，可以发现确实符合异或门的输出。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426002713990.png" alt="image-20220426002713990"></p>
<h4 id="python实现："><a href="#python实现：" class="headerlink" title="python实现："></a>python实现：</h4><p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426002743961.png" alt="image-20220426002743961"></p>
<h4 id="感知机表示"><a href="#感知机表示" class="headerlink" title="感知机表示"></a>感知机表示</h4><p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426002843588.png" alt="image-20220426002843588"></p>
<p>​        如图2-13所示，异或门是一种多层结构的神经网络。这里，将最左边的 一列称为第0层，中间的一列称为第1层，最右边的一列称为第2层，总共由3层构成，但是因为拥有权重的层实质上只有2层（第0层和第1层之间，第1层和第2层之间），所以称为“2层感知机”。 </p>
<p>​        图2-13所示的感知机与前面介绍的与门、或门的感知机形状不 同。实际上，与门、或门是单层感知机，而异或门是2层感知机。叠加了多层的感知机也称为<strong>多层感知机</strong>。</p>
<h2 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h2><p>​        感知机的缺点是设定权重的工作是由人工进行的。神经网络的一个重要性质是它可以自动地从数据中学习到合适的权重参数。</p>
<h3 id="从感知机到神经网络"><a href="#从感知机到神经网络" class="headerlink" title="从感知机到神经网络"></a>从感知机到神经网络</h3><p>​        神经网络和感知机有很多共同点。这里，我们主要以两者的差异为中心，来介绍神经网络的结构。</p>
<p>​        用图来表示神经网络的话，如图3-1所示。我们把最左边的一列称为 输入层，最右边的一列称为输出层，中间的一列称为中间层。中间层有时也称为隐藏层。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426003432777.png" alt="image-20220426003432777"></p>
<p>​        只看图3-1的话，神经网络的形状类似上一章的感知机。实际上，就神经元的连接方式而言，与感知机并没有任何差异。</p>
<p>​        首先将引入新函数 h(x)，将式（2.2）改写成下面的式（3.2）和式（3.3）。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426003632591.png" alt="image-20220426003632591"></p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426003641823.png" alt="image-20220426003641823"></p>
<h3 id="激活函数的引入"><a href="#激活函数的引入" class="headerlink" title="激活函数的引入"></a>激活函数的引入</h3><p>​        上述的 <code>h()</code> 会将输入信号的总和转换为输出信号，这种函数一般称为激活函数。激活函数是连接感知机和神经网络的桥梁。</p>
<p>​        现在进一步改写式（3.2）：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426003830730.png" alt="image-20220426003830730"></p>
<p>​        神经网络表示：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426003906712.png" alt="image-20220426003906712"></p>
<p>​        实际上，<strong>感知机和神经网络的区别主要在于激活函数的不同</strong>。</p>
<h3 id="常用的激活函数"><a href="#常用的激活函数" class="headerlink" title="常用的激活函数"></a>常用的激活函数</h3><h4 id="阶跃函数"><a href="#阶跃函数" class="headerlink" title="阶跃函数"></a>阶跃函数</h4><p>​        是感知机使用的激活函数。python表示为：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426004352199.png" alt="image-20220426004352199"></p>
<p>​        这个实现简单、易于理解，但是参数x只能接受实数（浮点数）。</p>
<p>​        将阶跃函数图形化：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426004533178.png" alt="image-20220426004533178"></p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426004547967.png" alt="image-20220426004547967"></p>
<p>​        阶跃函数以0为界，输出从0切换为1（或者从1切换为0）。 它的值呈阶梯式变化，所以称为阶跃函数。</p>
<h4 id="sigmoid函数"><a href="#sigmoid函数" class="headerlink" title="sigmoid函数"></a>sigmoid函数</h4><p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426004204695.png" alt="image-20220426004204695"></p>
<p>​        python实现：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426004625771.png" alt="image-20220426004625771"></p>
<p>​        将sigmoid函数图形化：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426004726650.png" alt="image-20220426004726650"></p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426004736859.png" alt="image-20220426004736859"></p>
<h4 id="阶跃函数和sigmoid函数的比较"><a href="#阶跃函数和sigmoid函数的比较" class="headerlink" title="阶跃函数和sigmoid函数的比较"></a>阶跃函数和sigmoid函数的比较</h4><p>不同点：</p>
<ol>
<li>“平滑性”的不同。sigmoid函数是一条平滑的曲线，输出随着输入发生连续性的变化。而阶跃函数以0为界，输出发 生急剧性的变化。sigmoid函数的平滑性对神经网络的学习具有重要意义。</li>
<li>相对于阶跃函数只能返回0或1，sigmoid函数可以返 回0.731 …、0.880 …等实数（这一点和刚才的平滑性有关）。也就是说，感知机中神经元之间流动的是0或1的二元信号，而神经网络中流动的是连续的实数值信号。 </li>
</ol>
<p>相同点：</p>
<ol>
<li>从宏观视角看，可以发现它们具有相似的形状。两者的结构均是“输入小时，输出接近0（为 0）； 随着输入增大，输出向1靠近（变成1）”。也就是说，当输入信号为重要信息时， 阶跃函数和sigmoid函数都会输出较大的值；当输入信号为不重要的信息时， 两者都输出较小的值。</li>
<li>不管输入信号有多小，或者有多 大，输出信号的值都在0到1之间。</li>
<li>均为非线性函数。 sigmoid函数是一条曲线，阶跃函数是一条像阶梯一样的折线。</li>
</ol>
<p>​        <strong>神经网络不能实现线性函数。线性函数的问题在于，不管如何加深层数，总是存在与之等效的“无隐藏层的神经网络”。</strong></p>
<p>​        比如，我们考虑把线性函数h(x) = cx作为激活 函数，把y(x) = h(h(h(x)))的运算对应3层神经网络。这个运算会进行 y(x) = c×c×c×x的乘法运算，但是同样的处理可以由y(x) = ax（注意， a = c 3）这一次乘法运算（即没有隐藏层的神经网络）来表示。如本例所示， 使用线性函数时，无法发挥多层网络带来的优势。因此，为了发挥叠加层所 带来的优势，激活函数必须使用非线性函数。</p>
<h4 id="ReLU函数"><a href="#ReLU函数" class="headerlink" title="ReLU函数"></a>ReLU函数</h4><p>​        在输入大于0时，直接输出该值；在输入小于等于0时，输出0。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426005246347.png" alt="image-20220426005246347"></p>
<p>​        python实现：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426005310463.png" alt="image-20220426005310463"></p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426005322420.png" alt="image-20220426005322420"></p>
<h4 id="3层神经网络的实现-从输入到输出的（前向）处理的示例"><a href="#3层神经网络的实现-从输入到输出的（前向）处理的示例" class="headerlink" title="3层神经网络的实现 - 从输入到输出的（前向）处理的示例"></a>3层神经网络的实现 - 从输入到输出的（前向）处理的示例</h4><h5 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h5><p>​        具体使用Python的NumPy数组来实现。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426143246606.png" alt="image-20220426143246606"></p>
<p>​        符号表示：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426143345552.png" alt="image-20220426143345552"></p>
<h5 id="各层间信号传递的实现"><a href="#各层间信号传递的实现" class="headerlink" title="各层间信号传递的实现"></a>各层间信号传递的实现</h5><p>​        首先是第0层到第1层的信号传递：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426143509707.png" alt="image-20220426143509707"></p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426143624707.png" alt="image-20220426143624707"></p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426143654909.png" alt="image-20220426143654909"></p>
<p>​        接着是在第1层的激活函数实现：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426143910870.png" alt="image-20220426143910870"></p>
<p>​        python实现 - 使用sigmoid激活函数：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426143951321.png" alt="image-20220426143951321"></p>
<p>​        接着是第1层到第2层的实现：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426144018599.png" alt="image-20220426144018599"></p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426144034719.png" alt="image-20220426144034719"></p>
<p>​        最后是第2层到输出层的实现：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426144112787.png" alt="image-20220426144112787"></p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426144123604.png" alt="image-20220426144123604"></p>
<p>​        值得注意的是，输出层的激活函数是 identity_function() 恒等函数，与之前的激活函数不同。事实上，<strong>输出层所用的激活函数，要根据求解问题的性质决定。一般地，回归问题可以使用恒等函数，二元分类问题可以使用sigmoid函数， 多元分类问题可以使用softmax函数。</strong></p>
<h3 id="输出层的激活函数"><a href="#输出层的激活函数" class="headerlink" title="输出层的激活函数"></a>输出层的激活函数</h3><p>​        一般地，回归问题可以使用恒等函数，二元分类问题可以使用sigmoid函数， 多元分类问题可以使用softmax函数。</p>
<h4 id="恒等函数"><a href="#恒等函数" class="headerlink" title="恒等函数"></a>恒等函数</h4><p>​        对于输入的信息，不加以任何改动地直接输出。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426144457279.png" alt="image-20220426144457279"></p>
<h4 id="softmax函数"><a href="#softmax函数" class="headerlink" title="softmax函数"></a>softmax函数</h4><p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426144525475.png" alt="image-20220426144525475"></p>
<p>​        感知机图示：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426144557653.png" alt="image-20220426144557653"></p>
<p>​        可以看得出，输出层的各个神经元都受到所有输入信号的影响。python实现如下：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426144633711.png" alt="image-20220426144633711"></p>
<p>​        但是softmax函数有一个缺陷就是溢出问题。具体的改进如下：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426145019262.png" alt="image-20220426145019262"></p>
<p>​        <strong>最终确定的实现方式：</strong></p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426144934584.png" alt="image-20220426144934584"></p>
<p>​        softmax函数的特征：softmax函数的输出是0.0到1.0之间的实数。并且，softmax 函数的输出值的总和是1。<strong>输出总和为1是softmax函数的一个重要性质。</strong>正因为有了这个性质，我们才可以<strong>把softmax函数的输出解释为“概率”</strong>。 </p>
<h3 id="输出层的神经元数量"><a href="#输出层的神经元数量" class="headerlink" title="输出层的神经元数量"></a>输出层的神经元数量</h3><p>输出层的神经元数量需要根据待解决的问题来决定。对于分类问题，输 出层的神经元数量一般设定为类别的数量。比如，对于某个输入图像，预测 是图中的数字0到9中的哪一个的问题（10类别分类问题），可以将输出层的神经元设定为10个。 </p>
<h3 id="手写数字识别-前向传播的实例"><a href="#手写数字识别-前向传播的实例" class="headerlink" title="手写数字识别 - 前向传播的实例"></a>手写数字识别 - 前向传播的实例</h3><h4 id="使用神经网络解决问题的步骤"><a href="#使用神经网络解决问题的步骤" class="headerlink" title="使用神经网络解决问题的步骤"></a>使用神经网络解决问题的步骤</h4><p>​        和求解机器学习问题的步骤（分成学习和推理两个阶段进行）一样， 使用神经网络解决问题时，也需要首先使用训练数据（学习数据）进 行权重参数的学习；进行推理时，使用刚才学习到的参数，对输入数据进行分类。</p>
<h4 id="数据集说明-MNIST数据集"><a href="#数据集说明-MNIST数据集" class="headerlink" title="数据集说明 - MNIST数据集"></a>数据集说明 - MNIST数据集</h4><p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426145512028.png" alt="image-20220426145512028"></p>
<p>​        读取数据集的Python实现：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426145548000.png" alt="image-20220426145548000"></p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426145601621.png" alt="image-20220426145601621"></p>
<p>​        <code>load_mnist(normalize=True, flatten=True, one_hot_label=False)</code> 解读：。第 1 个参数 normalize设置是否将输入图像正规化为0.0～1.0的值。如果将该参数设置 为False，则输入图像的像素会保持原来的0～255。第2个参数flatten设置 是否展开输入图像（变成一维数组）。如果将该参数设置为False，则输入图 像为1×28×28的三维数组；若设置为True，则输入图像会保存为由784个 元素构成的一维数组。第3个参数one_hot_label设置是否将标签保存为onehot表示（one-hot representation）。 <strong>one-hot</strong>表示是仅正确解标签为1，其余 皆为0的数组，就像[0,0,1,0,0,0,0,0,0,0]这样。</p>
<h4 id="神经网络的推理过程"><a href="#神经网络的推理过程" class="headerlink" title="神经网络的推理过程"></a>神经网络的推理过程</h4><p>​        首先确定输入层和输出层的神经元个数：输入层有784个神经元，输出层有10个神经元。输入层的784这个数字来 源于图像大小的28×28 = 784，输出层的10这个数字来源于10类别分类。</p>
<p>​        接着确定隐藏层：有2个隐藏层，第1个隐藏层有 50个神经元，第2个隐藏层有100个神经元。这个50和100可以设置为任何值。 </p>
<p>​        最后开始具体实现：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426150022713.png" alt="image-20220426150022713"></p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426150030572.png" alt="image-20220426150030572"></p>
<p>​        评价它的识别精度（accuracy）， 即能在多大程度上正确分类。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426150057848.png" alt="image-20220426150057848"></p>
<h2 id="神经网络的学习"><a href="#神经网络的学习" class="headerlink" title="神经网络的学习"></a>神经网络的学习</h2><p>​        这里所说的“学习”是指从训练数据中 自动获取最优权重参数的过程。学习的目的就是以该损失函数为基准，找出能使它 的值达到最小的权重参数。</p>
<h3 id="从数据中学习"><a href="#从数据中学习" class="headerlink" title="从数据中学习"></a>从数据中学习</h3><p>​        <strong>神经网络的特征就是可以从数据中学习。</strong> 所谓“从数据中学习”，是指 可以由数据自动决定权重参数的值。</p>
<h4 id="数据驱动"><a href="#数据驱动" class="headerlink" title="数据驱动"></a>数据驱动</h4><p>​        极力避免人为介入，尝试从收集到的 数据中发现答案（模式）。下面以上述MNIST的实现为例：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426185709724.png" alt="image-20220426185709724"></p>
<p>​        解决的方案：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426185943428.png" alt="image-20220426185943428"></p>
<p>​        神经网络的优点是对所有的问题都可以用同样的流程来解决。比如，不 管要求解的问题是识别5，还是识别狗，抑或是识别人脸，神经网络都是通 过不断地学习所提供的数据，尝试发现待求解的问题的模式。也就是说，与 待处理的问题无关，神经网络可以将数据直接作为原始数据，进行“端对端” 的学习。</p>
<h4 id="训练数据和测试数据"><a href="#训练数据和测试数据" class="headerlink" title="训练数据和测试数据"></a>训练数据和测试数据</h4><p>​        机器学习中，一般将数据分为训练数据和测试数据两部分来进行学习和实验等。训练数据也可以称为监督数据。 首先，使用训练数据进行学习，寻找最优的参数；然后，使用测试数据评价训练得到的模型的实际能力。</p>
<p>​        将数据划分为训练数据和测试数据的原因：因为我们追求的是模型的泛化能力。为了正确评价模型的泛化能 力，就必须划分训练数据和测试数据。泛化能力是指处理未被观察过的数据（不包含在训练数据中的数据）的 能力。获得泛化能力是机器学习的最终目标。</p>
<p>​        因此，仅仅用一个数据集去学习和评价参数，是无法进行正确评价的。 这样会导致可以顺利地处理某个数据集，但无法处理其他数据集的情况。顺 便说一下，只对某个数据集过度拟合的状态称为<strong>过拟合</strong>（over fitting）。避免过拟合也是机器学习的一个重要课题。</p>
<h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>​        神经网络以某个指标为线索寻找最优权重参数。神经网络的学习中所用的指标称为损失函数。这个损失函数可以使用任意函数， 但一般用均方误差和交叉熵误差等。</p>
<p>​        损失函数是表示神经网络性能的“恶劣程度”的指标，即当前的神经网络对监督数据在多大程度上不拟合，在多大程度上不一致。 </p>
<h4 id="均方误差"><a href="#均方误差" class="headerlink" title="均方误差"></a>均方误差</h4><p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426190752746.png" alt="image-20220426190752746"></p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426190826642.png" alt="image-20220426190826642"></p>
<h4 id="交叉熵误差"><a href="#交叉熵误差" class="headerlink" title="交叉熵误差"></a>交叉熵误差</h4><p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426190939789.png" alt="image-20220426190939789"></p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426190959268.png" alt="image-20220426190959268"></p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426191411012.png" alt="image-20220426191411012"></p>
<h4 id="mini-batch学习"><a href="#mini-batch学习" class="headerlink" title="mini-batch学习"></a>mini-batch学习</h4><p>​        机器学习使用训练数据进行学习。使用训练数据进行学习，严格来说， 就是针对训练数据计算损失函数的值，找出使该值尽可能小的参数。因此， 计算损失函数时必须将所有的训练数据作为对象。</p>
<p>​        但是很多情况下，数据集会有几百万、几千万之多，这种情况下以全部数据为对象计算损失函数是不现实的。因此，我们从全部数据中选出一部分，作为全部数据的“近似”。神经网络的学习也是从训练数据中选出一批数据（称为mini-batch,小批量），然后对每个mini-batch进行学习。</p>
<p>​        示例：从这个训练数据中随机抽取10笔数据的python实现。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426192318957.png" alt="image-20220426192318957"></p>
<h4 id="mini-batch版交叉熵误差的实现"><a href="#mini-batch版交叉熵误差的实现" class="headerlink" title="mini-batch版交叉熵误差的实现"></a>mini-batch版交叉熵误差的实现</h4><p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426192609627.png" alt="image-20220426192609627"></p>
<h4 id="为何要设定损失函数"><a href="#为何要设定损失函数" class="headerlink" title="为何要设定损失函数"></a>为何要设定损失函数</h4><p>​        在神经网络的学习中，寻找最优参数（权重和偏置）时， 要寻找使损失函数的值尽可能小的参数。为了找到使损失函数的值尽可能小 的地方，需要计算参数的导数（确切地讲是梯度），然后以这个导数为指引， 逐步更新参数的值。 </p>
<p>​        那么为什么不能用识别精度作为指标？识别精度对微小的参数变化基本上没有什么反应，即便有反应，它的值 也是不连续地、突然地变化。作为激活函数的阶跃函数也有同样的情况。出 于相同的原因，如果使用阶跃函数作为激活函数，神经网络的学习将无法进行。 </p>
<h3 id="数值微分"><a href="#数值微分" class="headerlink" title="数值微分"></a>数值微分</h3><h4 id="导数"><a href="#导数" class="headerlink" title="导数"></a>导数</h4><p>​        导数就是表示某个瞬间的变化量。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426193212398.png" alt="image-20220426193212398"></p>
<p>​        python实现：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426193406450.png" alt="image-20220426193406450"></p>
<p>​        利用微小的差分求导数的过程称为数值微分，而基于数学式的推导求导数的过程，则用“解析性”（analytic）一词，称为“解析性求解”或者“解析性求导”。</p>
<h4 id="偏导数"><a href="#偏导数" class="headerlink" title="偏导数"></a>偏导数</h4><p>​        把有多个变量的函数的导数称为偏导数。示例：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426193557061.png" alt="image-20220426193557061"></p>
<p>​        偏导数和单变量的导数一样，都是求某个地方的斜率。不过， 偏导数需要将多个变量中的某一个变量定为目标变量，并将其他变量固定为某个值。</p>
<h3 id="梯度"><a href="#梯度" class="headerlink" title="梯度"></a>梯度</h3><p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426193824647.png" alt="image-20220426193824647"></p>
<p>​        梯度表示的是各点处的函数值减小最多的方向。因此， 无法保证梯度所指的方向就是函数的最小值或者真正应该前进的方向。实际 上，在复杂的函数中，梯度指示的方向基本上都不是函数值最小处。</p>
<p>​        虽然梯度的方向并不一定指向最小值，但沿着它的方向能够最大限度地 减小函数的值。因此，在寻找函数的最小值（或者尽可能小的值）的位置的 任务中，要以梯度的信息为线索，决定前进的方向。 </p>
<h4 id="梯度法"><a href="#梯度法" class="headerlink" title="梯度法"></a>梯度法</h4><p>​        机器学习的主要任务是在学习时寻找最优参数。同样地，神经网络也必 须在学习时找到最优参数（权重和偏置）。这里所说的最优参数是指损失函数取最小值时的参数。但是，一般而言，损失函数很复杂，参数空间庞大，我 们不知道它在何处能取得最小值。而通过巧妙地使用梯度来寻找函数最小值 （或者尽可能小的值）的方法就是梯度法。 </p>
<p>​        在梯度法中，函数的取值从当前位置沿着梯 度方向前进一定距离，然后在新的地方重新求梯度，再沿着新梯度方向前进， 如此反复，不断地沿梯度方向前进。也就是，通过不断地沿梯度方向前进， 逐渐减小函数值的过程就是梯度法。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426194301454.png" alt="image-20220426194301454"></p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426194340088.png" alt="image-20220426194340088"></p>
<h4 id="神经网络的梯度"><a href="#神经网络的梯度" class="headerlink" title="神经网络的梯度"></a>神经网络的梯度</h4><p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426214159646.png" alt="image-20220426214159646"></p>
<p>​        以一个简单的神经网络为例，来实现求梯度的代码。首先实现一个simpleNet类。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426214241551.png" alt="image-20220426214241551"></p>
<p>​        接下来求梯度。我们使用numerical_gradient(f, x)求梯 度（这里定义的函数f(W)的参数W是一个伪参数。因为numerical_gradient(f, x)会在内部执行f(x),为了与之兼容而定义了f(W)）。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426214449531.png" alt="image-20220426214449531"></p>
<p>​        numerical_gradient(f, x) 的参数f是函数，x是传给函数f的参数。因此， 这里参数x取net.W，并定义一个计算损失函数的新函数f，然后把这个新定 义的函数传递给numerical_gradient(f, x)。 </p>
<h3 id="学习算法的实现"><a href="#学习算法的实现" class="headerlink" title="学习算法的实现"></a>学习算法的实现</h3><p>​        首先确认一下神经网络的学习步骤：</p>
<ol>
<li><p>前提 ：</p>
<p>​        神经网络存在合适的权重和偏置，调整权重和偏置以便拟合训练数据的过程称为“学习”。神经网络的学习分成下面4个步骤。</p>
</li>
<li><p>步骤1（mini-batch）：</p>
<p>​         从训练数据中随机选出一部分数据，这部分数据称为mini-batch。我们 的目标是减小mini-batch的损失函数的值。</p>
</li>
<li><p>步骤2（计算梯度）：</p>
<p>​         为了减小mini-batch的损失函数的值，需要求出各个权重参数的梯度。 梯度表示损失函数的值减小最多的方向。</p>
</li>
<li><p>步骤3（更新参数）：</p>
<p>​        将权重参数沿梯度方向进行微小更新。</p>
</li>
<li><p>步骤4（重复）：</p>
<p>​        重复步骤1、步骤2、步骤3。</p>
</li>
</ol>
<p>​        下面，我们来实现手写数字识别的神经网络。这里以2层神经网络（隐 藏层为1层的网络）为对象，使用MNIST数据集进行学习。</p>
<h4 id="2层神经网络的类"><a href="#2层神经网络的类" class="headerlink" title="2层神经网络的类"></a>2层神经网络的类</h4><p>​        将这个2层神经网络实现为一个名为TwoLayerNet的类：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426214930956.png" alt="image-20220426214930956"></p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426214952256.png" alt="image-20220426214952256"></p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426215011476.png" alt="image-20220426215011476"></p>
<p>​        方法的说明：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426215050183.png" alt="image-20220426215050183"></p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426215335478.png" alt="image-20220426215335478"></p>
<p>​        其中，权重使用符合高斯分布的随机数进行</p>
<p>，偏置使用0进行初始化。</p>
<h4 id="mini-batch的实现"><a href="#mini-batch的实现" class="headerlink" title="mini-batch的实现"></a>mini-batch的实现</h4><p>​        下面，我们就以 TwoLayerNet类为对象，使用MNIST数据集进行学习。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426215536201.png" alt="image-20220426215536201"></p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426215548770.png" alt="image-20220426215548770"></p>
<p>​        用图像来表示损失函数的值的推移：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426215700761.png" alt="image-20220426215700761"></p>
<p>​        通过观察，可以发现随着学习的进行，损失函数的值在不断减小。这 是学习正常进行的信号，表示神经网络的权重参数在逐渐拟合数据。也就是 说，神经网络的确在学习！通过反复地向它浇灌（输入）数据，神经网络正 在逐渐向最优参数靠近。</p>
<h4 id="基于测试数据的评价"><a href="#基于测试数据的评价" class="headerlink" title="基于测试数据的评价"></a>基于测试数据的评价</h4><p>​        根据图4-11呈现的结果，我们确认了通过反复学习可以使损失函数的值 逐渐减小这一事实。但光看这个结果还不能说明该神经网络在 其他数据集上也一定能有同等程度的表现。 </p>
<p>​        神经网络的学习中，<strong>必须确认是否能够正确识别训练数据以外的其他数据，即确认是否会发生过拟合</strong>。过拟合是指，虽然训练数据中的数字图像能 被正确辨别，但是不在训练数据中的数字图像却无法被识别的现象。 </p>
<p>​        神经网络学习的最初目标是掌握泛化能力，因此，要评价神经网络的泛 化能力，就必须使用不包含在训练数据中的数据。下面的代码在进行学习的 过程中，会定期地对训练数据和测试数据记录识别精度。这里，每经过一个 epoch，我们都会记录下训练数据和测试数据的识别精度。epoch是一个单位。一个epoch表示学习中所有训练数据均被使用过 一次时的更新次数。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426215923793.png" alt="image-20220426215923793"></p>
<p>​        在上面的例子中，每经过一个epoch，就对所有的训练数据和测试数据 计算识别精度，并记录结果。之所以要计算每一个epoch的识别精度，是因 为如果在for语句的循环中一直计算识别精度，会花费太多时间。并且，也没有必要那么频繁地记录识别精度（只要从大方向上大致把握识别精度的推 移就可以了）。因此，我们才会每经过一个epoch就记录一次训练数据的识别 精度。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426220115941.png" alt="image-20220426220115941"></p>
<h2 id="误差反向传播法"><a href="#误差反向传播法" class="headerlink" title="误差反向传播法"></a>误差反向传播法</h2><p>​        数值微 分虽然简单，也容易实现，但缺点是计算上比较费时间。误差反向传播法能够更加高效计算权重参数的梯度。</p>
<h3 id="计算图"><a href="#计算图" class="headerlink" title="计算图"></a>计算图</h3><p>​        计算图将计算过程用图形表示出来。这里说的图形是数据结构图，通 过多个节点和边表示（连接节点的直线称为“边”）。</p>
<h4 id="用计算图求解"><a href="#用计算图求解" class="headerlink" title="用计算图求解"></a>用计算图求解</h4><p>​        现在，我们尝试用计算图解简单的问题。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426220304570.png" alt="image-20220426220304570"></p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426220339963.png" alt="image-20220426220339963"></p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426220356276.png" alt="image-20220426220356276"></p>
<p>​        综上，用计算图解题的情况下，需要按如下流程进行：</p>
<ol>
<li><p>构建计算图。 </p>
</li>
<li><p>在计算图上，从左向右进行计算。</p>
</li>
</ol>
<p>​        这里的第2歩“从左向右进行计算”是一种正方向上的传播，简称为正向传播。反向（从图上看的话，就是从右向左） 的传播称为反向传播。</p>
<h4 id="局部计算"><a href="#局部计算" class="headerlink" title="局部计算"></a>局部计算</h4><p>​        计算图的特征是可以通过传递“局部计算”获得最终结果。局部计算是指，无论全局发生了什么， 都能只根据与自己相关的信息输出接下来的结果。 </p>
<p>​        举一个简单的例子：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426222201919.png" alt="image-20220426222201919"></p>
<p>​        其中苹果和其他很多东西的求和运算（4000 + 200→4200）并不关心4000这个 数字是如何计算而来的，只要把两个数字相加就可以了。换言之，各个节点 处只需进行与自己有关的计算（在这个例子中是对输入的两个数字进行加法 运算），不用考虑全局。 </p>
<p>​        综上，计算图可以集中精力于局部计算。无论全局的计算有多么复杂， 各个步骤所要做的就是对象节点的局部计算。虽然局部计算非常简单，但是 通过传递它的计算结果，可以获得全局的复杂计算的结果。</p>
<h4 id="为何用计算图解题"><a href="#为何用计算图解题" class="headerlink" title="为何用计算图解题"></a>为何用计算图解题</h4><ol>
<li><p>局部计算。无论全局是多么复杂的计算，都可以通 过局部计算使各个节点致力于简单的计算，从而简化问题。</p>
<ol>
<li>利用计算图可以将中间的计算结果全部保存起来（比如，计算进行到2个苹 果时的金额是200日元、加上消费税之前的金额650日元等）。<ol>
<li>最大的原因是，可以通过反向传播高效计算导数。 </li>
</ol>
</li>
</ol>
</li>
</ol>
<p>​        先思考问题1，我 们计算了购买2个苹果时加上消费税最终需要支付的金额。这里，假设我们想知道苹果价格的上涨会在多大程度上影响最终的支付金额，即求“支付金 额关于苹果的价格的导数”。这个导数的值可以通过计算图的 反向传播求出来。下面先看一下结果：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426222529844.png" alt="image-20220426222529844"></p>
<p>​        如图5-5所示，反向传播使用与正方向相反的箭头（粗线）表示。反向传 播传递“局部导数”，将导数的值写在箭头的下方。在这个例子中，反向传 播从右向左传递导数的值（1→1.1→2.2）。从这个结果中可知，“支付金额 关于苹果的价格的导数”的值是2.2。这意味着，如果苹果的价格上涨1日元， 最终的支付金额会增加2.2日元（严格地讲，如果苹果的价格增加某个微小值， 则最终的支付金额将增加那个微小值的2.2倍）。 </p>
<p>​        综上，计算图的优点是，可以通过正向传播和反向传 播高效地计算各个变量的导数值。</p>
<h3 id="链式法则"><a href="#链式法则" class="headerlink" title="链式法则"></a>链式法则</h3><p>​        反向传播将局部导数向正方向的反方向（从右到左）传递，传递这个局部导数的原理，是基于链式法则（chain rule）的。</p>
<h4 id="计算图的反向传播"><a href="#计算图的反向传播" class="headerlink" title="计算图的反向传播"></a>计算图的反向传播</h4><p>​        先来看一个使用计算图的反向传播的例子。假设存在 y = f(x)的计算，这个计算的反向传播如图5-6所示。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426223001804.png" alt="image-20220426223001804"></p>
<h4 id="什么是链式法则"><a href="#什么是链式法则" class="headerlink" title="什么是链式法则"></a>什么是链式法则</h4><p>​        先从复合函数说起。复合函数是由多个函数构成的函数。如下：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426223048743.png" alt="image-20220426223048743"></p>
<p>​        链式法则是关于复合函数的导数的性质，具体的定义是：如果某个函数由复合函数表示，则该复合函数的导数可以用构成复 合函数的各个函数的导数的乘积表示。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426223236994.png" alt="image-20220426223236994"></p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426223312562.png" alt="image-20220426223312562"></p>
<h4 id="链式法则和计算图"><a href="#链式法则和计算图" class="headerlink" title="链式法则和计算图"></a>链式法则和计算图</h4><p>​        尝试将式（5.4）的链式法则的计算用计算图表示出来：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426223608649.png" alt="image-20220426223608649"></p>
<p>​        如图所示，计算图的反向传播从右到左传播信号。反向传播的计算顺序 是，先将节点的输入信号乘以节点的局部导数（偏导数），然后再传递给下一 个节点。</p>
<p>​        把式（5.3）的结果代入到图5-7中，结果如图5-8所示</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426223756732.png" alt="image-20220426223756732"></p>
<h3 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h3><p>​        本节将以“+” 和“×”等运算为例，介绍反向传播的结构。</p>
<h4 id="加法节点的反向传播"><a href="#加法节点的反向传播" class="headerlink" title="加法节点的反向传播"></a>加法节点的反向传播</h4><p>​        以z = x + y为对象，观察它的 反向传播。z = x + y的导数可由下式（解析性地）计算出来。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426224044214.png" alt="image-20220426224044214"></p>
<p>​        用计算图表示的话，如 图5-9所示。 </p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426224116511.png" alt="image-20220426224116511"></p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426230904232.png" alt="image-20220426230904232"></p>
<p>​        具体例子：假设有“10 + 5=15”这一计算，反向传播时，从上游会传来值1.3。用计算图表示：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426230952411.png" alt="image-20220426230952411"></p>
<h4 id="乘法节点的反向传播"><a href="#乘法节点的反向传播" class="headerlink" title="乘法节点的反向传播"></a>乘法节点的反向传播</h4><p>​        这里我们考虑z = xy。这个 式子的导数用式（5.6）表示。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426231031054.png" alt="image-20220426231031054"></p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426232151961.png" alt="image-20220426232151961"></p>
<p>​        现在我们来看一个具体的例子。比如，假设有“10×5 = 50”这一计算， 反向传播时，从上游会传来值1.3。用计算图表示：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426232202960.png" alt="image-20220426232202960"></p>
<p>​        综上，加法的反向传播只是将上游的值传给下游， 并不需要正向传播的输入信号。但是，乘法的反向传播需要正向传播时的输 入信号值。因此，实现乘法节点的反向传播时，要保存正向传播的输入信号。</p>
<h4 id="苹果的例子"><a href="#苹果的例子" class="headerlink" title="苹果的例子"></a>苹果的例子</h4><p>​        再来思考一下本章最开始举的购买苹果的例子（2个苹果和消费税）。这 里要解的问题是苹果的价格、苹果的个数、消费税这3个变量各自如何影响 最终支付的金额。这个问题相当于求“支付金额关于苹果的价格的导数”“支付金额关于苹果的个数的导数”“支付金额关于消费税的导数”。计算图表示：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426232405992.png" alt="image-20220426232405992"></p>
<h3 id="简单层的实现"><a href="#简单层的实现" class="headerlink" title="简单层的实现"></a>简单层的实现</h3><p>​        使用Python实现前面的购买苹果的例子。这里，我们把要实现 的计算图的乘法节点称为“乘法层”（MulLayer），加法节点称为“加法层” 。</p>
<p>​        这里所说的“层”是神经网络中功能的单位。比如，负责sigmoid函数的 Sigmoid、负责矩阵乘积的Affine等，都以层为单位进行实现。层的实现中有两个共通的方法（接口）forward()和backward()。forward() 对应正向传播，backward()对应反向传播。 </p>
<h4 id="乘法层的实现"><a href="#乘法层的实现" class="headerlink" title="乘法层的实现"></a>乘法层的实现</h4><p>​        乘法层作为MulLayer类，其实现过程如下：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426232721900.png" alt="image-20220426232721900"></p>
<p>​        <strong>init</strong>()中会初始化实例变量x和y，它们用于保存正向传播时的输入值。 forward()接收x和y两个参数，将它们相乘后输出。backward()将从上游传 来的导数（dout）乘以正向传播的翻转值，然后传给下游。 </p>
<p>​        具体的例子：使用MulLayer实现前面的购买苹果 的例子（2个苹果和消费税）。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426232405992.png" alt="image-20220426232405992"></p>
<p>​        具体的python实现如下：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426232907752.png" alt="image-20220426232907752"></p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426232924935.png" alt="image-20220426232924935"></p>
<p>​        调用backward()的顺序与调用forward()的顺序相反。此外，要注 意backward()的参数中需要输入“关于正向传播时的输出变量的导数”。</p>
<h4 id="加法层的实现"><a href="#加法层的实现" class="headerlink" title="加法层的实现"></a>加法层的实现</h4><p>​        乘法层作为AddLayer类，其实现过程如下：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426233047105.png" alt="image-20220426233047105"></p>
<p>​        具体的例子：的购买2个苹果和3个橘子。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426233223625.png" alt="image-20220426233223625"></p>
<p>​        具体的python实现：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426233238444.png" alt="image-20220426233238444"></p>
<p>​        综上，计算图中层的实现（这里是加法层和乘法层）非常简单，使用这 些层可以进行复杂的导数计算。下面，我们来实现神经网络中使用的层。</p>
<h3 id="激活函数层的实现"><a href="#激活函数层的实现" class="headerlink" title="激活函数层的实现"></a>激活函数层的实现</h3><p>​        现在，我们将计算图的思路应用到神经网络中。这里，我们把构成神经 网络的层实现为一个类。先来实现激活函数的ReLU层和Sigmoid层。</p>
<h4 id="ReLU层"><a href="#ReLU层" class="headerlink" title="ReLU层"></a>ReLU层</h4><p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426233401348.png" alt="image-20220426233401348"></p>
<p>​        具体实现如下：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426233438942.png" alt="image-20220426233438942"></p>
<p>​        ReLU层的作用就像电路中的开关一样。正向传播时，有电流通过 的话，就将开关设为ON；没有电流通过的话，就将开关设为OFF。 反向传播时，开关为ON的话，电流会直接通过；开关为OFF的话， 则不会有电流通过。</p>
<h4 id="Sigmoid层"><a href="#Sigmoid层" class="headerlink" title="Sigmoid层"></a>Sigmoid层</h4><p>​        数学公式如下：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426233646760.png" alt="image-20220426233646760"></p>
<p>​        上述计算图的正向、反向传播计算图如下：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426233814793.png" alt="image-20220426233814793"></p>
<p>​        图5-20的计算图可以画成图5-21的集约化的“sigmoid”节点：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426233956190.png" alt="image-20220426233956190"></p>
<p>​        图5-20的计算图和简洁版的图5-21的计算图的计算结果是相同的，但是，<strong>简洁版的计算图可以省略反向传播中的计算过程，因此计算效率更高</strong>。此外， 通过对节点进行集约化，可以<strong>不用在意Sigmoid层中琐碎的细节，而只需要专注它的输入和输出</strong>，这一点也很重要。 </p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426234116958.png" alt="image-20220426234116958"></p>
<p>​        因此，图5-21所表示的Sigmoid层的反向传播，只根据正向传播的输出 就能计算出来。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426234134743.png" alt="image-20220426234134743"></p>
<p>​        Python实现Sigmoid层：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426234155853.png" alt="image-20220426234155853"></p>
<h3 id="Affine-Softmax层的实现"><a href="#Affine-Softmax层的实现" class="headerlink" title="Affine/Softmax层的实现"></a>Affine/Softmax层的实现</h3><h4 id="Affine层"><a href="#Affine层" class="headerlink" title="Affine层"></a>Affine层</h4><p>​        神经网络的正向传播中，为了计算加权信号的总和，使用了矩阵的乘积运算：Y = np.dot(X, W) + B。神经网络的正向传播中进行的矩阵的乘积运算在几何学领域被称为“仿 射变换” 。这里将进行仿射变换的处理实现为“Affine层”。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426234425589.png" alt="image-20220426234425589"></p>
<p>​        具体的反向传播的数学公式：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426234534013.png" alt="image-20220426234534013"></p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426234555220.png" alt="image-20220426234555220"></p>
<h4 id="Softmax-with-Loss-层"><a href="#Softmax-with-Loss-层" class="headerlink" title="Softmax-with-Loss 层"></a>Softmax-with-Loss 层</h4><p>​        神经网络中进行的处理有推理和学习两个阶段。神经网络的<strong>推理通常不使用Softmax层</strong>。神经网络中未被正规化的输出结果有时被称为“得分”。也就是说，当神经网络的推理只需要给出一个答案的情况下，因为此时只对得分最大值感兴趣，所以不需要Softmax层。 不过，<strong>神经网络的学习阶段则需要Softmax层</strong>。</p>
<p>​        下面来实现Softmax层。考虑到这里也包含作为损失函数的交叉熵误差，所以称为“Softmax-with-Loss层”。 计算图如下：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426234908519.png" alt="image-20220426234908519"></p>
<p>​        简易图如下：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426234937456.png" alt="image-20220426234937456"></p>
<p>​        Softmax层的反向传播得到了 （y1 −t1,y 2 −t2,y 3 −t3）这样“漂亮”的结果。由于（y1,y 2,y 3）是 Softmax层的输出，（ t1,t 2,t 3）是监督数据，所以（y1 −t1,y 2 −t2,y3 −t3）是 Softmax层的输出和训练数据的差分。神经网络的反向传播会把这个差分表示的误差传递给前面的层，这是神经网络学习中的重要性质。</p>
<p>​        神经网络学习的目的就是通过调整权重参数，使神经网络的输出（Softmax 的输出）接近正确结果。</p>
<p>​        考虑一个具体的例子，比如思考训练数据是（0,1,0）， Softmax层的输出是(0.3, 0.2, 0.5)的情形。因为正确解标签处的概率是0.2（20%），这个时候的神经网络未能进行正确的识别。此时，Softmax层的反向传播传递的 是(0.3,−0.8,0.5)这样一个大的误差。</p>
<p>​        再举一个例子，比如思考训练数据是(0,1,0)，Softmax层的输出是(0.01, 0.99, 0)的情形（这个神经网络识别得相当准确）。此时Softmax层的反向传播 传递的是(0.01,−0.01, 0)这样一个小的误差。</p>
<p>​        现在来进行Softmax-with-Loss层的实现：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426235700380.png" alt="image-20220426235700380"></p>
<h3 id="误差反向传播法的实现"><a href="#误差反向传播法的实现" class="headerlink" title="误差反向传播法的实现"></a>误差反向传播法的实现</h3><p>​        和需要花费较多时间的数值微分不同，误差反向传播法可以快速高效地 计算梯度。</p>
<h4 id="对应误差反向传播法的神经网络的实现"><a href="#对应误差反向传播法的神经网络的实现" class="headerlink" title="对应误差反向传播法的神经网络的实现"></a>对应误差反向传播法的神经网络的实现</h4><p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426235825192.png" alt="image-20220426235825192"></p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426235924724.png" alt="image-20220426235924724"></p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220426235935415.png" alt="image-20220426235935415"></p>
<p>​        请注意这个实现中的粗体字代码部分，尤其是将神经网络的层保存为 OrderedDict这一点非常重要。OrderedDict是有序字典，“有序”是指它可以 记住向字典里添加元素的顺序。因此，神经网络的正向传播只需按照添加元 素的顺序调用各层的forward()方法就可以完成处理，而反向传播只需要按 照相反的顺序调用各层即可。因为Affine层和ReLU层的内部会正确处理正 向传播和反向传播，所以这里要做的事情仅仅是以正确的顺序连接各层，再 按顺序（或者逆序）调用各层。</p>
<h4 id="误差反向传播法的梯度确认"><a href="#误差反向传播法的梯度确认" class="headerlink" title="误差反向传播法的梯度确认"></a>误差反向传播法的梯度确认</h4><p>​        求梯度的方法有两种：一种是基于数值微分的方 法，另一种是解析性地求解数学式的方法。后一种方法通过使用误差反向传 播法，即使存在大量的参数，也可以高效地计算梯度。数值微分主要用于做误差反向传播法的结果参照。经常会比较数值微分的结果和 误差反向传播法的结果，以确认误差反向传播法的实现是否正确。</p>
<p>​        确认数值 微分求出的梯度结果和误差反向传播法求出的结果是否一致（严格地讲，是 非常相近）的操作称为梯度确认。具体代码如下：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427000311931.png" alt="image-20220427000311931"></p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427000323295.png" alt="image-20220427000323295"></p>
<p>​        数值微分和误差反向传播法的计算结果之间的误差为0是很少见的。 这是因为计算机的计算精度有限（比如，32位浮点数）。受到数值精 度的限制，刚才的误差一般不会为0，但是如果实现正确的话，可 以期待这个误差是一个接近0的很小的值。如果这个值很大，就说 明误差反向传播法的实现存在错误。</p>
<h4 id="使用误差反向传播法的学习"><a href="#使用误差反向传播法的学习" class="headerlink" title="使用误差反向传播法的学习"></a>使用误差反向传播法的学习</h4><p>​        和之前的实现相比，不同之处仅在于通过误差反向传播法求梯度这一点。具体代码如下：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427000516017.png" alt="image-20220427000516017"></p>
<h2 id="与学习相关的技巧"><a href="#与学习相关的技巧" class="headerlink" title="与学习相关的技巧"></a>与学习相关的技巧</h2><p>​        涉及寻找最优权重 参数的最优化方法、权重参数的初始值、超参数的设定方法等。还有权值衰减、Dropout等应对过拟合的正则化方法。</p>
<h3 id="参数的更新"><a href="#参数的更新" class="headerlink" title="参数的更新"></a>参数的更新</h3><p>​        神经网络的学习的目的是找到使损失函数的值尽可能小的参数。这是寻 找最优参数的问题，解决这个问题的过程称为最优化。</p>
<p>​        前面讲的，为了找到最优参数，我们将参数的梯度（导数）作为了线索。 使用参数的梯度，沿梯度方向更新参数，并重复这个步骤多次，从而逐渐靠近最优参数，这个过程称为随机梯度下降法，简称为SGD。下面介绍SGD以及其他的一些优化方法。</p>
<h4 id="探险家的故事"><a href="#探险家的故事" class="headerlink" title="探险家的故事"></a>探险家的故事</h4><p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427000847184.png" alt="image-20220427000847184"></p>
<h4 id="SGD"><a href="#SGD" class="headerlink" title="SGD"></a>SGD</h4><p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427000922610.png" alt="image-20220427000922610"></p>
<p>​         SGD是朝着梯度方向只前进一定距离的简单方法。现在，我们将SGD实现为一个Python类：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427000958525.png" alt="image-20220427000958525"></p>
<p>​        SGD的缺点：如果函数的形状非均向（anisotropic），比如呈延伸状，搜索 的路径就会非常低效。因此，我们需要比单纯朝梯度方向前进的SGD更聪 明的方法。<strong>SGD低效的根本原因是，梯度的方向并没有指向最小值的方向</strong>。 </p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427001255137.png" alt="image-20220427001255137"></p>
<h4 id="Momentum"><a href="#Momentum" class="headerlink" title="Momentum"></a>Momentum</h4><p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427001143764.png" alt="image-20220427001143764"></p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427001205651.png" alt="image-20220427001205651"></p>
<p>​        和SGD相比，我们发现 “之”字形的“程度”减轻了。这是因为虽然x轴方向上受到的力非常小，但 是一直在同一方向上受力，所以朝同一个方向会有一定的加速。反过来，虽 然y轴方向上受到的力很大，但是因为交互地受到正方向和反方向的力，它 们会互相抵消，所以y轴方向上的速度不稳定。因此，和SGD时的情形相比， 可以更快地朝x轴方向靠近，减弱“之”字形的变动程度。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427001315762.png" alt="image-20220427001315762"></p>
<h4 id="AdaGrad"><a href="#AdaGrad" class="headerlink" title="AdaGrad"></a>AdaGrad</h4><p>​        在神经网络的学习中，学习率（数学式中记为η）的值很重要。学习率过小， 会导致学习花费过多时间；反过来，学习率过大，则会导致学习发散而不能 正确进行。 </p>
<p>​        <strong>学习率衰减</strong>是随着学习的进行，使学习率逐渐减小。实际上，一开始“多” 学，然后逐渐“少”学的方法，在神经网络的学习中经常被使用。</p>
<p>​        AdaGrad会为参数的每个元素适当地调整学习率，与此同时进行学习 。具体的数学公式如下：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427001605936.png" alt="image-20220427001605936"></p>
<p>​        具体的实现过程：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427001633007.png" alt="image-20220427001633007"></p>
<p>​        这里需要注意的是，最后一行加上了微小值1e-7。这是为了防止当 self.h[key]中有0时，将0用作除数的情况。在很多深度学习的框架中，这 个微小值也可以设定为参数，但这里我们用的是1e-7这个固定值。 </p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427001731531.png" alt="image-20220427001731531"></p>
<h4 id="基于MNIST数据集的更新方法的比较"><a href="#基于MNIST数据集的更新方法的比较" class="headerlink" title="基于MNIST数据集的更新方法的比较"></a>基于MNIST数据集的更新方法的比较</h4><p>​        以MNIST数据集为例，比较前面介绍的SGD、Momentum、 AdaGrad、Adam这4种方法，并确认不同的方法在学习进展上有多大程度的差异。</p>
<p>​        下述图例以一个5层神经网络为对象，其中每层有100个神经元。激活函数使用的是ReLU。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427001854838.png" alt="image-20220427001854838"></p>
<p>​        结果会根据要解决的问题而变。很显然，超参数（学习率等）的设定值不同，结果也会发生变化。（目前）并不存在能在所有问题中都表现良好 的方法。这4种方法各有各的特点，都有各自擅长解决的问题和不擅长解决 的问题。 </p>
<h3 id="权重的初始值"><a href="#权重的初始值" class="headerlink" title="权重的初始值"></a>权重的初始值</h3><p>​        在神经网络的学习中，权重的初始值特别重要。实际上，设定什么样的 权重初始值，经常关系到神经网络的学习能否成功。</p>
<h4 id="可以将权重初始值设为0吗"><a href="#可以将权重初始值设为0吗" class="headerlink" title="可以将权重初始值设为0吗"></a>可以将权重初始值设为0吗</h4><p>​        将权重初始值设为 0的话，将无法正确进行学习。 </p>
<p>​        因为在误差反向传播法中，所有的权重值都会进行 相同的更新。比如，在2层神经网络中，假设第1层和第2层的权重为0。这 样一来，正向传播时，因为输入层的权重为0，所以第2层的神经元全部会 被传递相同的值。第2层的神经元中全部输入相同的值，这意味着反向传播 时第2层的权重全部都会进行相同的更新（回忆一下“乘法节点的反向传播”的内容）。因此，权重被更新为相同的值，并拥有了对称的值（重复的值）。 这使得神经网络拥有许多不同的权重的意义丧失了。为了防止“权重均一化” （严格地讲，是为了瓦解权重的对称结构），<strong>必须随机生成初始值</strong>。</p>
<p>​        一般情况下，权重初始值都是像0.01 * np.random.randn(10, 100)这样，使用 由高斯分布生成的值乘以0.01后得到的值（标准差为0.01的高斯分布）。 </p>
<h4 id="隐藏层的激活值的分布"><a href="#隐藏层的激活值的分布" class="headerlink" title="隐藏层的激活值的分布"></a>隐藏层的激活值的分布</h4><p>​        首先我们来做一个简单的实验，观察权重初始值是如何影响隐藏层的 激活值的分布的。</p>
<p>​        实验内容：向一个5层神经网络（激活函数使用 sigmoid函数）传入随机生成的输入数据，用直方图绘制各层激活值的数据分布。具体代码如下：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427002356362.png" alt="image-20220427002356362"></p>
<p>​        这里假设神经网络有5层，每层有100个神经元。然后，用高斯分布随 机生成1000个数据作为输入数据，并把它们传给5层神经网络。激活函数使 用sigmoid函数，各层的激活值的结果保存在activations变量中。</p>
<p>​        这个代码段中需要注意的是权重的尺度。虽然这次我们使用的是标准差为1的高斯分布，但实验的目的是通过改变这个尺度（标准差），观察激活值的分布如何变 化。现在，我们将保存在activations中的各层数据画成直方图。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427002510717.png" alt="image-20220427002510717"></p>
<p>​        从图6-10可知，各层的激活值呈偏向0和1的分布。这里使用的sigmoid 函数是S型函数，随着输出不断地靠近0（或者靠近1），它的导数的值逐渐接 近0。因此，偏向0和1的数据分布会造成反向传播中梯度的值不断变小，最 后消失。这个问题称为<strong>梯度消失</strong>（gradient vanishing）。层次加深的深度学习 中，梯度消失的问题可能会更加严重。 </p>
<p>​        下面，将权重的标准差设为0.01，进行相同的实验。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427002550906.png" alt="image-20220427002550906"></p>
<p>​        这次呈集中在0.5附近的分布。因为不像刚才的例子那样偏向0和1，所 以不会发生梯度消失的问题。但是，激活值的分布有所偏向，说明在表现力 上会有很大问题。为什么这么说呢？因为如果有多个神经元都输出几乎相同 的值，那它们就没有存在的意义了。比如，如果100个神经元都输出几乎相 同的值，那么也可以由1个神经元来表达基本相同的事情。因此，<strong>激活值在分布上有所偏向会出现“表现力受限”的问题</strong>。</p>
<p>​        综上，各层的激活值的分布都要求有适当的广度。因为通过在各层间传递多样性的数据，神经网络可以进行高效的学习。反 过来，如果传递的是有所偏向的数据，就会出现梯度消失或者“表 现力受限”的问题，导致学习可能无法顺利进行。</p>
<p>​        尝试使用Xavier Glorot等人的论文中推荐的权重初始值（俗 称“ Xavier初始值”）。现在，在一般的深度学习框架中，Xavier初始值已被 作为标准使用。Xavier的论文中，为了使各层的激活值呈现出具有相同广度的分布，推导了合适的权重尺度。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427002825649.png" alt="image-20220427002825649"></p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427002847884.png" alt="image-20220427002847884"></p>
<p>​        图6-13的分布中，后面的层的分布呈稍微歪斜的形状。如果用tanh 函数（双曲线函数）代替sigmoid函数，这个稍微歪斜的问题就能得 到改善。实际上，使用tanh函数后，会呈漂亮的吊钟型分布。tanh 函数和sigmoid函数同是S型曲线函数，但tanh函数是关于原点(0, 0) 对称的S型曲线，而sigmoid函数是关于(x, y)=(0,0.5)对称的S型曲 线。众所周知，<strong>用作激活函数的函数最好具有关于原点对称的性质</strong>。</p>
<h4 id="ReLU的权重初始值"><a href="#ReLU的权重初始值" class="headerlink" title="ReLU的权重初始值"></a>ReLU的权重初始值</h4><p>​        因为 sigmoid函数和tanh函数左右对称，且中央附近可以视作线性函数，所以适 合使用Xavier初始值。但当激活函数使用ReLU时，一般推荐使用ReLU专 用的初始值，也就是Kaiming He等人推荐的初始值，也称为“He初始值”。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427003030448.png" alt="image-20220427003030448"></p>
<p>​        现在来看一下激活函数使用ReLU时激活值的分布。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427003105044.png" alt="image-20220427003105044"> </p>
<p>​        观察实验结果可知：</p>
<ol>
<li>当“std = 0.01”时，各层的激活值非常小 ，说明逆向传播时权重的梯度也同样很小。这是很 严重的问题，实际上学习基本上没有进展。</li>
<li>是初始值为Xavier初始值时的结果，在层加深后，激活值的偏向变大，学习时会出现梯 度消失的问题。</li>
<li>当初始值为He初始值时，各层中分布的广度相同。由于 即便层加深，数据的广度也能保持不变，因此逆向传播时，也会传递合适的值。</li>
</ol>
<p>​        <strong>总结一下，当激活函数使用ReLU时，权重初始值使用He初始值，当 激活函数为sigmoid或tanh等S型曲线函数时，初始值使用Xavier初始值。 这是目前的最佳实践。</strong></p>
<h4 id="基于MNIST数据集的权重初始值的比较"><a href="#基于MNIST数据集的权重初始值的比较" class="headerlink" title="基于MNIST数据集的权重初始值的比较"></a>基于MNIST数据集的权重初始值的比较</h4><p>​        下面通过实际的数据，观察不同的权重初始值的赋值方法会在多大程度 上影响神经网络的学习。这里，我们基于std = 0.01、Xavier初始值、He初 始值进行实验：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427003356814.png" alt="image-20220427003356814"></p>
<p>​        这个实验中，神经网络有5层，每层有100个神经元，激活函数使用的 是ReLU。从图6-15的结果可知，std = 0.01时完全无法进行学习。当权重初始值为Xavier初始值和He初始值时，学习进行得很顺利。 并且，我们发现He初始值时的学习进度更快一些。</p>
<p>​        综上，在神经网络的学习中，权重初始值非常重要。很多时候权重初始 值的设定关系到神经网络的学习能否成功。</p>
<h3 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h3><p>​        机器学习的问题中，过拟合是一个很常见的问题。过拟合指的是只能拟 合训练数据，但不能很好地拟合不包含在训练数据中的其他数据的状态。机 器学习的目标是提高泛化能力，即便是没有包含在训练数据里的未观测数据， 也希望模型可以进行正确的识别。我们可以制作复杂的、表现力强的模型，但是相应地，抑制过拟合的技巧也很重要。</p>
<h4 id="过拟合"><a href="#过拟合" class="headerlink" title="过拟合"></a>过拟合</h4><p>​        发生过拟合的原因，主要有以下两个。</p>
<p>• 模型拥有大量参数、表现力强。 </p>
<p>• 训练数据少。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427003659412.png" alt="image-20220427003659412"></p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427003738332.png" alt="image-20220427003738332"></p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427003745695.png" alt="image-20220427003745695"></p>
<p>​        过了100个epoch左右后，用训练数据测量到的识别精度几乎都为 100%。但是，对于测试数据，离100%的识别精度还有较大的差距。如此大 的识别精度差距，是只拟合了训练数据的结果。从图中可知，<strong>模型对训练时没有使用的一般数据（测试数据）拟合得不是很好</strong>。</p>
<h4 id="权值衰减"><a href="#权值衰减" class="headerlink" title="权值衰减"></a>权值衰减</h4><p>​        权值衰减是一直以来经常被使用的一种抑制过拟合的方法。该方法通过 在学习的过程中对大的权重进行惩罚，来抑制过拟合。很多过拟合原本就是 因为权重参数取值过大才发生的。 </p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427004002717.png" alt="image-20220427004002717"></p>
<p>​        对于刚刚进行的实验，应用λ = 0.1的权值衰减， 结果如图6-21所示：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427004055377.png" alt="image-20220427004055377"></p>
<h4 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h4><p>​        如果网络的模型变得很复杂，只用权值衰减难以应对。在这种情 况下，我们经常会使用Dropout 方法。</p>
<p>​        Dropout是一种在学习的过程中随机删除神经元的方法。训练时，随机 选出隐藏层的神经元，然后将其删除。被删除的神经元不再进行信号的传递。训练时，每传递一次数据，就会随机选择要删除的神经元。 然后，测试时，虽然会传递所有的神经元信号，但是对于各个神经元的输出， 要乘上训练时的删除比例后再输出。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427004202665.png" alt="image-20220427004202665"> </p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427004258867.png" alt="image-20220427004258867"></p>
<p>​        这里的要点是，每次正向传播时，self.mask中都会以False的形式保 存要删除的神经元。self.mask会随机生成和x形状相同的数组，并将值比 dropout_ratio大的元素设为True。反向传播时的行为和ReLU相同。也就是说， 正向传播时传递了信号的神经元，反向传播时按原样传递信号；正向传播时没有传递信号的神经元，反向传播时信号将停在那里。</p>
<p>​        使用MNIST数据集进行验证，以确认Dropout的效果。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427004444343.png" alt="image-20220427004444343"></p>
<h3 id="超参数的验证"><a href="#超参数的验证" class="headerlink" title="超参数的验证"></a>超参数的验证</h3><p>​        这里所说的超参数是指，比如各层的神经元数量、batch大小、参 数更新时的学习率或权值衰减等。如果这些超参数没有设置合适的值，模型 的性能就会很差。虽然超参数的取值非常重要，但是在决定超参数的过程中 一般会伴随很多的试错。</p>
<h4 id="验证数据"><a href="#验证数据" class="headerlink" title="验证数据"></a>验证数据</h4><p>​        数据集分成了训练数据和测试数据，训练数据用于学习， 测试数据用于评估泛化能力。由此，就可以评估是否只过度拟合了训练数据 （是否发生了过拟合），以及泛化能力如何等。 </p>
<p>​        下面我们要对超参数设置各种各样的值以进行验证。这里要注意的是， 不能使用测试数据评估超参数的性能。因为如果使用测试数 据调整超参数，超参数的值会对测试数据发生过拟合。换句话说，用测试数 据确认超参数的值的“好坏”，就会导致超参数的值被调整为只拟合测试数据。 这样的话，可能就会得到不能拟合其他数据、泛化能力低的模型。 </p>
<p>​        因此，调整超参数时，必须使用超参数专用的确认数据。用于调整超参 数的数据，一般称为验证数据（validation data）。我们使用这个验证数据来 评估超参数的好坏。</p>
<p>​        对于MNIST数据集，获得验证数据的 最简单的方法就是从训练数据中事先分割20%作为验证数据。代码如下：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427004748867.png" alt="image-20220427004748867"></p>
<h4 id="超参数的最优化"><a href="#超参数的最优化" class="headerlink" title="超参数的最优化"></a>超参数的最优化</h4><p>​        进行超参数的最优化时，逐渐缩小超参数的“好值”的存在范围非常重要。 所谓逐渐缩小范围，是指一开始先大致设定一个范围，从这个范围中随机选 出一个超参数（采样），用这个采样到的值进行识别精度的评估；然后，多次 重复该操作，观察识别精度的结果，根据这个结果缩小超参数的“好值”的范围。 通过重复这一操作，就可以逐渐确定超参数的合适范围。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427004837325.png" alt="image-20220427004837325"></p>
<p>​        具体的优化方法是：减少学习的epoch，缩短一次评估所需的时间 。</p>
<p>​        对超参优化的内容作一个总结如下：</p>
<p>步骤0：设定超参数的范围。<br>步骤1：从设定的超参数范围中随机采样。<br>步骤2：使用步骤1中采样到的超参数的值进行学习，通过验证数据评估识别精 度（但是要将epoch设置得很小）。<br>步骤3：重复步骤1和步骤2（100次等），根据它们的识别精度的结果，缩小超参 数的范围。</p>
<p>​        反复进行上述操作，不断缩小超参数的范围，在缩小到一定程度时，从 该范围中选出一个超参数的值。这就是进行超参数的最优化的一种方法。</p>
<p>​        在超参数的最优化中，如果需要更精炼的方法，可以使用贝叶斯最优 化（Bayesian optimization）。贝叶斯最优化运用以贝叶斯定理为中心的数学理论，能够更加严密、高效地进行最优化。</p>
<h4 id="超参数最优化的实现"><a href="#超参数最优化的实现" class="headerlink" title="超参数最优化的实现"></a>超参数最优化的实现</h4><p>​        使用MNIST数据集进行超参数的最优化。这里我们将学习 率和控制权值衰减强度的系数（下文称为“权值衰减系数”）这两个超参数的 搜索问题作为对象。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427005130183.png" alt="image-20220427005130183"></p>
<p>​        像这样进行随机采样后，再使用那些值进行学习。之后，多次使用各种 超参数的值重复进行学习，观察合乎逻辑的超参数在哪里。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427005241022.png" alt="image-20220427005241022"></p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427005256357.png" alt="image-20220427005256357"></p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427005308840.png" alt="image-20220427005308840"></p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427005318490.png" alt="image-20220427005318490"></p>
<h2 id="卷积神经网络"><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h2><p>​        卷积神经网络（CNN）被用于图像识别、语音识别等各种场合，在图像识别的比赛中，基于 深度学习的方法几乎都以CNN为基础。</p>
<h3 id="整体结构"><a href="#整体结构" class="headerlink" title="整体结构"></a>整体结构</h3><p>​        CNN和之前介绍的神经网络一样，不过， CNN中新出现了卷积层（Convolution层）和池化层（Pooling层）。</p>
<p>​        之前介绍的神经网络中，相邻层的所有神经元之间都有连接，这称为全 连接（fully-connected）。另外，我们用Affine层实现了全连接层。如果使用 这个Affine层，一个5层的全连接的神经网络就可以通过图7-1所示的网络结 构来实现。 </p>
<p>​        全连接的神经网络中，Affine层后面跟着激活函数ReLU 层（或者 Sigmoid层）。这里堆叠了4层“ Affine-ReLU”组合，然后第5层是 Affine层，最后由Softmax层输出最终结果（概率）。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427005556833.png" alt="image-20220427005556833"></p>
<p>​        如图7-2所示，CNN中新增了Convolution层和Pooling层。CNN的 层的连接顺序是“Convolution - ReLU -（Pooling）”（ Pooling层有时会被省 略）。这可以理解为之前的“Affine - ReLU”连接被替换成了“Convolution - ReLU -（Pooling）”连接。 </p>
<p>​        还需要注意的是，在图7-2的CNN中，靠近输出的层中使用了之前 的“ Affine - ReLU”组合。此外，最后的输出层中使用了之前的“Affine - Softmax”组合。这些都是一般的CNN中比较常见的结构。</p>
<h3 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h3><h4 id="全连接层存在的问题"><a href="#全连接层存在的问题" class="headerlink" title="全连接层存在的问题"></a>全连接层存在的问题</h4><p>​        全连接的神经网络中使用了全连接层（Affine层）。在全连接层中，相邻层的神经元全部连接在一起，输出的数量可以任意决定。 </p>
<p>​        全连接层的问题在于，忽视了数据的形状。比如，输入数据是图像时，图像通常是高、长、通道方向上的3维形状。但是，向全 连接层输入时，需要将3维数据拉平为1维数据。</p>
<p>​        而卷积层可以保持形状不变。当输入数据是图像时，卷积层会以3维 数据的形式接收输入数据，并同样以3维数据的形式输出至下一层。因此， 在CNN中，可以（有可能）正确理解图像等具有形状的数据。 </p>
<p>​        CNN中，有时将卷积层的输入输出数据称为<strong>特征图</strong>（feature map）。其中，卷积层的输入数据称为输入特征图（input feature map），输出 数据称为输出特征图（output feature map）。</p>
<h4 id="卷积运算"><a href="#卷积运算" class="headerlink" title="卷积运算"></a>卷积运算</h4><p>​        卷积层进行的处理就是卷积运算。先看一个具体的例子：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427005929093.png" alt="image-20220427005929093"></p>
<p>​        在这个例子中，输入 数据是有高长方向的形状的数据，滤波器也一样，有高长方向上的维度。假 设用（height, width）表示数据和滤波器的形状，则在本例中，输入大小是 (4, 4)，滤波器大小是(3, 3)，输出大小是(2, 2)。图7-4 中展示了卷积运算的计算顺序。 </p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427010050958.png" alt="image-20220427010050958"></p>
<p>​        对于输入数据，卷积运算以一定间隔滑动滤波器的窗口并应用。这里所 说的窗口是指图7-4中灰色的3×3的部分。如图7-4所示，将各个位置上滤波器的元素和输入的对应元素相乘，然后再求和（有时将这个计算称为乘积 累加运算）。然后，将这个结果保存到输出的对应位置。将这个过程在所有 位置都进行一遍，就可以得到卷积运算的输出。 </p>
<p>​        滤波器就对应全连接神经网络的权重。CNN页包含偏置，包含偏置的卷积运算的处理流如图 7-5所示。 </p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427010258290.png" alt="image-20220427010258290"></p>
<p>如图7-5所示，向应用了滤波器的数据加上了偏置。偏置通常只有1个 （1×1），这个值会被加到应用了滤波器的所有元素上。</p>
<h4 id="填充"><a href="#填充" class="headerlink" title="填充"></a>填充</h4><p>​        在进行卷积层的处理之前，有时要向输入数据的周围填入固定的数据（比 如0等），这称为填充（padding），是卷积运算中经常会用到的处理。比如， 在图7-6的例子中，对大小为(4, 4)的输入数据应用了幅度为1的填充。“幅 度为1的填充”是指用幅度为1像素的0填充周围。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427010420838.png" alt="image-20220427010420838"></p>
<p>​        如图7-6所示，通过填充，大小为(4, 4)的输入数据变成了(6,6)的形状。 然后，<strong>应用大小为(3, 3)的滤波器，生成了大小为(4,4)的输出数据</strong>。<strong>使用填充主要是为了调整输出的大小</strong>。</p>
<h4 id="步幅"><a href="#步幅" class="headerlink" title="步幅"></a>步幅</h4><p>​        应用滤波器的位置间隔称为步幅（stride）。之前的例子中步幅都是1，如 果将步幅设为2，则如图7-7所示，应用滤波器的窗口的间隔变为2个元素。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427010543431.png" alt="image-20220427010543431"></p>
<p>​        综上，增大步幅后，输出大小会变小。而增大填充后，输出大小会变大。 </p>
<p>​        这里，假设输入大小为(H,W)，滤波器大小为(FH,FW)，输出大小为 (OH,OW)，填充为P，步幅为S。此时，输出大小可通过式(7.1)进行计算。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427010656964.png" alt="image-20220427010656964"></p>
<p>​        简单的例子：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427010743137.png" alt="image-20220427010743137"></p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427010818249.png" alt="image-20220427010818249"></p>
<h4 id="3维数据的卷积运算"><a href="#3维数据的卷积运算" class="headerlink" title="3维数据的卷积运算"></a>3维数据的卷积运算</h4><p>​        图7-8是卷积运算的例子，图7-9是计算顺序。这里以3通道的数据为例， 展示了卷积运算的结果。和2维数据时（图7-3的例子）相比，可以发现纵深 方向（通道方向）上特征图增加了。通道方向上有多个特征图时，会按通道 进行输入数据和滤波器的卷积运算，并将结果相加，从而得到输出。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427010935469.png" alt="image-20220427010935469"></p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427010953855.png" alt="image-20220427010953855"></p>
<p>​        需要注意的是，在3维数据的卷积运算中，输入数据和滤波器的通道数 要设为相同的值。在这个例子中，输入数据和滤波器的通道数一致，均为3。 滤波器大小可以设定为任意值（不过，每个通道的滤波器大小要全部相同）。 这个例子中滤波器大小为(3, 3)，但也可以设定为(2, 2)、(1, 1)、(5, 5)等任 意值。再强调一下，通道数只能设定为和输入数据的通道数相同的值（本例中为3）。</p>
<h4 id="结合方块思考"><a href="#结合方块思考" class="headerlink" title="结合方块思考"></a>结合方块思考</h4><p>​        将数据和滤波器结合长方体的方块来考虑，3维数据的卷积运算会很 容易理解。把3维数据表示为多维数组 时，书写顺序为（channel, height, width）。比如，通道数为C、高度为H、 长度为W的数据的形状可以写成（C, H,W）。滤波器也一样，要按（channel, height, width）的顺序书写。比如，通道数为C、滤波器高度为FH（Filter Height）、长度为FW（Filter Width）时，可以写成（C,FH,FW）。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427115918643.png" alt="image-20220427115918643"></p>
<p>​        这个例子中，数据输出是1张特征图。所谓1张特征图，换句话说， 就是通道数为1的特征图。如果要在通道方向上也拥有多个卷积运算的输出，就需要用到多个滤波器（权重）。图表示如下：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427120013576.png" alt="image-20220427120013576"></p>
<p>​        图7-11中，通过应用FN个滤波器，输出特征图也生成了FN个。如果 将这FN个特征图汇集在一起，就得到了形状为(FN,OH,OW)的方块。将 这个方块传给下一层，就是CNN的处理流。 </p>
<p>​        如图7-11所示，关于卷积运算的滤波器，也必须考虑滤波器的数 量。因此，作为4维数据，滤波器的权重数据要按(output_channel,input_ channel, height, width)的顺序书写。比如，通道数为3、大小为5×5的滤 波器有20个时，可以写成(20, 3, 5, 5)。 </p>
<p>​        卷积运算和全连接层一样存在偏置。如果进 一步追加偏置的加法运算处理，则结果如下面的图7-12所示。 </p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427120157004.png" alt="image-20220427120157004"></p>
<p>​        每个通道只有一个偏置。这里，偏置的形状是(FN,1,1)， 滤波器的输出结果的形状是(FN, OH, OW)。这两个方块相加时，要对滤波 器的输出结果(FN,OH,OW)按通道加上相同的偏置值。</p>
<h3 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h3><p>​        池化是缩小高、长方向上的空间的运算。如图7-14所示，将 2×2的区域集约成1个元素的处理，缩小空间大小。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427120339167.png" alt="image-20220427120339167"></p>
<p>​        例子中的处理顺序是按步幅2进行2×2的Max池化，“Max 池化”是获取最大值的运算。如图所示，从 2×2的区域中取出最大的元素。此外，这个例子中将步幅设为了2，所以 2×2的窗口的移动间隔为2个元素。另外，一般来说，<strong>池化的窗口大小会和步幅设定成相同的值</strong>。比如，3×3的窗口的步幅会设为3，4×4的窗口 的步幅会设为4等。</p>
<p>​        除了Max池化之外，还有Average池化等。Max池化是从 目标区域中取出最大值，Average池化则是计算目标区域的平均值。 在图像识别领域，主要使用Max池化。</p>
<p>​        池化层的特征是：</p>
<ol>
<li><p>没有要学习的参数。池化只是从目标区域中取最 大值（或者平均值），所以不存在要学习的参数。</p>
</li>
<li><p>通道数不发生变化。经过池化运算，输入数据和输出数据的通道数不会发生变化。如图7-15 所示，计算是按通道独立进行的。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427120706280.png" alt="image-20220427120706280"></p>
</li>
<li><p>对微小的位置变化具有鲁棒性（健壮）。输入数据发生微小偏差时，池化仍会返回相同的结果。因此，池化对 输入数据的微小偏差具有鲁棒性。 如下图：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427120845813.png" alt="image-20220427120845813"></p>
</li>
</ol>
<h3 id="卷积层和池化层的实现"><a href="#卷积层和池化层的实现" class="headerlink" title="卷积层和池化层的实现"></a>卷积层和池化层的实现</h3><p>​        首先实现一个四维数据。CNN中各层间传递的数据是4维数据。所谓4维数据，比如 数据的形状是(10, 1, 28, 28)，则它对应10个高为28、长为28、通道为1的数 据。用Python来实现的话，如下所示。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427121059722.png" alt="image-20220427121059722"></p>
<p>​        如果要访问第1个数据，只要写x[0]就可以了（注意Python的索 引是从0开始的）。同样地，用x[1]可以访问第2个数据。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427121124056.png" alt="image-20220427121124056"></p>
<p>​        如果要访问第1个数据的第1个通道的空间数据，可以写成下面这样。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427121210155.png" alt="image-20220427121210155"></p>
<h4 id="基于im2col的展开"><a href="#基于im2col的展开" class="headerlink" title="基于im2col的展开"></a>基于im2col的展开</h4><p>​        im2col是一个函数，将输入数据展开以适合滤波器（权重）。对3维的输入数据应用im2col后，数据转换为2维矩阵（正确地讲，是把包含批数量的4维数据转换成了2维数据）。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427121643026.png" alt="image-20220427121643026"></p>
<p>​        如图7-18所示， 对于输入数据，将应用滤波器的区域（3维方块）横向展开为1列。im2col会 在所有应用滤波器的地方进行这个展开处理。</p>
<p>​        在图7-18中，为了便于观察，将步幅设置得很大，以使滤波器的应用区 域不重叠。而在实际的卷积运算中，滤波器的应用区域几乎都是重叠的。在 滤波器的应用区域重叠的情况下，使用im2col展开后，展开后的元素个数会多于原方块的元素个数。因此，<strong>使用im2col的实现存在比普通的实现消耗更多内存的缺点</strong>。但是，汇总成一个大的矩阵进行计算，对计算机的计算颇有益处。比如，在矩阵计算的库（线性代数库）等中，矩阵计算的实现已被高度最优化，可以高速地进行大矩阵的乘法运算。因此，通过归结到矩阵计算上，可以有效地利用线性代数库。</p>
<p>​        使用im2col展开输入数据后，之后就只需将卷积层的滤波器（权重）纵 向展开为1列，并计算2个矩阵的乘积即可（参照图7-19）。这和全连接层的 Affi  ne层进行的处理基本相同。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427121934492.png" alt="image-20220427121934492"></p>
<p>​        如图7-19所示，基于im2col方式的输出结果是2维矩阵。因为CNN中 数据会保存为4维数组，所以要将2维输出数据转换为合适的形状。以上就 是卷积层的实现流程。</p>
<h4 id="卷积层的实现"><a href="#卷积层的实现" class="headerlink" title="卷积层的实现"></a>卷积层的实现</h4><p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427122017735.png" alt="image-20220427122017735"></p>
<p>​        具体使用：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427122045024.png" alt="image-20220427122045024"></p>
<p>​        这里举了两个例子。第一个是批大小为1、通道为3的7×7的数据，第 二个的批大小为10，数据形状和第一个相同。分别对其应用im2col函数，在 这两种情形下，第2维的元素个数均为75。这是滤波器（通道为3、大小为 5×5）的元素个数的总和。批大小为1时，im2col的结果是(9,75)。而第2 个例子中批大小为10，所以保存了10倍的数据，即(90,75)。 </p>
<p>​        现在使用im2col来实现卷积层的forword处理：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427122643411.png" alt="image-20220427122643411"></p>
<p>​        通过使用im2col进行展开，基本上可以像实现全连接层的Affine层一样来实现。对于卷积层的backword处理，因为和Affine层的实现有很多共通的地方，所以就不再介绍了。</p>
<h4 id="池化层的实现"><a href="#池化层的实现" class="headerlink" title="池化层的实现"></a>池化层的实现</h4><p>​        池化层的实现和卷积层相同，都使用im2col展开输入数据。不过，池化 的情况下，在通道方向上是独立的，这一点和卷积层不同。如图 7-21所示，池化的应用区域按通道单独展开。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427123242448.png" alt="image-20220427123242448"></p>
<p>​        像这样展开之后，只需对展开的矩阵求各行的最大值，并转换为合适的 形状即可（图7-22）。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427123355144.png" alt="image-20220427123355144"></p>
<p>​        以下是池化层forword处理的实现：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427123421740.png" alt="image-20220427123421740"></p>
<p>​        池化层的实现步骤：</p>
<ol>
<li><p>展开输入数据。 </p>
</li>
<li><p>求各行的最大值。 </p>
</li>
<li>转换为合适的输出大小。</li>
</ol>
<p>​        池化层的backward处理可以参考ReLU层的实现中使用的max的反向传播。</p>
<h3 id="CNN的实现"><a href="#CNN的实现" class="headerlink" title="CNN的实现"></a>CNN的实现</h3><p>​        我们已经实现了卷积层和池化层，现在来组合这些层，搭建进行手写数字识别的CNN。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427141329524.png" alt="image-20220427141329524"></p>
<p>​        具体实现为 SimpleConvNet 类：</p>
<ol>
<li><p>初始化</p>
<p>​        将由初始化参数传入的卷积层的超参数从字典中取了出来（以方便 后面使用），然后，计算卷积层的输出大小。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427141519012.png" alt="image-20220427141519012"></p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427141542668.png" alt="image-20220427141542668"></p>
<p>​        权重参数的初始化，学习所需的参数是第1层的卷积层和剩余两个全连接层的权重和偏置。 将这些参数保存在实例变量的params字典中：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427142233531.png" alt="image-20220427142233531"></p>
<p>​        最后，生成必要的层：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427142327790.png" alt="image-20220427142327790"></p>
<p>​        从最前面开始按顺序向有序字典（OrderedDict）的 layers中添加层。只 有最后的SoftmaxWithLoss层被添加到别的变量lastLayer中。 </p>
</li>
<li><p>初始化后，实现用于推理的predict方法和求损失函数值的loss方法：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427143107610.png" alt="image-20220427143107610"></p>
<p>​        用于推理的predict方法从头 开始依次调用已添加的层，并将结果传递给下一层。在求损失函数的loss 方法中，除了使用predict方法进行的forward处理之外，还会继续进行 forward处理，直到到达最后的SoftmaxWithLoss层。</p>
</li>
<li><p>接下来，基于误差反向传播法求梯度：</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427143201536.png" alt="image-20220427143201536"></p>
<p>​        参数的梯度通过误差反向传播法（反向传播）求出，通过把正向传播和 反向传播组装在一起来完成。因为已经在各层正确实现了正向传播和反向传 播的功能，所以这里只需要以合适的顺序调用即可。最后，把各个权重参数 的梯度保存到grads字典中。这就是SimpleConvNet的实现。</p>
</li>
</ol>
<p>​        如上所述，卷积层和池化层是图像识别中必备的模块。CNN可以有效 读取图像中的某种特性，在手写数字识别中，还可以实现高精度的识别。</p>
<h3 id="CNN的可视化"><a href="#CNN的可视化" class="headerlink" title="CNN的可视化"></a>CNN的可视化</h3><h4 id="第1层权重的可视化"><a href="#第1层权重的可视化" class="headerlink" title="第1层权重的可视化"></a>第1层权重的可视化</h4><p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427144342320.png" alt="image-20220427144342320"></p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427144355432.png" alt="image-20220427144355432"></p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427144417412.png" alt="image-20220427144417412"></p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427144429993.png" alt="image-20220427144429993"></p>
<h4 id="基于分层结构的信息提取"><a href="#基于分层结构的信息提取" class="headerlink" title="基于分层结构的信息提取"></a>基于分层结构的信息提取</h4><p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427144453058.png" alt="image-20220427144453058"></p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427144504023.png" alt="image-20220427144504023"></p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427144514755.png" alt="image-20220427144514755"></p>
<h3 id="具有代表性的CNN"><a href="#具有代表性的CNN" class="headerlink" title="具有代表性的CNN"></a>具有代表性的CNN</h3><h4 id="LeNet"><a href="#LeNet" class="headerlink" title="LeNet"></a>LeNet</h4><p>​        是进行手写数字识别的网络。有连续的卷积层和池化层（正确地讲，是只“抽选元素”的子采样层），最 后经全连接层输出结果。</p>
<p>​        和“现在的CNN”相比， LeNet有几个不同点：</p>
<ol>
<li>激活 函数。LeNet中使用sigmoid函数，而现在的CNN中主要使用ReLU函数。 </li>
<li>原始的LeNet中使用子采样（subsampling）缩小中间数据的大小，而 现在的CNN中Max池化是主流。</li>
</ol>
<h4 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h4><p>​        AlexNet是引发深度学 习热潮的导火线，不过它的网络结构和LeNet基本上没有什么不同。AlexNet叠有多个卷积层和池化层，最后经由全连接层输出结果。虽然 结构上AlexNet和LeNet没有大的不同，但有以下几点差异。</p>
<ol>
<li>激活函数使用ReLU。</li>
<li>使用进行局部正规化的LRN（Local Response Normalization）层。 </li>
<li>使用Dropout。</li>
</ol>
<p>​        如上所述，关于网络结构，LeNet和AlexNet没有太大的不同。但是， 围绕它们的环境和计算机技术有了很大的进步。具体地说，现在任何人都可 以获得大量的数据。而且，擅长大规模并行计算的GPU得到普及，高速进 行大量的运算已经成为可能。大数据和GPU已成为深度学习发展的巨大的 原动力。</p>
<h2 id="深度学习"><a href="#深度学习" class="headerlink" title="深度学习"></a>深度学习</h2><p>​        深度学习是加深了层的深度神经网络。只需通过 叠加层，就可以创建深度网络。</p>
<h3 id="加深网络"><a href="#加深网络" class="headerlink" title="加深网络"></a>加深网络</h3><p>​        关于神经网络，我们已经学了很多东西，比如构成神经网络的各种层、 学习时的有效技巧、对图像特别有效的CNN、参数的最优化方法等，这些 都是深度学习中的重要技术。本节我们将这些已经学过的技术汇总起来，创 建一个深度网络，挑战MNIST数据集的手写数字识别。</p>
<h4 id="向更深的网络出发"><a href="#向更深的网络出发" class="headerlink" title="向更深的网络出发"></a>向更深的网络出发</h4><p>​        如图8-1所示，这个网络的层比之前实现的网络都更深。这里使用的卷 积层全都是3×3的小型滤波器，特点是随着层的加深，通道数变大（卷积 层的通道数从前面的层开始按顺序以16、16、32、32、64、64的方式增加）。 此外，还插入了池化层，以逐渐减小中间数据的空间大小；并且， 后面的全连接层中使用了Dropout层。</p>
<p><img src="学习笔记-《深度学习入门：基于-Python-的理论与实现》.assets/image-20220427145959397.png" alt="image-20220427145959397"></p>
<p>​        这个网络使用He初始值作为权重的初始值，使用Adam更新权重参数。 把上述内容总结起来，这个网络有如下特点：</p>
<ol>
<li>基于3×3的小型滤波器的卷积层。 </li>
<li>激活函数是ReLU。 </li>
<li>全连接层的后面使用Dropout层。</li>
<li>基于Adam的最优化。 </li>
<li>使用He初始值作为权重初始值。</li>
</ol>
<p>​        现在，我们使用这个网络进行学习。先说一下结论，这个网络的识 别精度为99.38% ，可以说是非常优秀的性能了！</p>

    </div>

    
    
    
	  
	
	 <div>
		<div>
    
        <div style="text-align:center;color: #ccc;font-size:24px;">-------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------</div>
    
</div>
	 </div>
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/python/" rel="tag"># python</a>
              <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag"># 深度学习</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/01/11/%E8%B4%AD%E7%89%A9%E8%BD%A6%E7%BB%93%E7%AE%97%E7%B3%BB%E7%BB%9F-%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E7%AF%87-%E9%A1%B9%E7%9B%AE%E5%B0%8F%E8%AE%B0/" rel="prev" title="购物车结算系统-配置文件篇-项目小记">
      <i class="fa fa-chevron-left"></i> 购物车结算系统-配置文件篇-项目小记
    </a></div>
      <div class="post-nav-item">
    <a href="/2022/01/13/LeetCode-55-%E8%B7%B3%E8%B7%83%E6%B8%B8%E6%88%8F/" rel="next" title="LeetCode - 55. 跳跃游戏">
      LeetCode - 55. 跳跃游戏 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B3%A8%E6%98%8E"><span class="nav-number">1.</span> <span class="nav-text">注明</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Python%E5%85%A5%E9%97%A8"><span class="nav-number">2.</span> <span class="nav-text">Python入门</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#python%E8%A7%A3%E9%87%8A%E5%99%A8%EF%BC%88%E5%9F%BA%E6%9C%AC%E7%9A%84%E4%BD%BF%E7%94%A8%EF%BC%89"><span class="nav-number">2.1.</span> <span class="nav-text">python解释器（基本的使用）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%89%88%E6%9C%AC%E6%9F%A5%E8%AF%A2"><span class="nav-number">2.1.1.</span> <span class="nav-text">版本查询</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%AE%97%E6%9C%AF%E8%BF%90%E7%AE%97"><span class="nav-number">2.1.2.</span> <span class="nav-text">算术运算</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B"><span class="nav-number">2.1.3.</span> <span class="nav-text">数据类型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8F%98%E9%87%8F"><span class="nav-number">2.1.4.</span> <span class="nav-text">变量</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%B3%A8%E9%87%8A"><span class="nav-number">2.1.5.</span> <span class="nav-text">注释</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%88%97%E8%A1%A8"><span class="nav-number">2.1.6.</span> <span class="nav-text">列表</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AD%97%E5%85%B8"><span class="nav-number">2.1.7.</span> <span class="nav-text">字典</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#bool"><span class="nav-number">2.1.8.</span> <span class="nav-text">bool</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#if-%E8%AF%AD%E5%8F%A5"><span class="nav-number">2.1.9.</span> <span class="nav-text">if 语句</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#for-%E8%AF%AD%E5%8F%A5"><span class="nav-number">2.1.10.</span> <span class="nav-text">for 语句</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%87%BD%E6%95%B0"><span class="nav-number">2.1.11.</span> <span class="nav-text">函数</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#python%E8%84%9A%E6%9C%AC%E6%96%87%E4%BB%B6"><span class="nav-number">2.2.</span> <span class="nav-text">python脚本文件</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BF%9D%E5%AD%98%E4%B8%BA%E6%96%87%E4%BB%B6%E7%9A%84%E6%AD%A5%E9%AA%A4"><span class="nav-number">2.2.1.</span> <span class="nav-text">保存为文件的步骤</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%B1%BB"><span class="nav-number">2.2.2.</span> <span class="nav-text">类</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Numpy"><span class="nav-number">2.3.</span> <span class="nav-text">Numpy</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AF%BC%E5%85%A5"><span class="nav-number">2.3.1.</span> <span class="nav-text">导入</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Numpy%E6%95%B0%E7%BB%84"><span class="nav-number">2.3.2.</span> <span class="nav-text">Numpy数组</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%80%E7%BB%B4%E6%95%B0%E7%BB%84%E7%AE%97%E6%9C%AF%E8%BF%90%E7%AE%97"><span class="nav-number">2.3.3.</span> <span class="nav-text">一维数组算术运算</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%A4%9A%E7%BB%B4%E6%95%B0%E7%BB%84%E7%AE%97%E6%9C%AF%E8%BF%90%E7%AE%97"><span class="nav-number">2.3.4.</span> <span class="nav-text">多维数组算术运算</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%8D%E5%90%8C%E8%A1%8C%E5%88%97%E6%95%B0%E7%9A%84%E6%95%B0%E7%BB%84%E8%AE%A1%E7%AE%97"><span class="nav-number">2.3.5.</span> <span class="nav-text">不同行列数的数组计算</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%8E%B7%E5%8F%96%E6%95%B0%E7%BB%84%E7%BB%B4%E5%BA%A6"><span class="nav-number">2.3.6.</span> <span class="nav-text">获取数组维度</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%8E%B7%E5%8F%96%E8%A1%8C%E5%88%97%E6%95%B0"><span class="nav-number">2.3.7.</span> <span class="nav-text">获取行列数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AE%BF%E9%97%AE%E5%85%83%E7%B4%A0"><span class="nav-number">2.3.8.</span> <span class="nav-text">访问元素</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Matplotlib"><span class="nav-number">2.4.</span> <span class="nav-text">Matplotlib</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%BB%98%E5%88%B6%E7%AE%80%E5%8D%95%E5%9B%BE%E5%BD%A2"><span class="nav-number">2.4.1.</span> <span class="nav-text">绘制简单图形</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#pyplot"><span class="nav-number">2.4.2.</span> <span class="nav-text">pyplot</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%98%BE%E7%A4%BA%E5%9B%BE%E5%83%8F"><span class="nav-number">2.4.3.</span> <span class="nav-text">显示图像</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%84%9F%E7%9F%A5%E6%9C%BA"><span class="nav-number">3.</span> <span class="nav-text">感知机</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%84%9F%E7%9F%A5%E6%9C%BA%E8%BF%90%E8%A1%8C%E5%8E%9F%E7%90%86"><span class="nav-number">3.1.</span> <span class="nav-text">感知机运行原理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AE%80%E5%8D%95%E9%80%BB%E8%BE%91%E7%94%B5%E8%B7%AF"><span class="nav-number">3.2.</span> <span class="nav-text">简单逻辑电路</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%8E%E9%97%A8%EF%BC%88and%EF%BC%89"><span class="nav-number">3.2.1.</span> <span class="nav-text">与门（and）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%8E%E9%9D%9E%E9%97%A8%EF%BC%88nand%EF%BC%89"><span class="nav-number">3.2.2.</span> <span class="nav-text">与非门（nand）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%88%96%E9%97%A8%EF%BC%88or%EF%BC%89"><span class="nav-number">3.2.3.</span> <span class="nav-text">或门（or）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%BB%BC%E4%B8%8A"><span class="nav-number">3.2.4.</span> <span class="nav-text">综上</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%84%9F%E7%9F%A5%E6%9C%BA%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="nav-number">3.3.</span> <span class="nav-text">感知机的实现</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%AE%80%E5%8D%95%E7%9A%84%E5%AE%9E%E7%8E%B0-%E4%B8%8E%E9%97%A8"><span class="nav-number">3.3.1.</span> <span class="nav-text">简单的实现 - 与门</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AF%BC%E5%85%A5%E6%9D%83%E9%87%8D%E5%92%8C%E5%81%8F%E7%BD%AE"><span class="nav-number">3.3.2.</span> <span class="nav-text">导入权重和偏置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8%E6%9D%83%E9%87%8D%E5%92%8C%E5%81%8F%E7%BD%AE%E7%9A%84%E5%AE%9E%E7%8E%B0-%E4%B8%8E%E9%97%A8"><span class="nav-number">3.3.3.</span> <span class="nav-text">使用权重和偏置的实现 - 与门</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%84%9F%E7%9F%A5%E6%9C%BA%E7%9A%84%E5%B1%80%E9%99%90%E6%80%A7"><span class="nav-number">3.4.</span> <span class="nav-text">感知机的局限性</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%BC%82%E6%88%96%E9%97%A8%EF%BC%88xor%EF%BC%89"><span class="nav-number">3.4.1.</span> <span class="nav-text">异或门（xor）</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA%E8%A7%A3%E5%86%B3%E5%BC%82%E6%88%96%E9%97%A8%E9%97%AE%E9%A2%98"><span class="nav-number">3.5.</span> <span class="nav-text">多层感知机解决异或门问题</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9B%BE%E4%BE%8B%E5%AE%9E%E7%8E%B0"><span class="nav-number">3.5.1.</span> <span class="nav-text">图例实现</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#python%E5%AE%9E%E7%8E%B0%EF%BC%9A"><span class="nav-number">3.5.2.</span> <span class="nav-text">python实现：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%84%9F%E7%9F%A5%E6%9C%BA%E8%A1%A8%E7%A4%BA"><span class="nav-number">3.5.3.</span> <span class="nav-text">感知机表示</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="nav-number">4.</span> <span class="nav-text">神经网络</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%8E%E6%84%9F%E7%9F%A5%E6%9C%BA%E5%88%B0%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="nav-number">4.1.</span> <span class="nav-text">从感知机到神经网络</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E7%9A%84%E5%BC%95%E5%85%A5"><span class="nav-number">4.2.</span> <span class="nav-text">激活函数的引入</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B8%B8%E7%94%A8%E7%9A%84%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0"><span class="nav-number">4.3.</span> <span class="nav-text">常用的激活函数</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%98%B6%E8%B7%83%E5%87%BD%E6%95%B0"><span class="nav-number">4.3.1.</span> <span class="nav-text">阶跃函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#sigmoid%E5%87%BD%E6%95%B0"><span class="nav-number">4.3.2.</span> <span class="nav-text">sigmoid函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%98%B6%E8%B7%83%E5%87%BD%E6%95%B0%E5%92%8Csigmoid%E5%87%BD%E6%95%B0%E7%9A%84%E6%AF%94%E8%BE%83"><span class="nav-number">4.3.3.</span> <span class="nav-text">阶跃函数和sigmoid函数的比较</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#ReLU%E5%87%BD%E6%95%B0"><span class="nav-number">4.3.4.</span> <span class="nav-text">ReLU函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AE%9E%E7%8E%B0-%E4%BB%8E%E8%BE%93%E5%85%A5%E5%88%B0%E8%BE%93%E5%87%BA%E7%9A%84%EF%BC%88%E5%89%8D%E5%90%91%EF%BC%89%E5%A4%84%E7%90%86%E7%9A%84%E7%A4%BA%E4%BE%8B"><span class="nav-number">4.3.5.</span> <span class="nav-text">3层神经网络的实现 - 从输入到输出的（前向）处理的示例</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%A2%98%E7%9B%AE"><span class="nav-number">4.3.5.1.</span> <span class="nav-text">题目</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%90%84%E5%B1%82%E9%97%B4%E4%BF%A1%E5%8F%B7%E4%BC%A0%E9%80%92%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="nav-number">4.3.5.2.</span> <span class="nav-text">各层间信号传递的实现</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%BE%93%E5%87%BA%E5%B1%82%E7%9A%84%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0"><span class="nav-number">4.4.</span> <span class="nav-text">输出层的激活函数</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%81%92%E7%AD%89%E5%87%BD%E6%95%B0"><span class="nav-number">4.4.1.</span> <span class="nav-text">恒等函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#softmax%E5%87%BD%E6%95%B0"><span class="nav-number">4.4.2.</span> <span class="nav-text">softmax函数</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%BE%93%E5%87%BA%E5%B1%82%E7%9A%84%E7%A5%9E%E7%BB%8F%E5%85%83%E6%95%B0%E9%87%8F"><span class="nav-number">4.5.</span> <span class="nav-text">输出层的神经元数量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB-%E5%89%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%9A%84%E5%AE%9E%E4%BE%8B"><span class="nav-number">4.6.</span> <span class="nav-text">手写数字识别 - 前向传播的实例</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%A7%A3%E5%86%B3%E9%97%AE%E9%A2%98%E7%9A%84%E6%AD%A5%E9%AA%A4"><span class="nav-number">4.6.1.</span> <span class="nav-text">使用神经网络解决问题的步骤</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E8%AF%B4%E6%98%8E-MNIST%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-number">4.6.2.</span> <span class="nav-text">数据集说明 - MNIST数据集</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E6%8E%A8%E7%90%86%E8%BF%87%E7%A8%8B"><span class="nav-number">4.6.3.</span> <span class="nav-text">神经网络的推理过程</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AD%A6%E4%B9%A0"><span class="nav-number">5.</span> <span class="nav-text">神经网络的学习</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%8E%E6%95%B0%E6%8D%AE%E4%B8%AD%E5%AD%A6%E4%B9%A0"><span class="nav-number">5.1.</span> <span class="nav-text">从数据中学习</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E9%A9%B1%E5%8A%A8"><span class="nav-number">5.1.1.</span> <span class="nav-text">数据驱动</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E5%92%8C%E6%B5%8B%E8%AF%95%E6%95%B0%E6%8D%AE"><span class="nav-number">5.1.2.</span> <span class="nav-text">训练数据和测试数据</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="nav-number">5.2.</span> <span class="nav-text">损失函数</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9D%87%E6%96%B9%E8%AF%AF%E5%B7%AE"><span class="nav-number">5.2.1.</span> <span class="nav-text">均方误差</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BA%A4%E5%8F%89%E7%86%B5%E8%AF%AF%E5%B7%AE"><span class="nav-number">5.2.2.</span> <span class="nav-text">交叉熵误差</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#mini-batch%E5%AD%A6%E4%B9%A0"><span class="nav-number">5.2.3.</span> <span class="nav-text">mini-batch学习</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#mini-batch%E7%89%88%E4%BA%A4%E5%8F%89%E7%86%B5%E8%AF%AF%E5%B7%AE%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="nav-number">5.2.4.</span> <span class="nav-text">mini-batch版交叉熵误差的实现</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%BA%E4%BD%95%E8%A6%81%E8%AE%BE%E5%AE%9A%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="nav-number">5.2.5.</span> <span class="nav-text">为何要设定损失函数</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B0%E5%80%BC%E5%BE%AE%E5%88%86"><span class="nav-number">5.3.</span> <span class="nav-text">数值微分</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AF%BC%E6%95%B0"><span class="nav-number">5.3.1.</span> <span class="nav-text">导数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%81%8F%E5%AF%BC%E6%95%B0"><span class="nav-number">5.3.2.</span> <span class="nav-text">偏导数</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A2%AF%E5%BA%A6"><span class="nav-number">5.4.</span> <span class="nav-text">梯度</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%A2%AF%E5%BA%A6%E6%B3%95"><span class="nav-number">5.4.1.</span> <span class="nav-text">梯度法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E6%A2%AF%E5%BA%A6"><span class="nav-number">5.4.2.</span> <span class="nav-text">神经网络的梯度</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="nav-number">5.5.</span> <span class="nav-text">学习算法的实现</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E7%B1%BB"><span class="nav-number">5.5.1.</span> <span class="nav-text">2层神经网络的类</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#mini-batch%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="nav-number">5.5.2.</span> <span class="nav-text">mini-batch的实现</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8E%E6%B5%8B%E8%AF%95%E6%95%B0%E6%8D%AE%E7%9A%84%E8%AF%84%E4%BB%B7"><span class="nav-number">5.5.3.</span> <span class="nav-text">基于测试数据的评价</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AF%AF%E5%B7%AE%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E6%B3%95"><span class="nav-number">6.</span> <span class="nav-text">误差反向传播法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%A1%E7%AE%97%E5%9B%BE"><span class="nav-number">6.1.</span> <span class="nav-text">计算图</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%94%A8%E8%AE%A1%E7%AE%97%E5%9B%BE%E6%B1%82%E8%A7%A3"><span class="nav-number">6.1.1.</span> <span class="nav-text">用计算图求解</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%B1%80%E9%83%A8%E8%AE%A1%E7%AE%97"><span class="nav-number">6.1.2.</span> <span class="nav-text">局部计算</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%BA%E4%BD%95%E7%94%A8%E8%AE%A1%E7%AE%97%E5%9B%BE%E8%A7%A3%E9%A2%98"><span class="nav-number">6.1.3.</span> <span class="nav-text">为何用计算图解题</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%93%BE%E5%BC%8F%E6%B3%95%E5%88%99"><span class="nav-number">6.2.</span> <span class="nav-text">链式法则</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AE%A1%E7%AE%97%E5%9B%BE%E7%9A%84%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD"><span class="nav-number">6.2.1.</span> <span class="nav-text">计算图的反向传播</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E9%93%BE%E5%BC%8F%E6%B3%95%E5%88%99"><span class="nav-number">6.2.2.</span> <span class="nav-text">什么是链式法则</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%93%BE%E5%BC%8F%E6%B3%95%E5%88%99%E5%92%8C%E8%AE%A1%E7%AE%97%E5%9B%BE"><span class="nav-number">6.2.3.</span> <span class="nav-text">链式法则和计算图</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD"><span class="nav-number">6.3.</span> <span class="nav-text">反向传播</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8A%A0%E6%B3%95%E8%8A%82%E7%82%B9%E7%9A%84%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD"><span class="nav-number">6.3.1.</span> <span class="nav-text">加法节点的反向传播</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B9%98%E6%B3%95%E8%8A%82%E7%82%B9%E7%9A%84%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD"><span class="nav-number">6.3.2.</span> <span class="nav-text">乘法节点的反向传播</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%8B%B9%E6%9E%9C%E7%9A%84%E4%BE%8B%E5%AD%90"><span class="nav-number">6.3.3.</span> <span class="nav-text">苹果的例子</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AE%80%E5%8D%95%E5%B1%82%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="nav-number">6.4.</span> <span class="nav-text">简单层的实现</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B9%98%E6%B3%95%E5%B1%82%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="nav-number">6.4.1.</span> <span class="nav-text">乘法层的实现</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8A%A0%E6%B3%95%E5%B1%82%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="nav-number">6.4.2.</span> <span class="nav-text">加法层的实现</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E5%B1%82%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="nav-number">6.5.</span> <span class="nav-text">激活函数层的实现</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#ReLU%E5%B1%82"><span class="nav-number">6.5.1.</span> <span class="nav-text">ReLU层</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Sigmoid%E5%B1%82"><span class="nav-number">6.5.2.</span> <span class="nav-text">Sigmoid层</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Affine-Softmax%E5%B1%82%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="nav-number">6.6.</span> <span class="nav-text">Affine&#x2F;Softmax层的实现</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Affine%E5%B1%82"><span class="nav-number">6.6.1.</span> <span class="nav-text">Affine层</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Softmax-with-Loss-%E5%B1%82"><span class="nav-number">6.6.2.</span> <span class="nav-text">Softmax-with-Loss 层</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AF%AF%E5%B7%AE%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E6%B3%95%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="nav-number">6.7.</span> <span class="nav-text">误差反向传播法的实现</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AF%B9%E5%BA%94%E8%AF%AF%E5%B7%AE%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E6%B3%95%E7%9A%84%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="nav-number">6.7.1.</span> <span class="nav-text">对应误差反向传播法的神经网络的实现</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AF%AF%E5%B7%AE%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E6%B3%95%E7%9A%84%E6%A2%AF%E5%BA%A6%E7%A1%AE%E8%AE%A4"><span class="nav-number">6.7.2.</span> <span class="nav-text">误差反向传播法的梯度确认</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8%E8%AF%AF%E5%B7%AE%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E6%B3%95%E7%9A%84%E5%AD%A6%E4%B9%A0"><span class="nav-number">6.7.3.</span> <span class="nav-text">使用误差反向传播法的学习</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%8E%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E7%9A%84%E6%8A%80%E5%B7%A7"><span class="nav-number">7.</span> <span class="nav-text">与学习相关的技巧</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8F%82%E6%95%B0%E7%9A%84%E6%9B%B4%E6%96%B0"><span class="nav-number">7.1.</span> <span class="nav-text">参数的更新</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%8E%A2%E9%99%A9%E5%AE%B6%E7%9A%84%E6%95%85%E4%BA%8B"><span class="nav-number">7.1.1.</span> <span class="nav-text">探险家的故事</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#SGD"><span class="nav-number">7.1.2.</span> <span class="nav-text">SGD</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Momentum"><span class="nav-number">7.1.3.</span> <span class="nav-text">Momentum</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#AdaGrad"><span class="nav-number">7.1.4.</span> <span class="nav-text">AdaGrad</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8EMNIST%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E6%9B%B4%E6%96%B0%E6%96%B9%E6%B3%95%E7%9A%84%E6%AF%94%E8%BE%83"><span class="nav-number">7.1.5.</span> <span class="nav-text">基于MNIST数据集的更新方法的比较</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9D%83%E9%87%8D%E7%9A%84%E5%88%9D%E5%A7%8B%E5%80%BC"><span class="nav-number">7.2.</span> <span class="nav-text">权重的初始值</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8F%AF%E4%BB%A5%E5%B0%86%E6%9D%83%E9%87%8D%E5%88%9D%E5%A7%8B%E5%80%BC%E8%AE%BE%E4%B8%BA0%E5%90%97"><span class="nav-number">7.2.1.</span> <span class="nav-text">可以将权重初始值设为0吗</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%9A%90%E8%97%8F%E5%B1%82%E7%9A%84%E6%BF%80%E6%B4%BB%E5%80%BC%E7%9A%84%E5%88%86%E5%B8%83"><span class="nav-number">7.2.2.</span> <span class="nav-text">隐藏层的激活值的分布</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#ReLU%E7%9A%84%E6%9D%83%E9%87%8D%E5%88%9D%E5%A7%8B%E5%80%BC"><span class="nav-number">7.2.3.</span> <span class="nav-text">ReLU的权重初始值</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8EMNIST%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E6%9D%83%E9%87%8D%E5%88%9D%E5%A7%8B%E5%80%BC%E7%9A%84%E6%AF%94%E8%BE%83"><span class="nav-number">7.2.4.</span> <span class="nav-text">基于MNIST数据集的权重初始值的比较</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%AD%A3%E5%88%99%E5%8C%96"><span class="nav-number">7.3.</span> <span class="nav-text">正则化</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%BF%87%E6%8B%9F%E5%90%88"><span class="nav-number">7.3.1.</span> <span class="nav-text">过拟合</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9D%83%E5%80%BC%E8%A1%B0%E5%87%8F"><span class="nav-number">7.3.2.</span> <span class="nav-text">权值衰减</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Dropout"><span class="nav-number">7.3.3.</span> <span class="nav-text">Dropout</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%B6%85%E5%8F%82%E6%95%B0%E7%9A%84%E9%AA%8C%E8%AF%81"><span class="nav-number">7.4.</span> <span class="nav-text">超参数的验证</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%AA%8C%E8%AF%81%E6%95%B0%E6%8D%AE"><span class="nav-number">7.4.1.</span> <span class="nav-text">验证数据</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%B6%85%E5%8F%82%E6%95%B0%E7%9A%84%E6%9C%80%E4%BC%98%E5%8C%96"><span class="nav-number">7.4.2.</span> <span class="nav-text">超参数的最优化</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%B6%85%E5%8F%82%E6%95%B0%E6%9C%80%E4%BC%98%E5%8C%96%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="nav-number">7.4.3.</span> <span class="nav-text">超参数最优化的实现</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="nav-number">8.</span> <span class="nav-text">卷积神经网络</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B4%E4%BD%93%E7%BB%93%E6%9E%84"><span class="nav-number">8.1.</span> <span class="nav-text">整体结构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8D%B7%E7%A7%AF%E5%B1%82"><span class="nav-number">8.2.</span> <span class="nav-text">卷积层</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82%E5%AD%98%E5%9C%A8%E7%9A%84%E9%97%AE%E9%A2%98"><span class="nav-number">8.2.1.</span> <span class="nav-text">全连接层存在的问题</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8D%B7%E7%A7%AF%E8%BF%90%E7%AE%97"><span class="nav-number">8.2.2.</span> <span class="nav-text">卷积运算</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%A1%AB%E5%85%85"><span class="nav-number">8.2.3.</span> <span class="nav-text">填充</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%AD%A5%E5%B9%85"><span class="nav-number">8.2.4.</span> <span class="nav-text">步幅</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3%E7%BB%B4%E6%95%B0%E6%8D%AE%E7%9A%84%E5%8D%B7%E7%A7%AF%E8%BF%90%E7%AE%97"><span class="nav-number">8.2.5.</span> <span class="nav-text">3维数据的卷积运算</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%BB%93%E5%90%88%E6%96%B9%E5%9D%97%E6%80%9D%E8%80%83"><span class="nav-number">8.2.6.</span> <span class="nav-text">结合方块思考</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B1%A0%E5%8C%96%E5%B1%82"><span class="nav-number">8.3.</span> <span class="nav-text">池化层</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8D%B7%E7%A7%AF%E5%B1%82%E5%92%8C%E6%B1%A0%E5%8C%96%E5%B1%82%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="nav-number">8.4.</span> <span class="nav-text">卷积层和池化层的实现</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8Eim2col%E7%9A%84%E5%B1%95%E5%BC%80"><span class="nav-number">8.4.1.</span> <span class="nav-text">基于im2col的展开</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8D%B7%E7%A7%AF%E5%B1%82%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="nav-number">8.4.2.</span> <span class="nav-text">卷积层的实现</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%B1%A0%E5%8C%96%E5%B1%82%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="nav-number">8.4.3.</span> <span class="nav-text">池化层的实现</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CNN%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="nav-number">8.5.</span> <span class="nav-text">CNN的实现</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CNN%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96"><span class="nav-number">8.6.</span> <span class="nav-text">CNN的可视化</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%AC%AC1%E5%B1%82%E6%9D%83%E9%87%8D%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96"><span class="nav-number">8.6.1.</span> <span class="nav-text">第1层权重的可视化</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8E%E5%88%86%E5%B1%82%E7%BB%93%E6%9E%84%E7%9A%84%E4%BF%A1%E6%81%AF%E6%8F%90%E5%8F%96"><span class="nav-number">8.6.2.</span> <span class="nav-text">基于分层结构的信息提取</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%B7%E6%9C%89%E4%BB%A3%E8%A1%A8%E6%80%A7%E7%9A%84CNN"><span class="nav-number">8.7.</span> <span class="nav-text">具有代表性的CNN</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#LeNet"><span class="nav-number">8.7.1.</span> <span class="nav-text">LeNet</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#AlexNet"><span class="nav-number">8.7.2.</span> <span class="nav-text">AlexNet</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0"><span class="nav-number">9.</span> <span class="nav-text">深度学习</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8A%A0%E6%B7%B1%E7%BD%91%E7%BB%9C"><span class="nav-number">9.1.</span> <span class="nav-text">加深网络</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%90%91%E6%9B%B4%E6%B7%B1%E7%9A%84%E7%BD%91%E7%BB%9C%E5%87%BA%E5%8F%91"><span class="nav-number">9.1.1.</span> <span class="nav-text">向更深的网络出发</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Bonnie"
      src="/images/avatar.gif">
  <p class="site-author-name" itemprop="name">Bonnie</p>
  <div class="site-description" itemprop="description">每天都要做个人啊</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">124</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">72</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2021-05 – 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Bonnie</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

  

</body>
</html>
